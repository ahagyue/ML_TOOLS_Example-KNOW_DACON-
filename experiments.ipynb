{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data_loader import create_data_loaders, create_exp_loaders\n",
    "from model.KnowNet import KnowNet\n",
    "from setting.base_config import BaseConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<torch.utils.data.dataloader.DataLoader at 0x7f2fb0438c10>,\n",
       "  <torch.utils.data.dataloader.DataLoader at 0x7f2fb0438a00>),\n",
       " (<torch.utils.data.dataloader.DataLoader at 0x7f2e4d309a30>,\n",
       "  <torch.utils.data.dataloader.DataLoader at 0x7f2e4d309f10>),\n",
       " (<torch.utils.data.dataloader.DataLoader at 0x7f2e4873d730>,\n",
       "  <torch.utils.data.dataloader.DataLoader at 0x7f2e4873d340>),\n",
       " (<torch.utils.data.dataloader.DataLoader at 0x7f2e4873d310>,\n",
       "  <torch.utils.data.dataloader.DataLoader at 0x7f2e4873d250>),\n",
       " (<torch.utils.data.dataloader.DataLoader at 0x7f2e4873d3a0>,\n",
       "  <torch.utils.data.dataloader.DataLoader at 0x7f2e4873d190>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BaseConfig()\n",
    "args = config.get_config(2017)\n",
    "data_loader , label_encoder, group = create_data_loaders(2017, args)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU_NUM=1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "layers = [77, 1000, 538]\n",
    "\n",
    "net = KnowNet(group, layers)\n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return (torch.argmax(x, axis = 1) == y).float().sum()/x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : val acc = 0.0431578947368421\n",
      "1 : val acc = 0.06578947368421052\n",
      "2 : val acc = 0.08157894736842106\n",
      "3 : val acc = 0.09736842105263158\n",
      "4 : val acc = 0.11421052631578947\n",
      "5 : val acc = 0.12368421052631579\n",
      "6 : val acc = 0.13526315789473684\n",
      "7 : val acc = 0.13736842105263158\n",
      "8 : val acc = 0.15947368421052632\n",
      "9 : val acc = 0.18052631578947367\n",
      "10 : val acc = 0.18052631578947367\n",
      "11 : val acc = 0.18842105263157893\n",
      "12 : val acc = 0.2\n",
      "13 : val acc = 0.2\n",
      "14 : val acc = 0.2031578947368421\n",
      "15 : val acc = 0.21736842105263157\n",
      "16 : val acc = 0.22052631578947368\n",
      "17 : val acc = 0.21263157894736842\n",
      "18 : val acc = 0.23473684210526316\n",
      "19 : val acc = 0.2326315789473684\n",
      "20 : val acc = 0.23210526315789473\n",
      "21 : val acc = 0.24157894736842106\n",
      "22 : val acc = 0.24421052631578946\n",
      "23 : val acc = 0.25\n",
      "24 : val acc = 0.2468421052631579\n",
      "25 : val acc = 0.2578947368421053\n",
      "26 : val acc = 0.26631578947368423\n",
      "27 : val acc = 0.25263157894736843\n",
      "28 : val acc = 0.26789473684210524\n",
      "29 : val acc = 0.2710526315789474\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = data_loader[1]\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0001)\n",
    "for epoch in range(30):\n",
    "    for data, label in train_data:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    acc = 0.\n",
    "    for data, label in val_data:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label).item()\n",
    "    acc /= len(val_data)\n",
    "    print(\"{} : val acc = {}\".format(epoch, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setting.exp_config import ExpConfig\n",
    "from exp.tuner import tune_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExpConfig()\n",
    "args = config.get_config(2017)\n",
    "\n",
    "net = lambda layer: KnowNet(group, layer)\n",
    "hyper_params_setting = config.get_exp_arg(net)\n",
    "default_setting = config.get_default_arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FOLD': 5,\n",
       " 'DATA_ROOT': PosixPath('../KNOW_data'),\n",
       " 'STRING_INDEX': [87, 88, 89, 92, 121, 139, 140, 141, 142, 143, 148],\n",
       " 'batch_size': 4,\n",
       " 'num_workers': 1,\n",
       " 'device': device(type='cuda', index=1),\n",
       " 'early_stopping_step': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4,\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 5e-06,\n",
       " 'criterion': CrossEntropyLoss(),\n",
       " 'optimizer': <function setting.exp_config.ExpConfig.__init__.<locals>.<lambda>(p, lr, wd)>,\n",
       " 'model': KnowNet(\n",
       "   (small_net_list): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (3): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (4): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (5): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (6): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (7): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (8): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (9): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (10): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (11): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (12): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (13): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (14): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (15): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (16): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (17): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (18): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (19): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (20): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (21): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (22): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (23): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (24): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (25): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (26): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (27): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (28): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (29): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (30): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (31): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (32): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (33): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (34): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (35): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (36): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (37): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (38): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (39): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (40): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (41): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (42): Sequential(\n",
       "       (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (43): Sequential(\n",
       "       (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (44): Sequential(\n",
       "       (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (45): Sequential(\n",
       "       (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (46): Sequential(\n",
       "       (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (47): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "     (48): Sequential(\n",
       "       (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "       (3): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (linear_layer): Sequential(\n",
       "     (0): Linear(in_features=77, out_features=100, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=100, out_features=538, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahagyue\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: n3h4t7kn\n",
      "Sweep URL: https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: or93tqlc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/or93tqlc\" target=\"_blank\">deep-sweep-1</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.211 , time : 40.31659388542175: 100%|██████████| 1898/1898 [00:40<00:00, 47.04it/s] \n",
      "Epoch: 0. Validation. Loss: 6.256 , time : 2.15878963470459: 100%|██████████| 475/475 [00:02<00:00, 216.31it/s]  \n",
      "Epoch: 1. Train.      Loss: 6.070 , time : 38.22487163543701: 100%|██████████| 1898/1898 [00:38<00:00, 49.61it/s] \n",
      "Epoch: 1. Validation. Loss: 6.254 , time : 2.131404399871826: 100%|██████████| 475/475 [00:02<00:00, 219.17it/s] \n",
      "Epoch: 2. Train.      Loss: 6.019 , time : 38.209322690963745: 100%|██████████| 1898/1898 [00:38<00:00, 49.63it/s]\n",
      "Epoch: 2. Validation. Loss: 6.212 , time : 2.107211112976074: 100%|██████████| 475/475 [00:02<00:00, 221.69it/s] \n",
      "Epoch: 3. Train.      Loss: 5.954 , time : 38.271275758743286: 100%|██████████| 1898/1898 [00:38<00:00, 49.55it/s]\n",
      "Epoch: 3. Validation. Loss: 6.146 , time : 2.1117544174194336: 100%|██████████| 475/475 [00:02<00:00, 221.21it/s]\n",
      "Epoch: 4. Train.      Loss: 5.859 , time : 38.313408851623535: 100%|██████████| 1898/1898 [00:38<00:00, 49.49it/s]\n",
      "Epoch: 4. Validation. Loss: 6.054 , time : 2.1478328704833984: 100%|██████████| 475/475 [00:02<00:00, 217.55it/s]\n",
      "Epoch: 5. Train.      Loss: 5.734 , time : 38.434985399246216: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s]\n",
      "Epoch: 5. Validation. Loss: 5.936 , time : 2.180344581604004: 100%|██████████| 475/475 [00:02<00:00, 214.36it/s] \n",
      "Epoch: 6. Train.      Loss: 5.590 , time : 38.9009153842926: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s]  \n",
      "Epoch: 6. Validation. Loss: 5.819 , time : 2.0715999603271484: 100%|██████████| 475/475 [00:02<00:00, 225.25it/s]\n",
      "Epoch: 7. Train.      Loss: 5.443 , time : 38.97060441970825: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 7. Validation. Loss: 5.706 , time : 2.1762142181396484: 100%|██████████| 475/475 [00:02<00:00, 214.79it/s]\n",
      "Epoch: 8. Train.      Loss: 5.304 , time : 38.39101266860962: 100%|██████████| 1898/1898 [00:38<00:00, 49.39it/s] \n",
      "Epoch: 8. Validation. Loss: 5.606 , time : 2.1679046154022217: 100%|██████████| 475/475 [00:02<00:00, 215.52it/s]\n",
      "Epoch: 9. Train.      Loss: 5.175 , time : 38.460376501083374: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s]\n",
      "Epoch: 9. Validation. Loss: 5.495 , time : 2.1464412212371826: 100%|██████████| 475/475 [00:02<00:00, 217.69it/s]\n",
      "Epoch: 10. Train.      Loss: 5.058 , time : 38.002429723739624: 100%|██████████| 1898/1898 [00:38<00:00, 49.90it/s]\n",
      "Epoch: 10. Validation. Loss: 5.405 , time : 2.1624109745025635: 100%|██████████| 475/475 [00:02<00:00, 216.05it/s]\n",
      "Epoch: 11. Train.      Loss: 4.951 , time : 38.777525901794434: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]\n",
      "Epoch: 11. Validation. Loss: 5.314 , time : 2.118593692779541: 100%|██████████| 475/475 [00:02<00:00, 219.97it/s] \n",
      "Epoch: 12. Train.      Loss: 4.853 , time : 37.459141969680786: 100%|██████████| 1898/1898 [00:37<00:00, 50.62it/s]\n",
      "Epoch: 12. Validation. Loss: 5.231 , time : 2.1367979049682617: 100%|██████████| 475/475 [00:02<00:00, 218.44it/s]\n",
      "Epoch: 13. Train.      Loss: 4.765 , time : 37.76795482635498: 100%|██████████| 1898/1898 [00:37<00:00, 50.21it/s] \n",
      "Epoch: 13. Validation. Loss: 5.144 , time : 2.049025774002075: 100%|██████████| 475/475 [00:02<00:00, 227.87it/s] \n",
      "Epoch: 14. Train.      Loss: 4.679 , time : 37.228166341781616: 100%|██████████| 1898/1898 [00:37<00:00, 50.93it/s]\n",
      "Epoch: 14. Validation. Loss: 5.066 , time : 2.074491500854492: 100%|██████████| 475/475 [00:02<00:00, 225.11it/s] \n",
      "Epoch: 15. Train.      Loss: 4.601 , time : 37.38590669631958: 100%|██████████| 1898/1898 [00:37<00:00, 50.72it/s] \n",
      "Epoch: 15. Validation. Loss: 5.019 , time : 2.1137166023254395: 100%|██████████| 475/475 [00:02<00:00, 220.83it/s]\n",
      "Epoch: 16. Train.      Loss: 4.526 , time : 37.64916944503784: 100%|██████████| 1898/1898 [00:37<00:00, 50.37it/s] \n",
      "Epoch: 16. Validation. Loss: 4.943 , time : 2.047900915145874: 100%|██████████| 475/475 [00:02<00:00, 227.95it/s] \n",
      "Epoch: 17. Train.      Loss: 4.454 , time : 37.2994863986969: 100%|██████████| 1898/1898 [00:37<00:00, 50.83it/s]  \n",
      "Epoch: 17. Validation. Loss: 4.881 , time : 2.051632881164551: 100%|██████████| 475/475 [00:02<00:00, 227.33it/s] \n",
      "Epoch: 18. Train.      Loss: 4.385 , time : 37.37120223045349: 100%|██████████| 1898/1898 [00:37<00:00, 50.74it/s] \n",
      "Epoch: 18. Validation. Loss: 4.843 , time : 2.0821876525878906: 100%|██████████| 475/475 [00:02<00:00, 224.24it/s]\n",
      "Epoch: 19. Train.      Loss: 4.319 , time : 37.59775471687317: 100%|██████████| 1898/1898 [00:37<00:00, 50.43it/s] \n",
      "Epoch: 19. Validation. Loss: 4.782 , time : 2.104743242263794: 100%|██████████| 475/475 [00:02<00:00, 220.96it/s] \n",
      "Epoch: 20. Train.      Loss: 4.256 , time : 37.734790086746216: 100%|██████████| 1898/1898 [00:37<00:00, 50.25it/s]\n",
      "Epoch: 20. Validation. Loss: 4.741 , time : 2.097844123840332: 100%|██████████| 475/475 [00:02<00:00, 222.64it/s] \n",
      "Epoch: 21. Train.      Loss: 4.194 , time : 37.0880069732666: 100%|██████████| 1898/1898 [00:37<00:00, 51.12it/s]  \n",
      "Epoch: 21. Validation. Loss: 4.688 , time : 2.0426175594329834: 100%|██████████| 475/475 [00:02<00:00, 227.87it/s]\n",
      "Epoch: 22. Train.      Loss: 4.137 , time : 37.286404848098755: 100%|██████████| 1898/1898 [00:37<00:00, 50.86it/s]\n",
      "Epoch: 22. Validation. Loss: 4.643 , time : 2.095140218734741: 100%|██████████| 475/475 [00:02<00:00, 222.97it/s] \n",
      "Epoch: 23. Train.      Loss: 4.081 , time : 37.74107241630554: 100%|██████████| 1898/1898 [00:37<00:00, 50.24it/s] \n",
      "Epoch: 23. Validation. Loss: 4.620 , time : 2.0661003589630127: 100%|██████████| 475/475 [00:02<00:00, 225.83it/s]\n",
      "Epoch: 24. Train.      Loss: 4.027 , time : 37.37959837913513: 100%|██████████| 1898/1898 [00:37<00:00, 50.73it/s] \n",
      "Epoch: 24. Validation. Loss: 4.566 , time : 2.0653879642486572: 100%|██████████| 475/475 [00:02<00:00, 225.89it/s]\n",
      "Epoch: 25. Train.      Loss: 3.971 , time : 37.42480134963989: 100%|██████████| 1898/1898 [00:37<00:00, 50.67it/s] \n",
      "Epoch: 25. Validation. Loss: 4.521 , time : 2.1390233039855957: 100%|██████████| 475/475 [00:02<00:00, 218.30it/s]\n",
      "Epoch: 26. Train.      Loss: 3.919 , time : 37.708386182785034: 100%|██████████| 1898/1898 [00:37<00:00, 50.28it/s]\n",
      "Epoch: 26. Validation. Loss: 4.478 , time : 2.0869362354278564: 100%|██████████| 475/475 [00:02<00:00, 222.53it/s]\n",
      "Epoch: 27. Train.      Loss: 3.869 , time : 37.576521158218384: 100%|██████████| 1898/1898 [00:37<00:00, 50.46it/s]\n",
      "Epoch: 27. Validation. Loss: 4.457 , time : 2.0662150382995605: 100%|██████████| 475/475 [00:02<00:00, 225.90it/s]\n",
      "Epoch: 28. Train.      Loss: 3.822 , time : 37.57516813278198: 100%|██████████| 1898/1898 [00:37<00:00, 50.46it/s] \n",
      "Epoch: 28. Validation. Loss: 4.416 , time : 2.095749616622925: 100%|██████████| 475/475 [00:02<00:00, 222.86it/s] \n",
      "Epoch: 29. Train.      Loss: 3.774 , time : 38.21117091178894: 100%|██████████| 1898/1898 [00:38<00:00, 49.62it/s] \n",
      "Epoch: 29. Validation. Loss: 4.385 , time : 2.13844895362854: 100%|██████████| 475/475 [00:02<00:00, 218.46it/s]  \n",
      "Epoch: 30. Train.      Loss: 3.728 , time : 38.68690085411072: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 30. Validation. Loss: 4.341 , time : 2.11033296585083: 100%|██████████| 475/475 [00:02<00:00, 221.26it/s]  \n",
      "Epoch: 31. Train.      Loss: 3.684 , time : 39.05127787590027: 100%|██████████| 1898/1898 [00:39<00:00, 48.56it/s] \n",
      "Epoch: 31. Validation. Loss: 4.325 , time : 2.1279397010803223: 100%|██████████| 475/475 [00:02<00:00, 218.22it/s]\n",
      "Epoch: 32. Train.      Loss: 3.640 , time : 38.95878291130066: 100%|██████████| 1898/1898 [00:38<00:00, 48.67it/s] \n",
      "Epoch: 32. Validation. Loss: 4.292 , time : 2.230989933013916: 100%|██████████| 475/475 [00:02<00:00, 209.40it/s] \n",
      "Epoch: 33. Train.      Loss: 3.598 , time : 38.641303300857544: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s]\n",
      "Epoch: 33. Validation. Loss: 4.275 , time : 2.177574634552002: 100%|██████████| 475/475 [00:02<00:00, 214.59it/s] \n",
      "Epoch: 34. Train.      Loss: 3.557 , time : 38.49956226348877: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 34. Validation. Loss: 4.250 , time : 2.095479965209961: 100%|██████████| 475/475 [00:02<00:00, 222.70it/s] \n",
      "Epoch: 35. Train.      Loss: 3.517 , time : 38.77915000915527: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 35. Validation. Loss: 4.214 , time : 2.111064910888672: 100%|██████████| 475/475 [00:02<00:00, 221.26it/s] \n",
      "Epoch: 36. Train.      Loss: 3.477 , time : 38.60048532485962: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 36. Validation. Loss: 4.203 , time : 2.1524651050567627: 100%|██████████| 475/475 [00:02<00:00, 217.05it/s]\n",
      "Epoch: 37. Train.      Loss: 3.438 , time : 38.45810675621033: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s] \n",
      "Epoch: 37. Validation. Loss: 4.152 , time : 2.1605825424194336: 100%|██████████| 475/475 [00:02<00:00, 216.29it/s]\n",
      "Epoch: 38. Train.      Loss: 3.402 , time : 38.62552189826965: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 38. Validation. Loss: 4.160 , time : 2.167908191680908: 100%|██████████| 475/475 [00:02<00:00, 215.51it/s] \n",
      "Epoch: 39. Train.      Loss: 3.366 , time : 38.91176986694336: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 39. Validation. Loss: 4.156 , time : 2.1419835090637207: 100%|██████████| 475/475 [00:02<00:00, 218.15it/s]\n",
      "Epoch: 40. Train.      Loss: 3.330 , time : 38.580076694488525: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 40. Validation. Loss: 4.143 , time : 2.215599775314331: 100%|██████████| 475/475 [00:02<00:00, 211.00it/s] \n",
      "Epoch: 41. Train.      Loss: 3.295 , time : 38.30727005004883: 100%|██████████| 1898/1898 [00:38<00:00, 49.50it/s] \n",
      "Epoch: 41. Validation. Loss: 4.121 , time : 2.104308843612671: 100%|██████████| 475/475 [00:02<00:00, 221.78it/s] \n",
      "Epoch: 42. Train.      Loss: 3.264 , time : 38.419708490371704: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]\n",
      "Epoch: 42. Validation. Loss: 4.104 , time : 2.140460968017578: 100%|██████████| 475/475 [00:02<00:00, 218.22it/s] \n",
      "Epoch: 43. Train.      Loss: 3.229 , time : 38.15176963806152: 100%|██████████| 1898/1898 [00:38<00:00, 49.70it/s] \n",
      "Epoch: 43. Validation. Loss: 4.061 , time : 2.1328940391540527: 100%|██████████| 475/475 [00:02<00:00, 219.06it/s]\n",
      "Epoch: 44. Train.      Loss: 3.199 , time : 38.48700737953186: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 44. Validation. Loss: 4.067 , time : 2.099623918533325: 100%|██████████| 475/475 [00:02<00:00, 222.46it/s] \n",
      "Epoch: 45. Train.      Loss: 3.162 , time : 38.48428964614868: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 45. Validation. Loss: 4.070 , time : 2.0805463790893555: 100%|██████████| 475/475 [00:02<00:00, 222.17it/s]\n",
      "Epoch: 46. Train.      Loss: 3.134 , time : 38.58951210975647: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 46. Validation. Loss: 4.044 , time : 2.1944937705993652: 100%|██████████| 475/475 [00:02<00:00, 212.94it/s]\n",
      "Epoch: 47. Train.      Loss: 3.102 , time : 39.18666172027588: 100%|██████████| 1898/1898 [00:39<00:00, 48.39it/s] \n",
      "Epoch: 47. Validation. Loss: 4.055 , time : 2.314171314239502: 100%|██████████| 475/475 [00:02<00:00, 202.11it/s] \n",
      "Epoch: 48. Train.      Loss: 3.075 , time : 38.617281436920166: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s]\n",
      "Epoch: 48. Validation. Loss: 4.043 , time : 2.179093837738037: 100%|██████████| 475/475 [00:02<00:00, 214.41it/s] \n",
      "Epoch: 49. Train.      Loss: 3.044 , time : 38.218581676483154: 100%|██████████| 1898/1898 [00:38<00:00, 49.61it/s]\n",
      "Epoch: 49. Validation. Loss: 4.027 , time : 2.158459424972534: 100%|██████████| 475/475 [00:02<00:00, 216.46it/s] \n",
      "Epoch: 50. Train.      Loss: 3.016 , time : 38.53201222419739: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 50. Validation. Loss: 4.023 , time : 2.1459593772888184: 100%|██████████| 475/475 [00:02<00:00, 217.60it/s]\n",
      "Epoch: 51. Train.      Loss: 2.987 , time : 38.72667407989502: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 51. Validation. Loss: 4.004 , time : 2.1392109394073486: 100%|██████████| 475/475 [00:02<00:00, 218.42it/s]\n",
      "Epoch: 52. Train.      Loss: 2.957 , time : 38.54460549354553: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 52. Validation. Loss: 4.024 , time : 2.1043317317962646: 100%|██████████| 475/475 [00:02<00:00, 221.82it/s]\n",
      "Epoch: 53. Train.      Loss: 2.930 , time : 38.42509865760803: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s] \n",
      "Epoch: 53. Validation. Loss: 4.027 , time : 2.119441032409668: 100%|██████████| 475/475 [00:02<00:00, 220.31it/s] \n",
      "Epoch: 54. Train.      Loss: 2.906 , time : 38.23117232322693: 100%|██████████| 1898/1898 [00:38<00:00, 49.60it/s] \n",
      "Epoch: 54. Validation. Loss: 4.010 , time : 2.1400911808013916: 100%|██████████| 475/475 [00:02<00:00, 218.31it/s]\n",
      "Epoch: 55. Train.      Loss: 2.881 , time : 38.263598918914795: 100%|██████████| 1898/1898 [00:38<00:00, 49.56it/s]\n",
      "Epoch: 55. Validation. Loss: 4.010 , time : 2.16131329536438: 100%|██████████| 475/475 [00:02<00:00, 216.19it/s]  \n",
      "Epoch: 56. Train.      Loss: 2.852 , time : 38.554264307022095: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s]\n",
      "Epoch: 56. Validation. Loss: 3.997 , time : 2.165562152862549: 100%|██████████| 475/475 [00:02<00:00, 215.62it/s] \n",
      "Epoch: 57. Train.      Loss: 2.828 , time : 38.87996482849121: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 57. Validation. Loss: 3.999 , time : 2.1264724731445312: 100%|██████████| 475/475 [00:02<00:00, 219.72it/s]\n",
      "Epoch: 58. Train.      Loss: 2.802 , time : 38.54553246498108: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 58. Validation. Loss: 4.026 , time : 2.153315782546997: 100%|██████████| 475/475 [00:02<00:00, 216.99it/s] \n",
      "Epoch: 59. Train.      Loss: 2.781 , time : 38.52164053916931: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 59. Validation. Loss: 4.016 , time : 2.106458902359009: 100%|██████████| 475/475 [00:02<00:00, 221.67it/s] \n",
      "Epoch: 60. Train.      Loss: 2.752 , time : 38.3630793094635: 100%|██████████| 1898/1898 [00:38<00:00, 49.43it/s]  \n",
      "Epoch: 60. Validation. Loss: 3.996 , time : 2.0764424800872803: 100%|██████████| 475/475 [00:02<00:00, 224.86it/s]\n",
      "Epoch: 61. Train.      Loss: 2.732 , time : 38.36750817298889: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 61. Validation. Loss: 4.003 , time : 2.1036934852600098: 100%|██████████| 475/475 [00:02<00:00, 221.86it/s]\n",
      "Epoch: 62. Train.      Loss: 2.709 , time : 38.83450150489807: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 62. Validation. Loss: 4.003 , time : 2.1326043605804443: 100%|██████████| 475/475 [00:02<00:00, 219.04it/s]\n",
      "Epoch: 63. Train.      Loss: 2.688 , time : 38.397000312805176: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s]\n",
      "Epoch: 63. Validation. Loss: 3.989 , time : 2.1798503398895264: 100%|██████████| 475/475 [00:02<00:00, 214.39it/s]\n",
      "Epoch: 64. Train.      Loss: 2.664 , time : 38.35572385787964: 100%|██████████| 1898/1898 [00:38<00:00, 49.44it/s] \n",
      "Epoch: 64. Validation. Loss: 3.979 , time : 2.2614946365356445: 100%|██████████| 475/475 [00:02<00:00, 206.79it/s]\n",
      "Epoch: 65. Train.      Loss: 2.641 , time : 38.78333854675293: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 65. Validation. Loss: 4.051 , time : 2.0817434787750244: 100%|██████████| 475/475 [00:02<00:00, 224.17it/s]\n",
      "Epoch: 66. Train.      Loss: 2.622 , time : 38.76603555679321: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 66. Validation. Loss: 4.013 , time : 2.1214828491210938: 100%|██████████| 475/475 [00:02<00:00, 220.16it/s]\n",
      "Epoch: 67. Train.      Loss: 2.599 , time : 38.749507188797: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]   \n",
      "Epoch: 67. Validation. Loss: 4.031 , time : 2.1382131576538086: 100%|██████████| 475/475 [00:02<00:00, 218.52it/s]\n",
      "Epoch: 68. Train.      Loss: 2.580 , time : 38.43587517738342: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s] \n",
      "Epoch: 68. Validation. Loss: 4.041 , time : 2.1035959720611572: 100%|██████████| 475/475 [00:02<00:00, 222.00it/s]\n",
      "Epoch: 69. Train.      Loss: 2.556 , time : 38.73912215232849: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 69. Validation. Loss: 4.036 , time : 2.253338098526001: 100%|██████████| 475/475 [00:02<00:00, 207.48it/s] \n",
      "Epoch: 70. Train.      Loss: 2.541 , time : 38.516753911972046: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 70. Validation. Loss: 4.048 , time : 2.1849021911621094: 100%|██████████| 475/475 [00:02<00:00, 213.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16324... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>███▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>███▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>███▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.55596</td></tr><tr><td>Min_Val_Loss</td><td>3.97948</td></tr><tr><td>Val_Loss</td><td>4.03558</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deep-sweep-1</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/or93tqlc\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/or93tqlc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_162331-or93tqlc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f84ryq4d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f84ryq4d\" target=\"_blank\">vivid-sweep-2</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.565 , time : 38.383793354034424: 100%|██████████| 1898/1898 [00:38<00:00, 49.40it/s]\n",
      "Epoch: 0. Validation. Loss: 4.058 , time : 2.140249729156494: 100%|██████████| 475/475 [00:02<00:00, 218.22it/s] \n",
      "Epoch: 1. Train.      Loss: 2.501 , time : 38.652050256729126: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]\n",
      "Epoch: 1. Validation. Loss: 4.020 , time : 2.18166184425354: 100%|██████████| 475/475 [00:02<00:00, 214.14it/s]  \n",
      "Epoch: 2. Train.      Loss: 2.482 , time : 38.16562223434448: 100%|██████████| 1898/1898 [00:38<00:00, 49.68it/s] \n",
      "Epoch: 2. Validation. Loss: 4.061 , time : 2.192591905593872: 100%|██████████| 475/475 [00:02<00:00, 212.99it/s] \n",
      "Epoch: 3. Train.      Loss: 2.463 , time : 38.49025630950928: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 3. Validation. Loss: 4.103 , time : 2.126556873321533: 100%|██████████| 475/475 [00:02<00:00, 219.54it/s] \n",
      "Epoch: 4. Train.      Loss: 2.443 , time : 38.50503063201904: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 4. Validation. Loss: 4.104 , time : 2.17122220993042: 100%|██████████| 475/475 [00:02<00:00, 214.98it/s]  \n",
      "Epoch: 5. Train.      Loss: 2.428 , time : 38.30547499656677: 100%|██████████| 1898/1898 [00:38<00:00, 49.50it/s] \n",
      "Epoch: 5. Validation. Loss: 4.137 , time : 2.2431628704071045: 100%|██████████| 475/475 [00:02<00:00, 207.99it/s]\n",
      "Epoch: 6. Train.      Loss: 2.406 , time : 38.65551447868347: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 6. Validation. Loss: 4.105 , time : 2.094508647918701: 100%|██████████| 475/475 [00:02<00:00, 222.91it/s] \n",
      "Epoch: 7. Train.      Loss: 2.390 , time : 38.664775371551514: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]\n",
      "Epoch: 7. Validation. Loss: 4.166 , time : 2.100656509399414: 100%|██████████| 475/475 [00:02<00:00, 222.11it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25603... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▃▆▆█▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.40628</td></tr><tr><td>Min_Val_Loss</td><td>4.01994</td></tr><tr><td>Val_Loss</td><td>4.10521</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vivid-sweep-2</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f84ryq4d\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f84ryq4d</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_171139-f84ryq4d/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cowno91t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cowno91t\" target=\"_blank\">still-sweep-3</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.413 , time : 38.78126072883606: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 0. Validation. Loss: 4.105 , time : 2.1508078575134277: 100%|██████████| 475/475 [00:02<00:00, 217.03it/s]\n",
      "Epoch: 1. Train.      Loss: 2.358 , time : 38.60560917854309: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 1. Validation. Loss: 4.157 , time : 2.1391053199768066: 100%|██████████| 475/475 [00:02<00:00, 218.15it/s]\n",
      "Epoch: 2. Train.      Loss: 2.342 , time : 38.48851156234741: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 2. Validation. Loss: 4.187 , time : 2.1367242336273193: 100%|██████████| 475/475 [00:02<00:00, 218.53it/s]\n",
      "Epoch: 3. Train.      Loss: 2.322 , time : 38.662575483322144: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]\n",
      "Epoch: 3. Validation. Loss: 4.180 , time : 2.2167491912841797: 100%|██████████| 475/475 [00:02<00:00, 210.79it/s]\n",
      "Epoch: 4. Train.      Loss: 2.309 , time : 38.69529342651367: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 4. Validation. Loss: 4.192 , time : 2.098581314086914: 100%|██████████| 475/475 [00:02<00:00, 222.50it/s] \n",
      "Epoch: 5. Train.      Loss: 2.292 , time : 38.71537399291992: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 5. Validation. Loss: 4.176 , time : 2.136749505996704: 100%|██████████| 475/475 [00:02<00:00, 218.54it/s] \n",
      "Epoch: 6. Train.      Loss: 2.279 , time : 38.51072955131531: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 6. Validation. Loss: 4.210 , time : 2.1417171955108643: 100%|██████████| 475/475 [00:02<00:00, 218.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27123... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.29203</td></tr><tr><td>Min_Val_Loss</td><td>4.10539</td></tr><tr><td>Val_Loss</td><td>4.17619</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">still-sweep-3</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cowno91t\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cowno91t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_171719-cowno91t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fsroykdl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fsroykdl\" target=\"_blank\">genial-sweep-4</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.303 , time : 39.52732729911804: 100%|██████████| 1898/1898 [00:39<00:00, 47.97it/s] \n",
      "Epoch: 0. Validation. Loss: 4.222 , time : 2.1413490772247314: 100%|██████████| 475/475 [00:02<00:00, 217.79it/s]\n",
      "Epoch: 1. Train.      Loss: 2.249 , time : 38.46699261665344: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s] \n",
      "Epoch: 1. Validation. Loss: 4.260 , time : 2.1879448890686035: 100%|██████████| 475/475 [00:02<00:00, 213.36it/s]\n",
      "Epoch: 2. Train.      Loss: 2.233 , time : 38.69406867027283: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 2. Validation. Loss: 4.249 , time : 2.1856915950775146: 100%|██████████| 475/475 [00:02<00:00, 213.66it/s]\n",
      "Epoch: 3. Train.      Loss: 2.221 , time : 38.410900354385376: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s]\n",
      "Epoch: 3. Validation. Loss: 4.276 , time : 2.1696650981903076: 100%|██████████| 475/475 [00:02<00:00, 213.04it/s]\n",
      "Epoch: 4. Train.      Loss: 2.206 , time : 38.61185359954834: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 4. Validation. Loss: 4.273 , time : 2.156369924545288: 100%|██████████| 475/475 [00:02<00:00, 216.59it/s] \n",
      "Epoch: 5. Train.      Loss: 2.194 , time : 38.854944467544556: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s]\n",
      "Epoch: 5. Validation. Loss: 4.249 , time : 2.1253600120544434: 100%|██████████| 475/475 [00:02<00:00, 219.68it/s]\n",
      "Epoch: 6. Train.      Loss: 2.181 , time : 38.573967695236206: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 6. Validation. Loss: 4.304 , time : 2.0988783836364746: 100%|██████████| 475/475 [00:02<00:00, 222.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28445... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▆▅██▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.19352</td></tr><tr><td>Min_Val_Loss</td><td>4.22198</td></tr><tr><td>Val_Loss</td><td>4.2489</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-4</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fsroykdl\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fsroykdl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_172217-fsroykdl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wcie012t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wcie012t\" target=\"_blank\">elated-sweep-5</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.105 , time : 24.144459009170532: 100%|██████████| 1898/1898 [00:24<00:00, 78.49it/s]\n",
      "Epoch: 0. Validation. Loss: 4.246 , time : 2.142453193664551: 100%|██████████| 475/475 [00:02<00:00, 217.93it/s] \n",
      "Epoch: 1. Train.      Loss: 2.096 , time : 23.658748388290405: 100%|██████████| 1898/1898 [00:23<00:00, 80.10it/s]\n",
      "Epoch: 1. Validation. Loss: 4.251 , time : 2.235135793685913: 100%|██████████| 475/475 [00:02<00:00, 209.02it/s] \n",
      "Epoch: 2. Train.      Loss: 2.090 , time : 23.478140115737915: 100%|██████████| 1898/1898 [00:23<00:00, 80.71it/s]\n",
      "Epoch: 2. Validation. Loss: 4.250 , time : 2.1074111461639404: 100%|██████████| 475/475 [00:02<00:00, 221.34it/s]\n",
      "Epoch: 3. Train.      Loss: 2.088 , time : 23.625778198242188: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]\n",
      "Epoch: 3. Validation. Loss: 4.266 , time : 2.0790555477142334: 100%|██████████| 475/475 [00:02<00:00, 224.45it/s]\n",
      "Epoch: 4. Train.      Loss: 2.084 , time : 23.62453031539917: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s] \n",
      "Epoch: 4. Validation. Loss: 4.253 , time : 2.1564395427703857: 100%|██████████| 475/475 [00:02<00:00, 216.60it/s]\n",
      "Epoch: 5. Train.      Loss: 2.084 , time : 23.682081937789917: 100%|██████████| 1898/1898 [00:23<00:00, 80.01it/s]\n",
      "Epoch: 5. Validation. Loss: 4.258 , time : 2.071202278137207: 100%|██████████| 475/475 [00:02<00:00, 225.35it/s] \n",
      "Epoch: 6. Train.      Loss: 2.081 , time : 23.762246131896973: 100%|██████████| 1898/1898 [00:23<00:00, 79.75it/s]\n",
      "Epoch: 6. Validation. Loss: 4.275 , time : 2.2014882564544678: 100%|██████████| 475/475 [00:02<00:00, 212.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29775... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▃▃▁▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▃█▄▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.08358</td></tr><tr><td>Min_Val_Loss</td><td>4.24606</td></tr><tr><td>Val_Loss</td><td>4.25838</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-5</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wcie012t\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wcie012t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_172715-wcie012t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ngcovzu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ngcovzu\" target=\"_blank\">deep-sweep-6</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.081 , time : 23.818892240524292: 100%|██████████| 1898/1898 [00:23<00:00, 79.56it/s]\n",
      "Epoch: 0. Validation. Loss: 4.280 , time : 2.1194891929626465: 100%|██████████| 475/475 [00:02<00:00, 220.31it/s]\n",
      "Epoch: 1. Train.      Loss: 2.079 , time : 23.855327606201172: 100%|██████████| 1898/1898 [00:23<00:00, 79.44it/s]\n",
      "Epoch: 1. Validation. Loss: 4.281 , time : 2.1790707111358643: 100%|██████████| 475/475 [00:02<00:00, 214.35it/s]\n",
      "Epoch: 2. Train.      Loss: 2.077 , time : 23.614368200302124: 100%|██████████| 1898/1898 [00:23<00:00, 80.25it/s]\n",
      "Epoch: 2. Validation. Loss: 4.287 , time : 2.1904284954071045: 100%|██████████| 475/475 [00:02<00:00, 213.12it/s]\n",
      "Epoch: 3. Train.      Loss: 2.077 , time : 23.743573427200317: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 3. Validation. Loss: 4.272 , time : 2.1527962684631348: 100%|██████████| 475/475 [00:02<00:00, 214.80it/s]\n",
      "Epoch: 4. Train.      Loss: 2.076 , time : 23.580513954162598: 100%|██████████| 1898/1898 [00:23<00:00, 80.36it/s]\n",
      "Epoch: 4. Validation. Loss: 4.282 , time : 2.1395092010498047: 100%|██████████| 475/475 [00:02<00:00, 218.27it/s]\n",
      "Epoch: 5. Train.      Loss: 2.074 , time : 23.69730043411255: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s] \n",
      "Epoch: 5. Validation. Loss: 4.291 , time : 2.112748384475708: 100%|██████████| 475/475 [00:02<00:00, 221.01it/s] \n",
      "Epoch: 6. Train.      Loss: 2.074 , time : 23.572890520095825: 100%|██████████| 1898/1898 [00:23<00:00, 80.39it/s]\n",
      "Epoch: 6. Validation. Loss: 4.300 , time : 2.11246919631958: 100%|██████████| 475/475 [00:02<00:00, 221.03it/s]  \n",
      "Epoch: 7. Train.      Loss: 2.073 , time : 23.68907856941223: 100%|██████████| 1898/1898 [00:23<00:00, 79.99it/s] \n",
      "Epoch: 7. Validation. Loss: 4.308 , time : 2.08056902885437: 100%|██████████| 475/475 [00:02<00:00, 224.26it/s]  \n",
      "Epoch: 8. Train.      Loss: 2.072 , time : 23.515146017074585: 100%|██████████| 1898/1898 [00:23<00:00, 80.58it/s]\n",
      "Epoch: 8. Validation. Loss: 4.295 , time : 2.0840039253234863: 100%|██████████| 475/475 [00:02<00:00, 221.62it/s]\n",
      "Epoch: 9. Train.      Loss: 2.070 , time : 24.065528392791748: 100%|██████████| 1898/1898 [00:24<00:00, 78.66it/s]\n",
      "Epoch: 9. Validation. Loss: 4.298 , time : 2.187950849533081: 100%|██████████| 475/475 [00:02<00:00, 212.11it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30684... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▄▁▃▅▇█▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.07151</td></tr><tr><td>Min_Val_Loss</td><td>4.27199</td></tr><tr><td>Val_Loss</td><td>4.29532</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deep-sweep-6</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ngcovzu\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ngcovzu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_173029-2ngcovzu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 049b5s9t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/049b5s9t\" target=\"_blank\">helpful-sweep-7</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.069 , time : 23.952343702316284: 100%|██████████| 1898/1898 [00:23<00:00, 79.12it/s]\n",
      "Epoch: 0. Validation. Loss: 4.315 , time : 2.146549701690674: 100%|██████████| 475/475 [00:02<00:00, 217.38it/s] \n",
      "Epoch: 1. Train.      Loss: 2.069 , time : 23.636688947677612: 100%|██████████| 1898/1898 [00:23<00:00, 80.17it/s]\n",
      "Epoch: 1. Validation. Loss: 4.317 , time : 2.085012674331665: 100%|██████████| 475/475 [00:02<00:00, 223.87it/s] \n",
      "Epoch: 2. Train.      Loss: 2.068 , time : 23.79029607772827: 100%|██████████| 1898/1898 [00:23<00:00, 79.64it/s] \n",
      "Epoch: 2. Validation. Loss: 4.332 , time : 2.1336989402770996: 100%|██████████| 475/475 [00:02<00:00, 218.80it/s]\n",
      "Epoch: 3. Train.      Loss: 2.067 , time : 23.92648458480835: 100%|██████████| 1898/1898 [00:23<00:00, 79.20it/s] \n",
      "Epoch: 3. Validation. Loss: 4.312 , time : 2.14203143119812: 100%|██████████| 475/475 [00:02<00:00, 217.88it/s]  \n",
      "Epoch: 4. Train.      Loss: 2.066 , time : 23.707709312438965: 100%|██████████| 1898/1898 [00:23<00:00, 79.93it/s]\n",
      "Epoch: 4. Validation. Loss: 4.321 , time : 2.152601718902588: 100%|██████████| 475/475 [00:02<00:00, 216.94it/s] \n",
      "Epoch: 5. Train.      Loss: 2.065 , time : 23.62018632888794: 100%|██████████| 1898/1898 [00:23<00:00, 80.23it/s] \n",
      "Epoch: 5. Validation. Loss: 4.332 , time : 2.129896640777588: 100%|██████████| 475/475 [00:02<00:00, 219.17it/s] \n",
      "Epoch: 6. Train.      Loss: 2.064 , time : 23.48484706878662: 100%|██████████| 1898/1898 [00:23<00:00, 80.69it/s] \n",
      "Epoch: 6. Validation. Loss: 4.321 , time : 2.1599693298339844: 100%|██████████| 475/475 [00:02<00:00, 216.06it/s]\n",
      "Epoch: 7. Train.      Loss: 2.063 , time : 23.720558881759644: 100%|██████████| 1898/1898 [00:23<00:00, 79.89it/s]\n",
      "Epoch: 7. Validation. Loss: 4.329 , time : 2.1025710105895996: 100%|██████████| 475/475 [00:02<00:00, 221.85it/s]\n",
      "Epoch: 8. Train.      Loss: 2.062 , time : 23.666929960250854: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]\n",
      "Epoch: 8. Validation. Loss: 4.333 , time : 2.1130645275115967: 100%|██████████| 475/475 [00:02<00:00, 220.96it/s]\n",
      "Epoch: 9. Train.      Loss: 2.062 , time : 24.04168200492859: 100%|██████████| 1898/1898 [00:24<00:00, 78.82it/s] \n",
      "Epoch: 9. Validation. Loss: 4.347 , time : 2.185816764831543: 100%|██████████| 475/475 [00:02<00:00, 213.54it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31915... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▆▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▃█▁▄█▄▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.06186</td></tr><tr><td>Min_Val_Loss</td><td>4.31184</td></tr><tr><td>Val_Loss</td><td>4.33332</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">helpful-sweep-7</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/049b5s9t\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/049b5s9t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_173501-049b5s9t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8j2wv5rd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8j2wv5rd\" target=\"_blank\">fine-sweep-8</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.060 , time : 23.72771120071411: 100%|██████████| 1898/1898 [00:23<00:00, 79.86it/s] \n",
      "Epoch: 0. Validation. Loss: 4.344 , time : 2.1821112632751465: 100%|██████████| 475/475 [00:02<00:00, 213.91it/s]\n",
      "Epoch: 1. Train.      Loss: 2.060 , time : 23.736586809158325: 100%|██████████| 1898/1898 [00:23<00:00, 79.83it/s]\n",
      "Epoch: 1. Validation. Loss: 4.343 , time : 2.113008975982666: 100%|██████████| 475/475 [00:02<00:00, 220.61it/s] \n",
      "Epoch: 2. Train.      Loss: 2.059 , time : 23.551406621932983: 100%|██████████| 1898/1898 [00:23<00:00, 80.46it/s]\n",
      "Epoch: 2. Validation. Loss: 4.335 , time : 2.1302239894866943: 100%|██████████| 475/475 [00:02<00:00, 219.14it/s]\n",
      "Epoch: 3. Train.      Loss: 2.058 , time : 23.678178548812866: 100%|██████████| 1898/1898 [00:23<00:00, 80.03it/s]\n",
      "Epoch: 3. Validation. Loss: 4.350 , time : 2.1998813152313232: 100%|██████████| 475/475 [00:02<00:00, 212.18it/s]\n",
      "Epoch: 4. Train.      Loss: 2.058 , time : 23.69938611984253: 100%|██████████| 1898/1898 [00:23<00:00, 79.95it/s] \n",
      "Epoch: 4. Validation. Loss: 4.353 , time : 2.0694799423217773: 100%|██████████| 475/475 [00:02<00:00, 225.49it/s]\n",
      "Epoch: 5. Train.      Loss: 2.057 , time : 23.80892252922058: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s] \n",
      "Epoch: 5. Validation. Loss: 4.362 , time : 2.2575795650482178: 100%|██████████| 475/475 [00:02<00:00, 207.03it/s]\n",
      "Epoch: 6. Train.      Loss: 2.056 , time : 23.757749795913696: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s]\n",
      "Epoch: 6. Validation. Loss: 4.373 , time : 2.1159725189208984: 100%|██████████| 475/475 [00:02<00:00, 220.62it/s]\n",
      "Epoch: 7. Train.      Loss: 2.054 , time : 23.471157789230347: 100%|██████████| 1898/1898 [00:23<00:00, 80.68it/s]\n",
      "Epoch: 7. Validation. Loss: 4.350 , time : 2.1875391006469727: 100%|██████████| 475/475 [00:02<00:00, 213.46it/s]\n",
      "Epoch: 8. Train.      Loss: 2.053 , time : 23.75558853149414: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s] \n",
      "Epoch: 8. Validation. Loss: 4.372 , time : 2.206984758377075: 100%|██████████| 475/475 [00:02<00:00, 211.66it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 757... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▅▅▄▃▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▁▄▄▆█▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.05445</td></tr><tr><td>Min_Val_Loss</td><td>4.33455</td></tr><tr><td>Val_Loss</td><td>4.34964</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fine-sweep-8</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8j2wv5rd\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8j2wv5rd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_173933-8j2wv5rd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bi2ocjmp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/bi2ocjmp\" target=\"_blank\">youthful-sweep-9</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.197 , time : 38.53751516342163: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 0. Validation. Loss: 6.242 , time : 2.160550355911255: 100%|██████████| 475/475 [00:02<00:00, 215.99it/s] \n",
      "Epoch: 1. Train.      Loss: 6.036 , time : 38.79369020462036: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 1. Validation. Loss: 6.210 , time : 2.1366047859191895: 100%|██████████| 475/475 [00:02<00:00, 218.36it/s]\n",
      "Epoch: 2. Train.      Loss: 5.956 , time : 38.0005304813385: 100%|██████████| 1898/1898 [00:38<00:00, 49.90it/s]  \n",
      "Epoch: 2. Validation. Loss: 6.144 , time : 2.2046144008636475: 100%|██████████| 475/475 [00:02<00:00, 211.71it/s]\n",
      "Epoch: 3. Train.      Loss: 5.847 , time : 38.604894161224365: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s]\n",
      "Epoch: 3. Validation. Loss: 6.029 , time : 2.221447706222534: 100%|██████████| 475/475 [00:02<00:00, 210.16it/s] \n",
      "Epoch: 4. Train.      Loss: 5.700 , time : 39.421210527420044: 100%|██████████| 1898/1898 [00:39<00:00, 48.10it/s]\n",
      "Epoch: 4. Validation. Loss: 5.906 , time : 2.15861439704895: 100%|██████████| 475/475 [00:02<00:00, 216.32it/s]  \n",
      "Epoch: 5. Train.      Loss: 5.531 , time : 38.6748571395874: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]  \n",
      "Epoch: 5. Validation. Loss: 5.766 , time : 2.2085163593292236: 100%|██████████| 475/475 [00:02<00:00, 210.21it/s]\n",
      "Epoch: 6. Train.      Loss: 5.359 , time : 38.77376317977905: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 6. Validation. Loss: 5.639 , time : 2.1927614212036133: 100%|██████████| 475/475 [00:02<00:00, 213.01it/s]\n",
      "Epoch: 7. Train.      Loss: 5.186 , time : 38.39565634727478: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 7. Validation. Loss: 5.486 , time : 2.147672176361084: 100%|██████████| 475/475 [00:02<00:00, 217.32it/s] \n",
      "Epoch: 8. Train.      Loss: 5.019 , time : 38.81397986412048: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 8. Validation. Loss: 5.333 , time : 2.1596710681915283: 100%|██████████| 475/475 [00:02<00:00, 216.21it/s]\n",
      "Epoch: 9. Train.      Loss: 4.863 , time : 38.95335555076599: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 9. Validation. Loss: 5.196 , time : 2.2136881351470947: 100%|██████████| 475/475 [00:02<00:00, 210.94it/s]\n",
      "Epoch: 10. Train.      Loss: 4.719 , time : 38.80183029174805: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 10. Validation. Loss: 5.087 , time : 2.160397529602051: 100%|██████████| 475/475 [00:02<00:00, 216.14it/s] \n",
      "Epoch: 11. Train.      Loss: 4.590 , time : 38.99441909790039: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 11. Validation. Loss: 4.958 , time : 2.1090009212493896: 100%|██████████| 475/475 [00:02<00:00, 221.36it/s]\n",
      "Epoch: 12. Train.      Loss: 4.474 , time : 38.64359450340271: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 12. Validation. Loss: 4.880 , time : 2.12070631980896: 100%|██████████| 475/475 [00:02<00:00, 220.08it/s]  \n",
      "Epoch: 13. Train.      Loss: 4.367 , time : 38.52888894081116: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 13. Validation. Loss: 4.786 , time : 2.119251012802124: 100%|██████████| 475/475 [00:02<00:00, 220.27it/s] \n",
      "Epoch: 14. Train.      Loss: 4.273 , time : 38.738805055618286: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s]\n",
      "Epoch: 14. Validation. Loss: 4.697 , time : 2.1025681495666504: 100%|██████████| 475/475 [00:02<00:00, 221.96it/s]\n",
      "Epoch: 15. Train.      Loss: 4.179 , time : 38.8089759349823: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s]  \n",
      "Epoch: 15. Validation. Loss: 4.649 , time : 2.1422767639160156: 100%|██████████| 475/475 [00:02<00:00, 217.99it/s]\n",
      "Epoch: 16. Train.      Loss: 4.097 , time : 38.651501178741455: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]\n",
      "Epoch: 16. Validation. Loss: 4.576 , time : 2.1579678058624268: 100%|██████████| 475/475 [00:02<00:00, 216.36it/s]\n",
      "Epoch: 17. Train.      Loss: 4.021 , time : 39.50507664680481: 100%|██████████| 1898/1898 [00:39<00:00, 48.00it/s] \n",
      "Epoch: 17. Validation. Loss: 4.542 , time : 2.148138999938965: 100%|██████████| 475/475 [00:02<00:00, 217.30it/s] \n",
      "Epoch: 18. Train.      Loss: 3.947 , time : 38.371694803237915: 100%|██████████| 1898/1898 [00:38<00:00, 49.41it/s]\n",
      "Epoch: 18. Validation. Loss: 4.467 , time : 2.1488516330718994: 100%|██████████| 475/475 [00:02<00:00, 217.30it/s]\n",
      "Epoch: 19. Train.      Loss: 3.875 , time : 38.63260459899902: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 19. Validation. Loss: 4.423 , time : 2.2075369358062744: 100%|██████████| 475/475 [00:02<00:00, 211.61it/s]\n",
      "Epoch: 20. Train.      Loss: 3.807 , time : 38.534902572631836: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]\n",
      "Epoch: 20. Validation. Loss: 4.399 , time : 2.151944637298584: 100%|██████████| 475/475 [00:02<00:00, 216.97it/s] \n",
      "Epoch: 21. Train.      Loss: 3.747 , time : 38.940523624420166: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s]\n",
      "Epoch: 21. Validation. Loss: 4.335 , time : 2.1239376068115234: 100%|██████████| 475/475 [00:02<00:00, 219.73it/s]\n",
      "Epoch: 22. Train.      Loss: 3.688 , time : 38.720715284347534: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 22. Validation. Loss: 4.279 , time : 2.167454719543457: 100%|██████████| 475/475 [00:02<00:00, 215.49it/s] \n",
      "Epoch: 23. Train.      Loss: 3.628 , time : 38.75346302986145: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 23. Validation. Loss: 4.271 , time : 2.078200101852417: 100%|██████████| 475/475 [00:02<00:00, 224.23it/s] \n",
      "Epoch: 24. Train.      Loss: 3.572 , time : 38.684940576553345: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s]\n",
      "Epoch: 24. Validation. Loss: 4.230 , time : 2.122750997543335: 100%|██████████| 475/475 [00:02<00:00, 219.92it/s] \n",
      "Epoch: 25. Train.      Loss: 3.524 , time : 38.71831727027893: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 25. Validation. Loss: 4.200 , time : 2.1569690704345703: 100%|██████████| 475/475 [00:02<00:00, 216.49it/s]\n",
      "Epoch: 26. Train.      Loss: 3.473 , time : 38.69858741760254: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 26. Validation. Loss: 4.169 , time : 2.1252706050872803: 100%|██████████| 475/475 [00:02<00:00, 219.72it/s]\n",
      "Epoch: 27. Train.      Loss: 3.424 , time : 38.72749423980713: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 27. Validation. Loss: 4.131 , time : 2.165138006210327: 100%|██████████| 475/475 [00:02<00:00, 215.49it/s] \n",
      "Epoch: 28. Train.      Loss: 3.376 , time : 38.77654695510864: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 28. Validation. Loss: 4.095 , time : 2.1407594680786133: 100%|██████████| 475/475 [00:02<00:00, 217.72it/s]\n",
      "Epoch: 29. Train.      Loss: 3.329 , time : 38.636205434799194: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s]\n",
      "Epoch: 29. Validation. Loss: 4.076 , time : 2.1172430515289307: 100%|██████████| 475/475 [00:02<00:00, 218.62it/s]\n",
      "Epoch: 30. Train.      Loss: 3.287 , time : 38.77167105674744: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 30. Validation. Loss: 4.047 , time : 2.1940598487854004: 100%|██████████| 475/475 [00:02<00:00, 212.76it/s]\n",
      "Epoch: 31. Train.      Loss: 3.246 , time : 38.78886532783508: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 31. Validation. Loss: 4.022 , time : 2.155226707458496: 100%|██████████| 475/475 [00:02<00:00, 216.65it/s] \n",
      "Epoch: 32. Train.      Loss: 3.201 , time : 38.95027017593384: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 32. Validation. Loss: 4.008 , time : 2.1773862838745117: 100%|██████████| 475/475 [00:02<00:00, 214.48it/s]\n",
      "Epoch: 33. Train.      Loss: 3.159 , time : 38.39859390258789: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 33. Validation. Loss: 3.979 , time : 2.0882046222686768: 100%|██████████| 475/475 [00:02<00:00, 223.51it/s]\n",
      "Epoch: 34. Train.      Loss: 3.123 , time : 38.95521402359009: 100%|██████████| 1898/1898 [00:38<00:00, 48.67it/s] \n",
      "Epoch: 34. Validation. Loss: 3.969 , time : 2.2057738304138184: 100%|██████████| 475/475 [00:02<00:00, 211.76it/s]\n",
      "Epoch: 35. Train.      Loss: 3.084 , time : 38.62070107460022: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 35. Validation. Loss: 3.939 , time : 2.2008674144744873: 100%|██████████| 475/475 [00:02<00:00, 212.28it/s]\n",
      "Epoch: 36. Train.      Loss: 3.052 , time : 38.7673978805542: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]  \n",
      "Epoch: 36. Validation. Loss: 3.902 , time : 2.166353225708008: 100%|██████████| 475/475 [00:02<00:00, 215.55it/s] \n",
      "Epoch: 37. Train.      Loss: 3.010 , time : 38.64775228500366: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 37. Validation. Loss: 3.904 , time : 2.2307801246643066: 100%|██████████| 475/475 [00:02<00:00, 209.30it/s]\n",
      "Epoch: 38. Train.      Loss: 2.981 , time : 38.80579876899719: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 38. Validation. Loss: 3.894 , time : 2.1550111770629883: 100%|██████████| 475/475 [00:02<00:00, 216.69it/s]\n",
      "Epoch: 39. Train.      Loss: 2.944 , time : 38.899274826049805: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 39. Validation. Loss: 3.867 , time : 2.205476999282837: 100%|██████████| 475/475 [00:02<00:00, 211.81it/s] \n",
      "Epoch: 40. Train.      Loss: 2.912 , time : 38.820308685302734: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]\n",
      "Epoch: 40. Validation. Loss: 3.856 , time : 2.169013500213623: 100%|██████████| 475/475 [00:02<00:00, 215.26it/s] \n",
      "Epoch: 41. Train.      Loss: 2.881 , time : 38.48949337005615: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 41. Validation. Loss: 3.862 , time : 2.1744487285614014: 100%|██████████| 475/475 [00:02<00:00, 214.78it/s]\n",
      "Epoch: 42. Train.      Loss: 2.850 , time : 38.43832206726074: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s] \n",
      "Epoch: 42. Validation. Loss: 3.831 , time : 2.1467809677124023: 100%|██████████| 475/475 [00:02<00:00, 217.50it/s]\n",
      "Epoch: 43. Train.      Loss: 2.817 , time : 38.96117544174194: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 43. Validation. Loss: 3.810 , time : 2.1435019969940186: 100%|██████████| 475/475 [00:02<00:00, 217.77it/s]\n",
      "Epoch: 44. Train.      Loss: 2.789 , time : 38.91961336135864: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 44. Validation. Loss: 3.808 , time : 2.145493507385254: 100%|██████████| 475/475 [00:02<00:00, 217.59it/s] \n",
      "Epoch: 45. Train.      Loss: 2.760 , time : 38.68391251564026: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 45. Validation. Loss: 3.775 , time : 2.187037467956543: 100%|██████████| 475/475 [00:02<00:00, 213.57it/s] \n",
      "Epoch: 46. Train.      Loss: 2.732 , time : 38.94732475280762: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 46. Validation. Loss: 3.789 , time : 2.1172122955322266: 100%|██████████| 475/475 [00:02<00:00, 220.42it/s]\n",
      "Epoch: 47. Train.      Loss: 2.705 , time : 39.035053730010986: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s]\n",
      "Epoch: 47. Validation. Loss: 3.795 , time : 2.2093536853790283: 100%|██████████| 475/475 [00:02<00:00, 211.46it/s]\n",
      "Epoch: 48. Train.      Loss: 2.677 , time : 38.41970729827881: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s] \n",
      "Epoch: 48. Validation. Loss: 3.733 , time : 2.12493634223938: 100%|██████████| 475/475 [00:02<00:00, 219.60it/s]  \n",
      "Epoch: 49. Train.      Loss: 2.650 , time : 38.30813002586365: 100%|██████████| 1898/1898 [00:38<00:00, 49.49it/s] \n",
      "Epoch: 49. Validation. Loss: 3.730 , time : 2.184941530227661: 100%|██████████| 475/475 [00:02<00:00, 213.60it/s] \n",
      "Epoch: 50. Train.      Loss: 2.626 , time : 38.862765312194824: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s]\n",
      "Epoch: 50. Validation. Loss: 3.744 , time : 2.1330759525299072: 100%|██████████| 475/475 [00:02<00:00, 218.68it/s]\n",
      "Epoch: 51. Train.      Loss: 2.602 , time : 38.84641242027283: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s] \n",
      "Epoch: 51. Validation. Loss: 3.696 , time : 2.22465443611145: 100%|██████████| 475/475 [00:02<00:00, 209.95it/s]  \n",
      "Epoch: 52. Train.      Loss: 2.575 , time : 38.98894190788269: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 52. Validation. Loss: 3.702 , time : 2.1338181495666504: 100%|██████████| 475/475 [00:02<00:00, 218.63it/s]\n",
      "Epoch: 53. Train.      Loss: 2.550 , time : 38.52669858932495: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 53. Validation. Loss: 3.711 , time : 2.1685683727264404: 100%|██████████| 475/475 [00:02<00:00, 215.37it/s]\n",
      "Epoch: 54. Train.      Loss: 2.528 , time : 38.45918846130371: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 54. Validation. Loss: 3.697 , time : 2.131052017211914: 100%|██████████| 475/475 [00:02<00:00, 219.01it/s] \n",
      "Epoch: 55. Train.      Loss: 2.506 , time : 38.42206931114197: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s] \n",
      "Epoch: 55. Validation. Loss: 3.678 , time : 2.104044198989868: 100%|██████████| 475/475 [00:02<00:00, 221.87it/s] \n",
      "Epoch: 56. Train.      Loss: 2.484 , time : 38.89679026603699: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s] \n",
      "Epoch: 56. Validation. Loss: 3.688 , time : 2.2063519954681396: 100%|██████████| 475/475 [00:02<00:00, 211.71it/s]\n",
      "Epoch: 57. Train.      Loss: 2.461 , time : 38.523606300354004: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s]\n",
      "Epoch: 57. Validation. Loss: 3.688 , time : 2.1654417514801025: 100%|██████████| 475/475 [00:02<00:00, 214.38it/s]\n",
      "Epoch: 58. Train.      Loss: 2.437 , time : 39.03729724884033: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s] \n",
      "Epoch: 58. Validation. Loss: 3.689 , time : 2.179163694381714: 100%|██████████| 475/475 [00:02<00:00, 214.32it/s] \n",
      "Epoch: 59. Train.      Loss: 2.417 , time : 38.61319065093994: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 59. Validation. Loss: 3.657 , time : 2.156733989715576: 100%|██████████| 475/475 [00:02<00:00, 216.50it/s] \n",
      "Epoch: 60. Train.      Loss: 2.397 , time : 38.985124349594116: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s]\n",
      "Epoch: 60. Validation. Loss: 3.653 , time : 2.1941299438476562: 100%|██████████| 475/475 [00:02<00:00, 212.74it/s]\n",
      "Epoch: 61. Train.      Loss: 2.377 , time : 38.75198459625244: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 61. Validation. Loss: 3.643 , time : 2.0890955924987793: 100%|██████████| 475/475 [00:02<00:00, 223.40it/s]\n",
      "Epoch: 62. Train.      Loss: 2.358 , time : 38.89133286476135: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 62. Validation. Loss: 3.664 , time : 2.164088726043701: 100%|██████████| 475/475 [00:02<00:00, 215.66it/s] \n",
      "Epoch: 63. Train.      Loss: 2.337 , time : 38.27702713012695: 100%|██████████| 1898/1898 [00:38<00:00, 49.54it/s] \n",
      "Epoch: 63. Validation. Loss: 3.642 , time : 2.1473350524902344: 100%|██████████| 475/475 [00:02<00:00, 217.27it/s]\n",
      "Epoch: 64. Train.      Loss: 2.317 , time : 38.99727416038513: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s] \n",
      "Epoch: 64. Validation. Loss: 3.632 , time : 2.101170301437378: 100%|██████████| 475/475 [00:02<00:00, 222.12it/s] \n",
      "Epoch: 65. Train.      Loss: 2.299 , time : 38.614805936813354: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s]\n",
      "Epoch: 65. Validation. Loss: 3.631 , time : 2.09853196144104: 100%|██████████| 475/475 [00:02<00:00, 222.42it/s]  \n",
      "Epoch: 66. Train.      Loss: 2.281 , time : 38.35851287841797: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 66. Validation. Loss: 3.643 , time : 2.12431263923645: 100%|██████████| 475/475 [00:02<00:00, 219.69it/s]  \n",
      "Epoch: 67. Train.      Loss: 2.261 , time : 38.751583099365234: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]\n",
      "Epoch: 67. Validation. Loss: 3.641 , time : 2.1243622303009033: 100%|██████████| 475/475 [00:02<00:00, 219.76it/s]\n",
      "Epoch: 68. Train.      Loss: 2.242 , time : 38.71771860122681: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 68. Validation. Loss: 3.628 , time : 2.200038194656372: 100%|██████████| 475/475 [00:02<00:00, 212.32it/s] \n",
      "Epoch: 69. Train.      Loss: 2.225 , time : 38.55502367019653: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 69. Validation. Loss: 3.625 , time : 2.0939383506774902: 100%|██████████| 475/475 [00:02<00:00, 221.24it/s]\n",
      "Epoch: 70. Train.      Loss: 2.205 , time : 38.499998569488525: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 70. Validation. Loss: 3.615 , time : 2.184030055999756: 100%|██████████| 475/475 [00:02<00:00, 213.88it/s] \n",
      "Epoch: 71. Train.      Loss: 2.191 , time : 38.69060945510864: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 71. Validation. Loss: 3.646 , time : 2.1869871616363525: 100%|██████████| 475/475 [00:02<00:00, 213.57it/s]\n",
      "Epoch: 72. Train.      Loss: 2.174 , time : 38.65821409225464: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 72. Validation. Loss: 3.642 , time : 2.168017625808716: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s] \n",
      "Epoch: 73. Train.      Loss: 2.158 , time : 38.608447790145874: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]\n",
      "Epoch: 73. Validation. Loss: 3.605 , time : 2.143479824066162: 100%|██████████| 475/475 [00:02<00:00, 217.68it/s] \n",
      "Epoch: 74. Train.      Loss: 2.136 , time : 38.67557144165039: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s] \n",
      "Epoch: 74. Validation. Loss: 3.625 , time : 2.1032748222351074: 100%|██████████| 475/475 [00:02<00:00, 221.95it/s]\n",
      "Epoch: 75. Train.      Loss: 2.124 , time : 38.5778272151947: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]  \n",
      "Epoch: 75. Validation. Loss: 3.604 , time : 2.086472511291504: 100%|██████████| 475/475 [00:02<00:00, 223.50it/s] \n",
      "Epoch: 76. Train.      Loss: 2.105 , time : 38.137752532958984: 100%|██████████| 1898/1898 [00:38<00:00, 49.72it/s]\n",
      "Epoch: 76. Validation. Loss: 3.620 , time : 2.1463048458099365: 100%|██████████| 475/475 [00:02<00:00, 217.53it/s]\n",
      "Epoch: 77. Train.      Loss: 2.091 , time : 38.49089980125427: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 77. Validation. Loss: 3.599 , time : 2.1344892978668213: 100%|██████████| 475/475 [00:02<00:00, 218.73it/s]\n",
      "Epoch: 78. Train.      Loss: 2.073 , time : 38.50430083274841: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 78. Validation. Loss: 3.620 , time : 2.1265642642974854: 100%|██████████| 475/475 [00:02<00:00, 219.50it/s]\n",
      "Epoch: 79. Train.      Loss: 2.060 , time : 38.506842374801636: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s]\n",
      "Epoch: 79. Validation. Loss: 3.611 , time : 2.158907890319824: 100%|██████████| 475/475 [00:02<00:00, 216.13it/s] \n",
      "Epoch: 80. Train.      Loss: 2.042 , time : 38.52191424369812: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 80. Validation. Loss: 3.611 , time : 2.1522037982940674: 100%|██████████| 475/475 [00:02<00:00, 216.97it/s]\n",
      "Epoch: 81. Train.      Loss: 2.027 , time : 38.45826578140259: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 81. Validation. Loss: 3.604 , time : 2.1893277168273926: 100%|██████████| 475/475 [00:02<00:00, 213.31it/s]\n",
      "Epoch: 82. Train.      Loss: 2.015 , time : 38.489192962646484: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s]\n",
      "Epoch: 82. Validation. Loss: 3.615 , time : 2.1647915840148926: 100%|██████████| 475/475 [00:02<00:00, 215.67it/s]\n",
      "Epoch: 83. Train.      Loss: 1.999 , time : 38.277525424957275: 100%|██████████| 1898/1898 [00:38<00:00, 49.53it/s]\n",
      "Epoch: 83. Validation. Loss: 3.613 , time : 2.099385976791382: 100%|██████████| 475/475 [00:02<00:00, 222.23it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1982... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.0154</td></tr><tr><td>Min_Val_Loss</td><td>3.59881</td></tr><tr><td>Val_Loss</td><td>3.61528</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">youthful-sweep-9</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/bi2ocjmp\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/bi2ocjmp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_174339-bi2ocjmp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p5ddm3ai with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/p5ddm3ai\" target=\"_blank\">spring-sweep-10</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.019 , time : 38.572548627853394: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s]\n",
      "Epoch: 0. Validation. Loss: 3.618 , time : 2.2067418098449707: 100%|██████████| 475/475 [00:02<00:00, 211.69it/s]\n",
      "Epoch: 1. Train.      Loss: 1.972 , time : 38.470842123031616: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]\n",
      "Epoch: 1. Validation. Loss: 3.608 , time : 2.172553062438965: 100%|██████████| 475/475 [00:02<00:00, 214.95it/s] \n",
      "Epoch: 2. Train.      Loss: 1.960 , time : 38.179542779922485: 100%|██████████| 1898/1898 [00:38<00:00, 49.66it/s]\n",
      "Epoch: 2. Validation. Loss: 3.616 , time : 2.1194727420806885: 100%|██████████| 475/475 [00:02<00:00, 219.71it/s]\n",
      "Epoch: 3. Train.      Loss: 1.945 , time : 38.97033905982971: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 3. Validation. Loss: 3.604 , time : 2.1663455963134766: 100%|██████████| 475/475 [00:02<00:00, 213.59it/s]\n",
      "Epoch: 4. Train.      Loss: 1.931 , time : 38.91031742095947: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 4. Validation. Loss: 3.600 , time : 2.226714611053467: 100%|██████████| 475/475 [00:02<00:00, 209.71it/s] \n",
      "Epoch: 5. Train.      Loss: 1.916 , time : 38.25406336784363: 100%|██████████| 1898/1898 [00:38<00:00, 49.56it/s] \n",
      "Epoch: 5. Validation. Loss: 3.624 , time : 2.1210720539093018: 100%|██████████| 475/475 [00:02<00:00, 220.01it/s]\n",
      "Epoch: 6. Train.      Loss: 1.903 , time : 38.94263529777527: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 6. Validation. Loss: 3.607 , time : 2.150639533996582: 100%|██████████| 475/475 [00:02<00:00, 217.08it/s] \n",
      "Epoch: 7. Train.      Loss: 1.889 , time : 38.805803060531616: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s]\n",
      "Epoch: 7. Validation. Loss: 3.618 , time : 2.1052355766296387: 100%|██████████| 475/475 [00:02<00:00, 221.69it/s]\n",
      "Epoch: 8. Train.      Loss: 1.873 , time : 38.81249761581421: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 8. Validation. Loss: 3.632 , time : 2.1326215267181396: 100%|██████████| 475/475 [00:02<00:00, 218.90it/s]\n",
      "Epoch: 9. Train.      Loss: 1.862 , time : 38.54443717002869: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 9. Validation. Loss: 3.602 , time : 2.1656112670898438: 100%|██████████| 475/475 [00:02<00:00, 215.50it/s]\n",
      "Epoch: 10. Train.      Loss: 1.851 , time : 38.55440330505371: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 10. Validation. Loss: 3.608 , time : 2.126622200012207: 100%|██████████| 475/475 [00:02<00:00, 219.53it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16946... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▄▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▃▅▂▁▆▃▅█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.86217</td></tr><tr><td>Min_Val_Loss</td><td>3.5998</td></tr><tr><td>Val_Loss</td><td>3.60199</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-10</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/p5ddm3ai\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/p5ddm3ai</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_184107-p5ddm3ai/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: frp791wk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/frp791wk\" target=\"_blank\">copper-sweep-11</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.871 , time : 38.804728507995605: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s]\n",
      "Epoch: 0. Validation. Loss: 3.612 , time : 2.172003984451294: 100%|██████████| 475/475 [00:02<00:00, 215.05it/s] \n",
      "Epoch: 1. Train.      Loss: 1.830 , time : 38.51469302177429: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s] \n",
      "Epoch: 1. Validation. Loss: 3.631 , time : 2.2120423316955566: 100%|██████████| 475/475 [00:02<00:00, 210.21it/s]\n",
      "Epoch: 2. Train.      Loss: 1.814 , time : 38.60227942466736: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 2. Validation. Loss: 3.624 , time : 2.187204122543335: 100%|██████████| 475/475 [00:02<00:00, 213.40it/s] \n",
      "Epoch: 3. Train.      Loss: 1.803 , time : 38.47848558425903: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 3. Validation. Loss: 3.633 , time : 2.1412296295166016: 100%|██████████| 475/475 [00:02<00:00, 217.79it/s]\n",
      "Epoch: 4. Train.      Loss: 1.794 , time : 38.67041301727295: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 4. Validation. Loss: 3.621 , time : 2.21146821975708: 100%|██████████| 475/475 [00:02<00:00, 210.68it/s]  \n",
      "Epoch: 5. Train.      Loss: 1.779 , time : 39.19663333892822: 100%|██████████| 1898/1898 [00:39<00:00, 48.37it/s] \n",
      "Epoch: 5. Validation. Loss: 3.658 , time : 2.181147336959839: 100%|██████████| 475/475 [00:02<00:00, 214.04it/s] \n",
      "Epoch: 6. Train.      Loss: 1.769 , time : 38.91282606124878: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 6. Validation. Loss: 3.618 , time : 2.2131173610687256: 100%|██████████| 475/475 [00:02<00:00, 210.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18964... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄▃▄▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.77935</td></tr><tr><td>Min_Val_Loss</td><td>3.61165</td></tr><tr><td>Val_Loss</td><td>3.65797</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">copper-sweep-11</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/frp791wk\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/frp791wk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_184852-frp791wk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sqc18cr0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/sqc18cr0\" target=\"_blank\">playful-sweep-12</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.791 , time : 38.27189874649048: 100%|██████████| 1898/1898 [00:38<00:00, 49.54it/s] \n",
      "Epoch: 0. Validation. Loss: 3.631 , time : 2.1864089965820312: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s]\n",
      "Epoch: 1. Train.      Loss: 1.751 , time : 38.77793765068054: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 1. Validation. Loss: 3.635 , time : 2.1877055168151855: 100%|██████████| 475/475 [00:02<00:00, 213.41it/s]\n",
      "Epoch: 2. Train.      Loss: 1.737 , time : 38.80907964706421: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 2. Validation. Loss: 3.637 , time : 2.2027289867401123: 100%|██████████| 475/475 [00:02<00:00, 212.02it/s]\n",
      "Epoch: 3. Train.      Loss: 1.727 , time : 38.80085897445679: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 3. Validation. Loss: 3.639 , time : 2.263441562652588: 100%|██████████| 475/475 [00:02<00:00, 206.22it/s] \n",
      "Epoch: 4. Train.      Loss: 1.718 , time : 38.34078359603882: 100%|██████████| 1898/1898 [00:38<00:00, 49.45it/s] \n",
      "Epoch: 4. Validation. Loss: 3.631 , time : 2.1366286277770996: 100%|██████████| 475/475 [00:02<00:00, 218.44it/s]\n",
      "Epoch: 5. Train.      Loss: 1.708 , time : 38.812071800231934: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s]\n",
      "Epoch: 5. Validation. Loss: 3.630 , time : 2.2024450302124023: 100%|██████████| 475/475 [00:02<00:00, 211.84it/s]\n",
      "Epoch: 6. Train.      Loss: 1.697 , time : 38.68337869644165: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 6. Validation. Loss: 3.650 , time : 2.1819162368774414: 100%|██████████| 475/475 [00:02<00:00, 213.93it/s]\n",
      "Epoch: 7. Train.      Loss: 1.689 , time : 38.413291692733765: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s]\n",
      "Epoch: 7. Validation. Loss: 3.654 , time : 2.140434503555298: 100%|██████████| 475/475 [00:02<00:00, 218.05it/s] \n",
      "Epoch: 8. Train.      Loss: 1.678 , time : 38.525980710983276: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]\n",
      "Epoch: 8. Validation. Loss: 3.667 , time : 2.2267568111419678: 100%|██████████| 475/475 [00:02<00:00, 209.76it/s]\n",
      "Epoch: 9. Train.      Loss: 1.667 , time : 38.23214101791382: 100%|██████████| 1898/1898 [00:38<00:00, 49.59it/s] \n",
      "Epoch: 9. Validation. Loss: 3.657 , time : 2.167687177658081: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s] \n",
      "Epoch: 10. Train.      Loss: 1.659 , time : 39.0916109085083: 100%|██████████| 1898/1898 [00:39<00:00, 48.50it/s]  \n",
      "Epoch: 10. Validation. Loss: 3.633 , time : 2.1348226070404053: 100%|██████████| 475/475 [00:02<00:00, 217.15it/s]\n",
      "Epoch: 11. Train.      Loss: 1.650 , time : 38.455909729003906: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]\n",
      "Epoch: 11. Validation. Loss: 3.632 , time : 2.1570191383361816: 100%|██████████| 475/475 [00:02<00:00, 216.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20285... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▄▃▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>████▅▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▂▃▁▁▅▆█▆▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.65853</td></tr><tr><td>Min_Val_Loss</td><td>3.62979</td></tr><tr><td>Val_Loss</td><td>3.6325</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-12</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/sqc18cr0\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/sqc18cr0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_185350-sqc18cr0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tkghrljq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/tkghrljq\" target=\"_blank\">clean-sweep-13</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.574 , time : 23.768721103668213: 100%|██████████| 1898/1898 [00:23<00:00, 79.72it/s]\n",
      "Epoch: 0. Validation. Loss: 3.627 , time : 2.1398582458496094: 100%|██████████| 475/475 [00:02<00:00, 218.09it/s]\n",
      "Epoch: 1. Train.      Loss: 1.563 , time : 23.77276086807251: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s] \n",
      "Epoch: 1. Validation. Loss: 3.621 , time : 2.101642608642578: 100%|██████████| 475/475 [00:02<00:00, 222.02it/s] \n",
      "Epoch: 2. Train.      Loss: 1.558 , time : 23.57426953315735: 100%|██████████| 1898/1898 [00:23<00:00, 80.38it/s] \n",
      "Epoch: 2. Validation. Loss: 3.621 , time : 2.246814012527466: 100%|██████████| 475/475 [00:02<00:00, 207.41it/s] \n",
      "Epoch: 3. Train.      Loss: 1.553 , time : 23.836336612701416: 100%|██████████| 1898/1898 [00:23<00:00, 79.50it/s]\n",
      "Epoch: 3. Validation. Loss: 3.624 , time : 2.135331630706787: 100%|██████████| 475/475 [00:02<00:00, 218.55it/s] \n",
      "Epoch: 4. Train.      Loss: 1.550 , time : 23.697961807250977: 100%|██████████| 1898/1898 [00:23<00:00, 79.96it/s]\n",
      "Epoch: 4. Validation. Loss: 3.625 , time : 2.15922474861145: 100%|██████████| 475/475 [00:02<00:00, 216.10it/s]  \n",
      "Epoch: 5. Train.      Loss: 1.548 , time : 24.002230167388916: 100%|██████████| 1898/1898 [00:24<00:00, 78.95it/s]\n",
      "Epoch: 5. Validation. Loss: 3.626 , time : 2.2167510986328125: 100%|██████████| 475/475 [00:02<00:00, 210.65it/s]\n",
      "Epoch: 6. Train.      Loss: 1.547 , time : 23.85578465461731: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s] \n",
      "Epoch: 6. Validation. Loss: 3.629 , time : 2.119572401046753: 100%|██████████| 475/475 [00:02<00:00, 220.12it/s] \n",
      "Epoch: 7. Train.      Loss: 1.547 , time : 23.862903594970703: 100%|██████████| 1898/1898 [00:23<00:00, 79.41it/s]\n",
      "Epoch: 7. Validation. Loss: 3.629 , time : 2.097175359725952: 100%|██████████| 475/475 [00:02<00:00, 222.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22963... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▁▁▃▅▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.54706</td></tr><tr><td>Min_Val_Loss</td><td>3.62144</td></tr><tr><td>Val_Loss</td><td>3.6287</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">clean-sweep-13</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/tkghrljq\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/tkghrljq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_190422-tkghrljq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: je3v6rgl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je3v6rgl\" target=\"_blank\">drawn-sweep-14</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.545 , time : 23.766722679138184: 100%|██████████| 1898/1898 [00:23<00:00, 79.73it/s]\n",
      "Epoch: 0. Validation. Loss: 3.633 , time : 2.1616740226745605: 100%|██████████| 475/475 [00:02<00:00, 215.96it/s]\n",
      "Epoch: 1. Train.      Loss: 1.544 , time : 23.483468294143677: 100%|██████████| 1898/1898 [00:23<00:00, 80.68it/s]\n",
      "Epoch: 1. Validation. Loss: 3.632 , time : 2.152379274368286: 100%|██████████| 475/475 [00:02<00:00, 216.81it/s] \n",
      "Epoch: 2. Train.      Loss: 1.543 , time : 23.700311422348022: 100%|██████████| 1898/1898 [00:23<00:00, 79.95it/s]\n",
      "Epoch: 2. Validation. Loss: 3.628 , time : 2.162588357925415: 100%|██████████| 475/475 [00:02<00:00, 215.67it/s] \n",
      "Epoch: 3. Train.      Loss: 1.545 , time : 23.997551202774048: 100%|██████████| 1898/1898 [00:24<00:00, 78.96it/s]\n",
      "Epoch: 3. Validation. Loss: 3.634 , time : 2.208021640777588: 100%|██████████| 475/475 [00:02<00:00, 211.41it/s] \n",
      "Epoch: 4. Train.      Loss: 1.542 , time : 23.75750732421875: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s] \n",
      "Epoch: 4. Validation. Loss: 3.635 , time : 2.2069003582000732: 100%|██████████| 475/475 [00:02<00:00, 211.22it/s]\n",
      "Epoch: 5. Train.      Loss: 1.542 , time : 23.555338144302368: 100%|██████████| 1898/1898 [00:23<00:00, 80.44it/s]\n",
      "Epoch: 5. Validation. Loss: 3.633 , time : 2.108045816421509: 100%|██████████| 475/475 [00:02<00:00, 221.08it/s] \n",
      "Epoch: 6. Train.      Loss: 1.541 , time : 24.00252890586853: 100%|██████████| 1898/1898 [00:24<00:00, 78.95it/s] \n",
      "Epoch: 6. Validation. Loss: 3.631 , time : 2.1310713291168213: 100%|██████████| 475/475 [00:02<00:00, 218.94it/s]\n",
      "Epoch: 7. Train.      Loss: 1.539 , time : 23.61507749557495: 100%|██████████| 1898/1898 [00:23<00:00, 80.22it/s] \n",
      "Epoch: 7. Validation. Loss: 3.634 , time : 2.1449360847473145: 100%|██████████| 475/475 [00:02<00:00, 217.39it/s]\n",
      "Epoch: 8. Train.      Loss: 1.539 , time : 23.87717342376709: 100%|██████████| 1898/1898 [00:23<00:00, 79.28it/s] \n",
      "Epoch: 8. Validation. Loss: 3.633 , time : 2.1527931690216064: 100%|██████████| 475/475 [00:02<00:00, 216.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24615... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆█▄▄▃▁</td></tr><tr><td>Min_Val_Loss</td><td>█▆▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▄▁▇█▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.53924</td></tr><tr><td>Min_Val_Loss</td><td>3.62792</td></tr><tr><td>Val_Loss</td><td>3.63359</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">drawn-sweep-14</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je3v6rgl\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je3v6rgl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_191012-je3v6rgl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cvpwyl3m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cvpwyl3m\" target=\"_blank\">solar-sweep-15</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.538 , time : 23.374143362045288: 100%|██████████| 1898/1898 [00:23<00:00, 81.07it/s]\n",
      "Epoch: 0. Validation. Loss: 3.644 , time : 2.1655805110931396: 100%|██████████| 475/475 [00:02<00:00, 215.44it/s]\n",
      "Epoch: 1. Train.      Loss: 1.538 , time : 23.70544743537903: 100%|██████████| 1898/1898 [00:23<00:00, 79.94it/s] \n",
      "Epoch: 1. Validation. Loss: 3.646 , time : 2.1521847248077393: 100%|██████████| 475/475 [00:02<00:00, 216.86it/s]\n",
      "Epoch: 2. Train.      Loss: 1.538 , time : 23.81215214729309: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s] \n",
      "Epoch: 2. Validation. Loss: 3.644 , time : 2.142031669616699: 100%|██████████| 475/475 [00:02<00:00, 217.89it/s] \n",
      "Epoch: 3. Train.      Loss: 1.537 , time : 23.58438277244568: 100%|██████████| 1898/1898 [00:23<00:00, 80.34it/s] \n",
      "Epoch: 3. Validation. Loss: 3.639 , time : 2.1933977603912354: 100%|██████████| 475/475 [00:02<00:00, 212.74it/s]\n",
      "Epoch: 4. Train.      Loss: 1.536 , time : 23.828734397888184: 100%|██████████| 1898/1898 [00:23<00:00, 79.52it/s]\n",
      "Epoch: 4. Validation. Loss: 3.649 , time : 2.177760601043701: 100%|██████████| 475/475 [00:02<00:00, 214.33it/s] \n",
      "Epoch: 5. Train.      Loss: 1.537 , time : 23.832743167877197: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s]\n",
      "Epoch: 5. Validation. Loss: 3.639 , time : 2.161006212234497: 100%|██████████| 475/475 [00:02<00:00, 215.97it/s] \n",
      "Epoch: 6. Train.      Loss: 1.535 , time : 24.107770919799805: 100%|██████████| 1898/1898 [00:24<00:00, 78.60it/s]\n",
      "Epoch: 6. Validation. Loss: 3.641 , time : 2.2115468978881836: 100%|██████████| 475/475 [00:02<00:00, 211.02it/s]\n",
      "Epoch: 7. Train.      Loss: 1.534 , time : 23.891937732696533: 100%|██████████| 1898/1898 [00:23<00:00, 79.31it/s]\n",
      "Epoch: 7. Validation. Loss: 3.647 , time : 2.14517879486084: 100%|██████████| 475/475 [00:02<00:00, 217.56it/s]  \n",
      "Epoch: 8. Train.      Loss: 1.534 , time : 23.701138019561768: 100%|██████████| 1898/1898 [00:23<00:00, 79.95it/s]\n",
      "Epoch: 8. Validation. Loss: 3.649 , time : 2.1635422706604004: 100%|██████████| 475/475 [00:02<00:00, 215.76it/s]\n",
      "Epoch: 9. Train.      Loss: 1.533 , time : 23.813840627670288: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s]\n",
      "Epoch: 9. Validation. Loss: 3.640 , time : 2.112893581390381: 100%|██████████| 475/475 [00:02<00:00, 220.70it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26260... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▄▆▃▁▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▆▄▁█▁▂▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.53393</td></tr><tr><td>Min_Val_Loss</td><td>3.63921</td></tr><tr><td>Val_Loss</td><td>3.64925</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">solar-sweep-15</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cvpwyl3m\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cvpwyl3m</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_191628-cvpwyl3m/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nurhdk35 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/nurhdk35\" target=\"_blank\">stellar-sweep-16</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.533 , time : 23.832285165786743: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s]\n",
      "Epoch: 0. Validation. Loss: 3.650 , time : 2.187878370285034: 100%|██████████| 475/475 [00:02<00:00, 213.38it/s] \n",
      "Epoch: 1. Train.      Loss: 1.532 , time : 23.711269855499268: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s]\n",
      "Epoch: 1. Validation. Loss: 3.649 , time : 2.1538453102111816: 100%|██████████| 475/475 [00:02<00:00, 216.72it/s]\n",
      "Epoch: 2. Train.      Loss: 1.531 , time : 23.806217670440674: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s]\n",
      "Epoch: 2. Validation. Loss: 3.654 , time : 2.128218173980713: 100%|██████████| 475/475 [00:02<00:00, 219.06it/s] \n",
      "Epoch: 3. Train.      Loss: 1.532 , time : 23.88847541809082: 100%|██████████| 1898/1898 [00:23<00:00, 79.32it/s] \n",
      "Epoch: 3. Validation. Loss: 3.649 , time : 2.2784371376037598: 100%|██████████| 475/475 [00:02<00:00, 204.99it/s]\n",
      "Epoch: 4. Train.      Loss: 1.531 , time : 23.912917852401733: 100%|██████████| 1898/1898 [00:23<00:00, 79.24it/s]\n",
      "Epoch: 4. Validation. Loss: 3.643 , time : 2.126479148864746: 100%|██████████| 475/475 [00:02<00:00, 219.41it/s] \n",
      "Epoch: 5. Train.      Loss: 1.530 , time : 23.6848623752594: 100%|██████████| 1898/1898 [00:23<00:00, 80.01it/s]  \n",
      "Epoch: 5. Validation. Loss: 3.648 , time : 2.1056008338928223: 100%|██████████| 475/475 [00:02<00:00, 221.56it/s]\n",
      "Epoch: 6. Train.      Loss: 1.529 , time : 23.570130586624146: 100%|██████████| 1898/1898 [00:23<00:00, 80.39it/s]\n",
      "Epoch: 6. Validation. Loss: 3.647 , time : 2.167280435562134: 100%|██████████| 475/475 [00:02<00:00, 215.22it/s] \n",
      "Epoch: 7. Train.      Loss: 1.528 , time : 23.739744424819946: 100%|██████████| 1898/1898 [00:23<00:00, 79.82it/s]\n",
      "Epoch: 7. Validation. Loss: 3.656 , time : 2.1690735816955566: 100%|██████████| 475/475 [00:02<00:00, 215.18it/s]\n",
      "Epoch: 8. Train.      Loss: 1.529 , time : 24.02057719230652: 100%|██████████| 1898/1898 [00:24<00:00, 78.89it/s] \n",
      "Epoch: 8. Validation. Loss: 3.651 , time : 2.14839243888855: 100%|██████████| 475/475 [00:02<00:00, 217.25it/s]  \n",
      "Epoch: 9. Train.      Loss: 1.528 , time : 23.69295334815979: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s] \n",
      "Epoch: 9. Validation. Loss: 3.669 , time : 2.1727967262268066: 100%|██████████| 475/475 [00:02<00:00, 214.79it/s]\n",
      "Epoch: 10. Train.      Loss: 1.527 , time : 23.753948211669922: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s]\n",
      "Epoch: 10. Validation. Loss: 3.656 , time : 2.2267134189605713: 100%|██████████| 475/475 [00:02<00:00, 209.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28072... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▇▄▃▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▆▆▆▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▄▃▁▂▂▅▃█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.52824</td></tr><tr><td>Min_Val_Loss</td><td>3.64294</td></tr><tr><td>Val_Loss</td><td>3.66885</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stellar-sweep-16</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/nurhdk35\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/nurhdk35</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_192313-nurhdk35/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cct7sgpa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cct7sgpa\" target=\"_blank\">faithful-sweep-17</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.188 , time : 38.8888726234436: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s]  \n",
      "Epoch: 0. Validation. Loss: 6.245 , time : 2.1911122798919678: 100%|██████████| 475/475 [00:02<00:00, 213.03it/s]\n",
      "Epoch: 1. Train.      Loss: 6.014 , time : 38.40780282020569: 100%|██████████| 1898/1898 [00:38<00:00, 49.37it/s] \n",
      "Epoch: 1. Validation. Loss: 6.178 , time : 2.1089084148406982: 100%|██████████| 475/475 [00:02<00:00, 221.18it/s]\n",
      "Epoch: 2. Train.      Loss: 5.899 , time : 40.306522607803345: 100%|██████████| 1898/1898 [00:40<00:00, 47.04it/s]\n",
      "Epoch: 2. Validation. Loss: 6.091 , time : 2.1291141510009766: 100%|██████████| 475/475 [00:02<00:00, 218.99it/s]\n",
      "Epoch: 3. Train.      Loss: 5.747 , time : 38.765804290771484: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]\n",
      "Epoch: 3. Validation. Loss: 5.946 , time : 2.1449427604675293: 100%|██████████| 475/475 [00:02<00:00, 217.59it/s]\n",
      "Epoch: 4. Train.      Loss: 5.556 , time : 38.542290925979614: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s]\n",
      "Epoch: 4. Validation. Loss: 5.776 , time : 2.1312143802642822: 100%|██████████| 475/475 [00:02<00:00, 218.94it/s]\n",
      "Epoch: 5. Train.      Loss: 5.350 , time : 38.7055287361145: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s]  \n",
      "Epoch: 5. Validation. Loss: 5.617 , time : 2.2415525913238525: 100%|██████████| 475/475 [00:02<00:00, 208.24it/s]\n",
      "Epoch: 6. Train.      Loss: 5.149 , time : 38.92748260498047: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 6. Validation. Loss: 5.443 , time : 2.1622185707092285: 100%|██████████| 475/475 [00:02<00:00, 215.84it/s]\n",
      "Epoch: 7. Train.      Loss: 4.964 , time : 38.4920015335083: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s]  \n",
      "Epoch: 7. Validation. Loss: 5.291 , time : 2.1935555934906006: 100%|██████████| 475/475 [00:02<00:00, 212.82it/s]\n",
      "Epoch: 8. Train.      Loss: 4.801 , time : 38.7310893535614: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]  \n",
      "Epoch: 8. Validation. Loss: 5.152 , time : 2.2156832218170166: 100%|██████████| 475/475 [00:02<00:00, 210.77it/s]\n",
      "Epoch: 9. Train.      Loss: 4.655 , time : 38.4858124256134: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]  \n",
      "Epoch: 9. Validation. Loss: 5.024 , time : 2.197291851043701: 100%|██████████| 475/475 [00:02<00:00, 212.47it/s] \n",
      "Epoch: 10. Train.      Loss: 4.524 , time : 38.847180128097534: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s]\n",
      "Epoch: 10. Validation. Loss: 4.921 , time : 2.173149347305298: 100%|██████████| 475/475 [00:02<00:00, 214.81it/s] \n",
      "Epoch: 11. Train.      Loss: 4.406 , time : 38.54975509643555: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 11. Validation. Loss: 4.827 , time : 2.1266350746154785: 100%|██████████| 475/475 [00:02<00:00, 219.39it/s]\n",
      "Epoch: 12. Train.      Loss: 4.296 , time : 38.79828405380249: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 12. Validation. Loss: 4.715 , time : 2.1297097206115723: 100%|██████████| 475/475 [00:02<00:00, 219.13it/s]\n",
      "Epoch: 13. Train.      Loss: 4.190 , time : 38.56986403465271: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 13. Validation. Loss: 4.657 , time : 2.1797375679016113: 100%|██████████| 475/475 [00:02<00:00, 214.20it/s]\n",
      "Epoch: 14. Train.      Loss: 4.093 , time : 38.72858810424805: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 14. Validation. Loss: 4.577 , time : 2.1262497901916504: 100%|██████████| 475/475 [00:02<00:00, 219.41it/s]\n",
      "Epoch: 15. Train.      Loss: 4.003 , time : 38.909279108047485: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s]\n",
      "Epoch: 15. Validation. Loss: 4.503 , time : 2.1968541145324707: 100%|██████████| 475/475 [00:02<00:00, 211.57it/s]\n",
      "Epoch: 16. Train.      Loss: 3.915 , time : 38.47278594970703: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 16. Validation. Loss: 4.441 , time : 2.1824557781219482: 100%|██████████| 475/475 [00:02<00:00, 213.71it/s]\n",
      "Epoch: 17. Train.      Loss: 3.834 , time : 38.98452353477478: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 17. Validation. Loss: 4.393 , time : 2.1726601123809814: 100%|██████████| 475/475 [00:02<00:00, 214.83it/s]\n",
      "Epoch: 18. Train.      Loss: 3.758 , time : 38.47368669509888: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 18. Validation. Loss: 4.336 , time : 2.1460154056549072: 100%|██████████| 475/475 [00:02<00:00, 217.38it/s]\n",
      "Epoch: 19. Train.      Loss: 3.682 , time : 38.92403268814087: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 19. Validation. Loss: 4.284 , time : 2.15735125541687: 100%|██████████| 475/475 [00:02<00:00, 216.38it/s]  \n",
      "Epoch: 20. Train.      Loss: 3.611 , time : 38.79375123977661: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 20. Validation. Loss: 4.242 , time : 2.1892354488372803: 100%|██████████| 475/475 [00:02<00:00, 213.23it/s]\n",
      "Epoch: 21. Train.      Loss: 3.541 , time : 38.724895000457764: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s]\n",
      "Epoch: 21. Validation. Loss: 4.213 , time : 2.133199691772461: 100%|██████████| 475/475 [00:02<00:00, 217.39it/s] \n",
      "Epoch: 22. Train.      Loss: 3.478 , time : 38.3664665222168: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s]  \n",
      "Epoch: 22. Validation. Loss: 4.143 , time : 2.109267234802246: 100%|██████████| 475/475 [00:02<00:00, 221.15it/s] \n",
      "Epoch: 23. Train.      Loss: 3.413 , time : 38.6832492351532: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]  \n",
      "Epoch: 23. Validation. Loss: 4.107 , time : 2.1610734462738037: 100%|██████████| 475/475 [00:02<00:00, 215.92it/s]\n",
      "Epoch: 24. Train.      Loss: 3.354 , time : 38.64899730682373: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 24. Validation. Loss: 4.076 , time : 2.101407289505005: 100%|██████████| 475/475 [00:02<00:00, 221.97it/s] \n",
      "Epoch: 25. Train.      Loss: 3.294 , time : 38.964362144470215: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]\n",
      "Epoch: 25. Validation. Loss: 4.044 , time : 2.2734079360961914: 100%|██████████| 475/475 [00:02<00:00, 205.31it/s]\n",
      "Epoch: 26. Train.      Loss: 3.238 , time : 38.399749994277954: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s]\n",
      "Epoch: 26. Validation. Loss: 3.997 , time : 2.1150941848754883: 100%|██████████| 475/475 [00:02<00:00, 218.87it/s]\n",
      "Epoch: 27. Train.      Loss: 3.181 , time : 38.48212766647339: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 27. Validation. Loss: 3.978 , time : 2.1790053844451904: 100%|██████████| 475/475 [00:02<00:00, 214.17it/s]\n",
      "Epoch: 28. Train.      Loss: 3.132 , time : 38.6710467338562: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s]  \n",
      "Epoch: 28. Validation. Loss: 3.940 , time : 2.228658437728882: 100%|██████████| 475/475 [00:02<00:00, 209.37it/s] \n",
      "Epoch: 29. Train.      Loss: 3.079 , time : 39.2734272480011: 100%|██████████| 1898/1898 [00:39<00:00, 48.28it/s]  \n",
      "Epoch: 29. Validation. Loss: 3.930 , time : 2.135096549987793: 100%|██████████| 475/475 [00:02<00:00, 218.58it/s] \n",
      "Epoch: 30. Train.      Loss: 3.033 , time : 38.86515760421753: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 30. Validation. Loss: 3.881 , time : 2.165470600128174: 100%|██████████| 475/475 [00:02<00:00, 215.49it/s] \n",
      "Epoch: 31. Train.      Loss: 2.986 , time : 38.684199810028076: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 31. Validation. Loss: 3.902 , time : 2.210813522338867: 100%|██████████| 475/475 [00:02<00:00, 211.18it/s] \n",
      "Epoch: 32. Train.      Loss: 2.940 , time : 38.930548906326294: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s]\n",
      "Epoch: 32. Validation. Loss: 3.844 , time : 2.157423257827759: 100%|██████████| 475/475 [00:02<00:00, 216.32it/s] \n",
      "Epoch: 33. Train.      Loss: 2.896 , time : 38.41011643409729: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s] \n",
      "Epoch: 33. Validation. Loss: 3.834 , time : 2.1683084964752197: 100%|██████████| 475/475 [00:02<00:00, 215.12it/s]\n",
      "Epoch: 34. Train.      Loss: 2.857 , time : 38.81339478492737: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 34. Validation. Loss: 3.778 , time : 2.1200125217437744: 100%|██████████| 475/475 [00:02<00:00, 220.01it/s]\n",
      "Epoch: 35. Train.      Loss: 2.814 , time : 38.52288007736206: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 35. Validation. Loss: 3.750 , time : 2.206317186355591: 100%|██████████| 475/475 [00:02<00:00, 211.55it/s] \n",
      "Epoch: 36. Train.      Loss: 2.774 , time : 38.50659680366516: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 36. Validation. Loss: 3.759 , time : 2.1625516414642334: 100%|██████████| 475/475 [00:02<00:00, 215.60it/s]\n",
      "Epoch: 37. Train.      Loss: 2.738 , time : 38.63082695007324: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 37. Validation. Loss: 3.742 , time : 2.2575459480285645: 100%|██████████| 475/475 [00:02<00:00, 206.67it/s]\n",
      "Epoch: 38. Train.      Loss: 2.698 , time : 38.88846969604492: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 38. Validation. Loss: 3.717 , time : 2.11037278175354: 100%|██████████| 475/475 [00:02<00:00, 221.01it/s]  \n",
      "Epoch: 39. Train.      Loss: 2.665 , time : 38.78413987159729: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 39. Validation. Loss: 3.713 , time : 2.1802046298980713: 100%|██████████| 475/475 [00:02<00:00, 214.13it/s]\n",
      "Epoch: 40. Train.      Loss: 2.629 , time : 38.9670033454895: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]  \n",
      "Epoch: 40. Validation. Loss: 3.700 , time : 2.217923879623413: 100%|██████████| 475/475 [00:02<00:00, 210.52it/s] \n",
      "Epoch: 41. Train.      Loss: 2.599 , time : 38.42885136604309: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 41. Validation. Loss: 3.676 , time : 2.149473190307617: 100%|██████████| 475/475 [00:02<00:00, 217.09it/s] \n",
      "Epoch: 42. Train.      Loss: 2.566 , time : 38.65667533874512: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s] \n",
      "Epoch: 42. Validation. Loss: 3.684 , time : 2.265151023864746: 100%|██████████| 475/475 [00:02<00:00, 206.21it/s] \n",
      "Epoch: 43. Train.      Loss: 2.531 , time : 39.020750522613525: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s]\n",
      "Epoch: 43. Validation. Loss: 3.669 , time : 2.147535562515259: 100%|██████████| 475/475 [00:02<00:00, 217.19it/s] \n",
      "Epoch: 44. Train.      Loss: 2.497 , time : 38.97007369995117: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 44. Validation. Loss: 3.668 , time : 2.1908740997314453: 100%|██████████| 475/475 [00:02<00:00, 213.01it/s]\n",
      "Epoch: 45. Train.      Loss: 2.468 , time : 38.90894174575806: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 45. Validation. Loss: 3.644 , time : 2.1650869846343994: 100%|██████████| 475/475 [00:02<00:00, 215.57it/s]\n",
      "Epoch: 46. Train.      Loss: 2.439 , time : 38.88487696647644: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 46. Validation. Loss: 3.644 , time : 2.1957662105560303: 100%|██████████| 475/475 [00:02<00:00, 212.65it/s]\n",
      "Epoch: 47. Train.      Loss: 2.407 , time : 39.07178354263306: 100%|██████████| 1898/1898 [00:39<00:00, 48.53it/s] \n",
      "Epoch: 47. Validation. Loss: 3.629 , time : 2.1938934326171875: 100%|██████████| 475/475 [00:02<00:00, 212.72it/s]\n",
      "Epoch: 48. Train.      Loss: 2.383 , time : 38.64434242248535: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 48. Validation. Loss: 3.626 , time : 2.164655923843384: 100%|██████████| 475/475 [00:02<00:00, 215.64it/s] \n",
      "Epoch: 49. Train.      Loss: 2.354 , time : 38.456780672073364: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s]\n",
      "Epoch: 49. Validation. Loss: 3.636 , time : 2.190990447998047: 100%|██████████| 475/475 [00:02<00:00, 213.10it/s] \n",
      "Epoch: 50. Train.      Loss: 2.326 , time : 38.84020018577576: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 50. Validation. Loss: 3.623 , time : 2.1012399196624756: 100%|██████████| 475/475 [00:02<00:00, 221.57it/s]\n",
      "Epoch: 51. Train.      Loss: 2.301 , time : 38.577369689941406: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 51. Validation. Loss: 3.616 , time : 2.1499149799346924: 100%|██████████| 475/475 [00:02<00:00, 217.07it/s]\n",
      "Epoch: 52. Train.      Loss: 2.274 , time : 38.86794948577881: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s] \n",
      "Epoch: 52. Validation. Loss: 3.644 , time : 2.1650097370147705: 100%|██████████| 475/475 [00:02<00:00, 213.40it/s]\n",
      "Epoch: 53. Train.      Loss: 2.249 , time : 38.8734176158905: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]  \n",
      "Epoch: 53. Validation. Loss: 3.619 , time : 2.2080023288726807: 100%|██████████| 475/475 [00:02<00:00, 211.38it/s]\n",
      "Epoch: 54. Train.      Loss: 2.221 , time : 38.967862367630005: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]\n",
      "Epoch: 54. Validation. Loss: 3.611 , time : 2.090873956680298: 100%|██████████| 475/475 [00:02<00:00, 223.06it/s] \n",
      "Epoch: 55. Train.      Loss: 2.198 , time : 38.73077845573425: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 55. Validation. Loss: 3.588 , time : 2.151872158050537: 100%|██████████| 475/475 [00:02<00:00, 216.79it/s] \n",
      "Epoch: 56. Train.      Loss: 2.175 , time : 38.5653862953186: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s]  \n",
      "Epoch: 56. Validation. Loss: 3.631 , time : 2.162501096725464: 100%|██████████| 475/475 [00:02<00:00, 215.76it/s] \n",
      "Epoch: 57. Train.      Loss: 2.153 , time : 38.775795459747314: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]\n",
      "Epoch: 57. Validation. Loss: 3.589 , time : 2.1023213863372803: 100%|██████████| 475/475 [00:02<00:00, 221.94it/s]\n",
      "Epoch: 58. Train.      Loss: 2.128 , time : 38.90399503707886: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 58. Validation. Loss: 3.626 , time : 2.162264347076416: 100%|██████████| 475/475 [00:02<00:00, 215.73it/s] \n",
      "Epoch: 59. Train.      Loss: 2.104 , time : 38.98514175415039: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 59. Validation. Loss: 3.626 , time : 2.1477887630462646: 100%|██████████| 475/475 [00:02<00:00, 217.27it/s]\n",
      "Epoch: 60. Train.      Loss: 2.082 , time : 38.701669692993164: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 60. Validation. Loss: 3.616 , time : 2.1848697662353516: 100%|██████████| 475/475 [00:02<00:00, 213.63it/s]\n",
      "Epoch: 61. Train.      Loss: 2.063 , time : 38.364219665527344: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s]\n",
      "Epoch: 61. Validation. Loss: 3.656 , time : 2.1140682697296143: 100%|██████████| 475/475 [00:02<00:00, 220.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29984... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.08237</td></tr><tr><td>Min_Val_Loss</td><td>3.58818</td></tr><tr><td>Val_Loss</td><td>3.61601</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">faithful-sweep-17</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cct7sgpa\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cct7sgpa</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_193021-cct7sgpa/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jipxhiz1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jipxhiz1\" target=\"_blank\">effortless-sweep-18</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.081 , time : 38.4826123714447: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.658 , time : 2.2121782302856445: 100%|██████████| 475/475 [00:02<00:00, 211.00it/s]\n",
      "Epoch: 1. Train.      Loss: 2.020 , time : 38.63952159881592: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 1. Validation. Loss: 3.669 , time : 2.168477773666382: 100%|██████████| 475/475 [00:02<00:00, 215.28it/s] \n",
      "Epoch: 2. Train.      Loss: 2.000 , time : 38.36175894737244: 100%|██████████| 1898/1898 [00:38<00:00, 49.43it/s] \n",
      "Epoch: 2. Validation. Loss: 3.619 , time : 2.1281239986419678: 100%|██████████| 475/475 [00:02<00:00, 219.28it/s]\n",
      "Epoch: 3. Train.      Loss: 1.978 , time : 38.389822244644165: 100%|██████████| 1898/1898 [00:38<00:00, 49.39it/s]\n",
      "Epoch: 3. Validation. Loss: 3.663 , time : 2.1031486988067627: 100%|██████████| 475/475 [00:02<00:00, 221.85it/s]\n",
      "Epoch: 4. Train.      Loss: 1.958 , time : 38.37551236152649: 100%|██████████| 1898/1898 [00:38<00:00, 49.41it/s] \n",
      "Epoch: 4. Validation. Loss: 3.628 , time : 2.232355833053589: 100%|██████████| 475/475 [00:02<00:00, 209.21it/s] \n",
      "Epoch: 5. Train.      Loss: 1.939 , time : 38.7504096031189: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]  \n",
      "Epoch: 5. Validation. Loss: 3.648 , time : 2.0963070392608643: 100%|██████████| 475/475 [00:02<00:00, 222.40it/s]\n",
      "Epoch: 6. Train.      Loss: 1.921 , time : 38.502655029296875: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s]\n",
      "Epoch: 6. Validation. Loss: 3.664 , time : 2.197737693786621: 100%|██████████| 475/475 [00:02<00:00, 212.30it/s] \n",
      "Epoch: 7. Train.      Loss: 1.901 , time : 38.600292444229126: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s]\n",
      "Epoch: 7. Validation. Loss: 3.659 , time : 2.1552648544311523: 100%|██████████| 475/475 [00:02<00:00, 216.43it/s]\n",
      "Epoch: 8. Train.      Loss: 1.883 , time : 38.52663516998291: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 8. Validation. Loss: 3.693 , time : 2.1395037174224854: 100%|██████████| 475/475 [00:02<00:00, 218.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8788... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆█▁▇▂▅▇▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.90082</td></tr><tr><td>Min_Val_Loss</td><td>3.61899</td></tr><tr><td>Val_Loss</td><td>3.65867</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">effortless-sweep-18</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jipxhiz1\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jipxhiz1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_201255-jipxhiz1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q98vdegv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q98vdegv\" target=\"_blank\">flowing-sweep-19</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.903 , time : 38.5568265914917: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.731 , time : 2.1367368698120117: 100%|██████████| 475/475 [00:02<00:00, 218.37it/s]\n",
      "Epoch: 1. Train.      Loss: 1.849 , time : 38.48163056373596: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 1. Validation. Loss: 3.700 , time : 2.179265022277832: 100%|██████████| 475/475 [00:02<00:00, 214.15it/s] \n",
      "Epoch: 2. Train.      Loss: 1.830 , time : 38.509543895721436: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s]\n",
      "Epoch: 2. Validation. Loss: 3.671 , time : 2.08596134185791: 100%|██████████| 475/475 [00:02<00:00, 223.61it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.813 , time : 38.66148233413696: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 3. Validation. Loss: 3.702 , time : 2.2278387546539307: 100%|██████████| 475/475 [00:02<00:00, 209.56it/s]\n",
      "Epoch: 4. Train.      Loss: 1.793 , time : 39.318371295928955: 100%|██████████| 1898/1898 [00:39<00:00, 48.22it/s]\n",
      "Epoch: 4. Validation. Loss: 3.701 , time : 2.1557540893554688: 100%|██████████| 475/475 [00:02<00:00, 216.54it/s]\n",
      "Epoch: 5. Train.      Loss: 1.778 , time : 38.46419811248779: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s] \n",
      "Epoch: 5. Validation. Loss: 3.757 , time : 2.191303253173828: 100%|██████████| 475/475 [00:02<00:00, 213.09it/s] \n",
      "Epoch: 6. Train.      Loss: 1.764 , time : 38.45998454093933: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 6. Validation. Loss: 3.749 , time : 2.1290183067321777: 100%|██████████| 475/475 [00:02<00:00, 217.46it/s]\n",
      "Epoch: 7. Train.      Loss: 1.748 , time : 38.871854066848755: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]\n",
      "Epoch: 7. Validation. Loss: 3.759 , time : 2.1823506355285645: 100%|██████████| 475/475 [00:02<00:00, 213.91it/s]\n",
      "Epoch: 8. Train.      Loss: 1.731 , time : 38.85620665550232: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 8. Validation. Loss: 3.758 , time : 2.1935253143310547: 100%|██████████| 475/475 [00:02<00:00, 212.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10490... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▃▁▃▃█▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.74805</td></tr><tr><td>Min_Val_Loss</td><td>3.67121</td></tr><tr><td>Val_Loss</td><td>3.75859</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">flowing-sweep-19</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q98vdegv\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q98vdegv</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_201916-q98vdegv/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rjwtnluo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rjwtnluo\" target=\"_blank\">fearless-sweep-20</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.752 , time : 38.45664596557617: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 0. Validation. Loss: 3.748 , time : 2.131701946258545: 100%|██████████| 475/475 [00:02<00:00, 218.83it/s] \n",
      "Epoch: 1. Train.      Loss: 1.707 , time : 38.67036485671997: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s] \n",
      "Epoch: 1. Validation. Loss: 3.788 , time : 2.1097471714019775: 100%|██████████| 475/475 [00:02<00:00, 221.11it/s]\n",
      "Epoch: 2. Train.      Loss: 1.691 , time : 38.63121056556702: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 2. Validation. Loss: 3.815 , time : 2.1238789558410645: 100%|██████████| 475/475 [00:02<00:00, 219.66it/s]\n",
      "Epoch: 3. Train.      Loss: 1.674 , time : 38.640620708465576: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s]\n",
      "Epoch: 3. Validation. Loss: 3.783 , time : 2.1473989486694336: 100%|██████████| 475/475 [00:02<00:00, 217.33it/s]\n",
      "Epoch: 4. Train.      Loss: 1.665 , time : 39.035780906677246: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s]\n",
      "Epoch: 4. Validation. Loss: 3.785 , time : 2.2665185928344727: 100%|██████████| 475/475 [00:02<00:00, 206.09it/s]\n",
      "Epoch: 5. Train.      Loss: 1.646 , time : 38.54145884513855: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 5. Validation. Loss: 3.840 , time : 2.144278049468994: 100%|██████████| 475/475 [00:02<00:00, 217.41it/s] \n",
      "Epoch: 6. Train.      Loss: 1.634 , time : 38.42249059677124: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s] \n",
      "Epoch: 6. Validation. Loss: 3.829 , time : 2.1557698249816895: 100%|██████████| 475/475 [00:02<00:00, 216.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12190... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄▆▄▄█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.64561</td></tr><tr><td>Min_Val_Loss</td><td>3.74831</td></tr><tr><td>Val_Loss</td><td>3.83989</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fearless-sweep-20</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rjwtnluo\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rjwtnluo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_202537-rjwtnluo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u8bprwdy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u8bprwdy\" target=\"_blank\">apricot-sweep-21</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.548 , time : 23.58404278755188: 100%|██████████| 1898/1898 [00:23<00:00, 80.35it/s] \n",
      "Epoch: 0. Validation. Loss: 3.806 , time : 2.10626482963562: 100%|██████████| 475/475 [00:02<00:00, 220.42it/s]  \n",
      "Epoch: 1. Train.      Loss: 1.535 , time : 23.30947780609131: 100%|██████████| 1898/1898 [00:23<00:00, 81.29it/s] \n",
      "Epoch: 1. Validation. Loss: 3.803 , time : 2.2119944095611572: 100%|██████████| 475/475 [00:02<00:00, 211.08it/s]\n",
      "Epoch: 2. Train.      Loss: 1.527 , time : 23.691442012786865: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 2. Validation. Loss: 3.807 , time : 2.099423408508301: 100%|██████████| 475/475 [00:02<00:00, 222.12it/s] \n",
      "Epoch: 3. Train.      Loss: 1.523 , time : 23.323391914367676: 100%|██████████| 1898/1898 [00:23<00:00, 81.24it/s]\n",
      "Epoch: 3. Validation. Loss: 3.812 , time : 2.0844244956970215: 100%|██████████| 475/475 [00:02<00:00, 223.59it/s]\n",
      "Epoch: 4. Train.      Loss: 1.520 , time : 23.704745054244995: 100%|██████████| 1898/1898 [00:23<00:00, 79.94it/s]\n",
      "Epoch: 4. Validation. Loss: 3.817 , time : 2.1131906509399414: 100%|██████████| 475/475 [00:02<00:00, 220.63it/s]\n",
      "Epoch: 5. Train.      Loss: 1.518 , time : 23.541658401489258: 100%|██████████| 1898/1898 [00:23<00:00, 80.49it/s]\n",
      "Epoch: 5. Validation. Loss: 3.811 , time : 2.1559395790100098: 100%|██████████| 475/475 [00:02<00:00, 216.24it/s]\n",
      "Epoch: 6. Train.      Loss: 1.515 , time : 23.470643520355225: 100%|██████████| 1898/1898 [00:23<00:00, 80.73it/s]\n",
      "Epoch: 6. Validation. Loss: 3.814 , time : 2.122629165649414: 100%|██████████| 475/475 [00:02<00:00, 219.81it/s] \n",
      "Epoch: 7. Train.      Loss: 1.514 , time : 23.691277742385864: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 7. Validation. Loss: 3.815 , time : 2.1070356369018555: 100%|██████████| 475/475 [00:02<00:00, 221.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13527... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▃▆█▅▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.51538</td></tr><tr><td>Min_Val_Loss</td><td>3.80289</td></tr><tr><td>Val_Loss</td><td>3.81372</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-21</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u8bprwdy\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u8bprwdy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_203035-u8bprwdy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 49ob7mlt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/49ob7mlt\" target=\"_blank\">light-sweep-22</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.512 , time : 23.446276664733887: 100%|██████████| 1898/1898 [00:23<00:00, 80.81it/s]\n",
      "Epoch: 0. Validation. Loss: 3.829 , time : 2.1315739154815674: 100%|██████████| 475/475 [00:02<00:00, 218.92it/s]\n",
      "Epoch: 1. Train.      Loss: 1.511 , time : 23.75268054008484: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s] \n",
      "Epoch: 1. Validation. Loss: 3.822 , time : 2.1203670501708984: 100%|██████████| 475/475 [00:02<00:00, 220.01it/s]\n",
      "Epoch: 2. Train.      Loss: 1.510 , time : 23.562403440475464: 100%|██████████| 1898/1898 [00:23<00:00, 80.41it/s]\n",
      "Epoch: 2. Validation. Loss: 3.832 , time : 2.1459197998046875: 100%|██████████| 475/475 [00:02<00:00, 217.41it/s]\n",
      "Epoch: 3. Train.      Loss: 1.509 , time : 23.574801445007324: 100%|██████████| 1898/1898 [00:23<00:00, 80.37it/s]\n",
      "Epoch: 3. Validation. Loss: 3.824 , time : 2.091456413269043: 100%|██████████| 475/475 [00:02<00:00, 222.92it/s] \n",
      "Epoch: 4. Train.      Loss: 1.508 , time : 23.674794673919678: 100%|██████████| 1898/1898 [00:23<00:00, 80.04it/s]\n",
      "Epoch: 4. Validation. Loss: 3.828 , time : 2.238647937774658: 100%|██████████| 475/475 [00:02<00:00, 208.60it/s] \n",
      "Epoch: 5. Train.      Loss: 1.507 , time : 23.83180260658264: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s] \n",
      "Epoch: 5. Validation. Loss: 3.824 , time : 2.109170436859131: 100%|██████████| 475/475 [00:02<00:00, 221.04it/s] \n",
      "Epoch: 6. Train.      Loss: 1.506 , time : 23.743505477905273: 100%|██████████| 1898/1898 [00:23<00:00, 79.81it/s]\n",
      "Epoch: 6. Validation. Loss: 3.836 , time : 2.2342164516448975: 100%|██████████| 475/475 [00:02<00:00, 208.98it/s]\n",
      "Epoch: 7. Train.      Loss: 1.506 , time : 23.80517029762268: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s] \n",
      "Epoch: 7. Validation. Loss: 3.834 , time : 2.0677576065063477: 100%|██████████| 475/475 [00:02<00:00, 225.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14571... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▁▆▂▄▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.50638</td></tr><tr><td>Min_Val_Loss</td><td>3.82153</td></tr><tr><td>Val_Loss</td><td>3.83577</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">light-sweep-22</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/49ob7mlt\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/49ob7mlt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_203414-49ob7mlt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ie0amtpq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ie0amtpq\" target=\"_blank\">expert-sweep-23</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.506 , time : 23.73195505142212: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s] \n",
      "Epoch: 0. Validation. Loss: 3.833 , time : 2.186292886734009: 100%|██████████| 475/475 [00:02<00:00, 212.41it/s] \n",
      "Epoch: 1. Train.      Loss: 1.504 , time : 23.782681703567505: 100%|██████████| 1898/1898 [00:23<00:00, 79.61it/s]\n",
      "Epoch: 1. Validation. Loss: 3.829 , time : 2.1880030632019043: 100%|██████████| 475/475 [00:02<00:00, 213.36it/s]\n",
      "Epoch: 2. Train.      Loss: 1.503 , time : 23.808829307556152: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s]\n",
      "Epoch: 2. Validation. Loss: 3.841 , time : 2.121680498123169: 100%|██████████| 475/475 [00:02<00:00, 219.85it/s] \n",
      "Epoch: 3. Train.      Loss: 1.503 , time : 23.697176933288574: 100%|██████████| 1898/1898 [00:23<00:00, 79.96it/s]\n",
      "Epoch: 3. Validation. Loss: 3.842 , time : 2.1851654052734375: 100%|██████████| 475/475 [00:02<00:00, 213.48it/s]\n",
      "Epoch: 4. Train.      Loss: 1.504 , time : 23.505656719207764: 100%|██████████| 1898/1898 [00:23<00:00, 80.61it/s]\n",
      "Epoch: 4. Validation. Loss: 3.849 , time : 2.100512742996216: 100%|██████████| 475/475 [00:02<00:00, 222.07it/s] \n",
      "Epoch: 5. Train.      Loss: 1.501 , time : 24.086326360702515: 100%|██████████| 1898/1898 [00:24<00:00, 78.67it/s]\n",
      "Epoch: 5. Validation. Loss: 3.837 , time : 2.206833600997925: 100%|██████████| 475/475 [00:02<00:00, 211.26it/s] \n",
      "Epoch: 6. Train.      Loss: 1.500 , time : 23.767770290374756: 100%|██████████| 1898/1898 [00:23<00:00, 79.73it/s]\n",
      "Epoch: 6. Validation. Loss: 3.846 , time : 2.1636528968811035: 100%|██████████| 475/475 [00:02<00:00, 215.66it/s]\n",
      "Epoch: 7. Train.      Loss: 1.499 , time : 23.693875551223755: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s]\n",
      "Epoch: 7. Validation. Loss: 3.846 , time : 2.1225364208221436: 100%|██████████| 475/475 [00:02<00:00, 219.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15583... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▅▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▁▅▅█▄▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.50005</td></tr><tr><td>Min_Val_Loss</td><td>3.82902</td></tr><tr><td>Val_Loss</td><td>3.84587</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">expert-sweep-23</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ie0amtpq\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ie0amtpq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_203753-ie0amtpq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4pd7epl2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4pd7epl2\" target=\"_blank\">skilled-sweep-24</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.500 , time : 23.71516752243042: 100%|██████████| 1898/1898 [00:23<00:00, 79.90it/s] \n",
      "Epoch: 0. Validation. Loss: 3.857 , time : 2.1179373264312744: 100%|██████████| 475/475 [00:02<00:00, 220.23it/s]\n",
      "Epoch: 1. Train.      Loss: 1.498 , time : 23.749520301818848: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 1. Validation. Loss: 3.847 , time : 2.1606216430664062: 100%|██████████| 475/475 [00:02<00:00, 216.01it/s]\n",
      "Epoch: 2. Train.      Loss: 1.498 , time : 23.826895475387573: 100%|██████████| 1898/1898 [00:23<00:00, 79.52it/s]\n",
      "Epoch: 2. Validation. Loss: 3.857 , time : 2.117706537246704: 100%|██████████| 475/475 [00:02<00:00, 220.31it/s] \n",
      "Epoch: 3. Train.      Loss: 1.497 , time : 23.558693885803223: 100%|██████████| 1898/1898 [00:23<00:00, 80.43it/s]\n",
      "Epoch: 3. Validation. Loss: 3.852 , time : 2.134230136871338: 100%|██████████| 475/475 [00:02<00:00, 218.49it/s] \n",
      "Epoch: 4. Train.      Loss: 1.496 , time : 23.855672359466553: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s]\n",
      "Epoch: 4. Validation. Loss: 3.867 , time : 2.119433879852295: 100%|██████████| 475/475 [00:02<00:00, 220.14it/s] \n",
      "Epoch: 5. Train.      Loss: 1.497 , time : 23.821616411209106: 100%|██████████| 1898/1898 [00:23<00:00, 79.54it/s]\n",
      "Epoch: 5. Validation. Loss: 3.861 , time : 2.181283473968506: 100%|██████████| 475/475 [00:02<00:00, 213.90it/s] \n",
      "Epoch: 6. Train.      Loss: 1.496 , time : 23.68475651741028: 100%|██████████| 1898/1898 [00:23<00:00, 80.00it/s] \n",
      "Epoch: 6. Validation. Loss: 3.867 , time : 2.1955695152282715: 100%|██████████| 475/475 [00:02<00:00, 212.51it/s]\n",
      "Epoch: 7. Train.      Loss: 1.495 , time : 24.016491413116455: 100%|██████████| 1898/1898 [00:24<00:00, 78.90it/s]\n",
      "Epoch: 7. Validation. Loss: 3.870 , time : 2.1333677768707275: 100%|██████████| 475/475 [00:02<00:00, 218.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16635... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▅▂▁▃▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▄▃█▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.49628</td></tr><tr><td>Min_Val_Loss</td><td>3.84718</td></tr><tr><td>Val_Loss</td><td>3.86736</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">skilled-sweep-24</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4pd7epl2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4pd7epl2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_204134-4pd7epl2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5wqe5sqs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5wqe5sqs\" target=\"_blank\">upbeat-sweep-25</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.168 , time : 38.47739243507385: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 0. Validation. Loss: 6.211 , time : 2.170729398727417: 100%|██████████| 475/475 [00:02<00:00, 215.04it/s] \n",
      "Epoch: 1. Train.      Loss: 5.953 , time : 38.280205488204956: 100%|██████████| 1898/1898 [00:38<00:00, 49.53it/s]\n",
      "Epoch: 1. Validation. Loss: 6.124 , time : 2.1019821166992188: 100%|██████████| 475/475 [00:02<00:00, 221.86it/s]\n",
      "Epoch: 2. Train.      Loss: 5.803 , time : 38.54544544219971: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 2. Validation. Loss: 5.984 , time : 2.1430089473724365: 100%|██████████| 475/475 [00:02<00:00, 217.78it/s]\n",
      "Epoch: 3. Train.      Loss: 5.615 , time : 38.63647508621216: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 3. Validation. Loss: 5.815 , time : 2.215940237045288: 100%|██████████| 475/475 [00:02<00:00, 210.56it/s] \n",
      "Epoch: 4. Train.      Loss: 5.396 , time : 38.85521674156189: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 4. Validation. Loss: 5.649 , time : 2.0872743129730225: 100%|██████████| 475/475 [00:02<00:00, 223.48it/s]\n",
      "Epoch: 5. Train.      Loss: 5.168 , time : 38.81071972846985: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 5. Validation. Loss: 5.442 , time : 2.1309990882873535: 100%|██████████| 475/475 [00:02<00:00, 218.19it/s]\n",
      "Epoch: 6. Train.      Loss: 4.960 , time : 38.56214952468872: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 6. Validation. Loss: 5.261 , time : 2.135533571243286: 100%|██████████| 475/475 [00:02<00:00, 216.81it/s] \n",
      "Epoch: 7. Train.      Loss: 4.775 , time : 38.99360418319702: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 7. Validation. Loss: 5.108 , time : 2.1166746616363525: 100%|██████████| 475/475 [00:02<00:00, 220.37it/s]\n",
      "Epoch: 8. Train.      Loss: 4.620 , time : 38.47108054161072: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 8. Validation. Loss: 4.973 , time : 2.2151427268981934: 100%|██████████| 475/475 [00:02<00:00, 210.72it/s]\n",
      "Epoch: 9. Train.      Loss: 4.484 , time : 38.64584541320801: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 9. Validation. Loss: 4.856 , time : 2.161818742752075: 100%|██████████| 475/475 [00:02<00:00, 215.86it/s] \n",
      "Epoch: 10. Train.      Loss: 4.362 , time : 39.06460356712341: 100%|██████████| 1898/1898 [00:39<00:00, 48.54it/s] \n",
      "Epoch: 10. Validation. Loss: 4.745 , time : 2.180316209793091: 100%|██████████| 475/475 [00:02<00:00, 213.99it/s] \n",
      "Epoch: 11. Train.      Loss: 4.246 , time : 38.91258692741394: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 11. Validation. Loss: 4.688 , time : 2.1853153705596924: 100%|██████████| 475/475 [00:02<00:00, 213.57it/s]\n",
      "Epoch: 12. Train.      Loss: 4.144 , time : 39.19207763671875: 100%|██████████| 1898/1898 [00:39<00:00, 48.38it/s] \n",
      "Epoch: 12. Validation. Loss: 4.594 , time : 2.155127763748169: 100%|██████████| 475/475 [00:02<00:00, 216.24it/s] \n",
      "Epoch: 13. Train.      Loss: 4.047 , time : 38.42534041404724: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 13. Validation. Loss: 4.521 , time : 2.2193491458892822: 100%|██████████| 475/475 [00:02<00:00, 208.34it/s]\n",
      "Epoch: 14. Train.      Loss: 3.953 , time : 38.72945475578308: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 14. Validation. Loss: 4.454 , time : 2.1902873516082764: 100%|██████████| 475/475 [00:02<00:00, 213.17it/s]\n",
      "Epoch: 15. Train.      Loss: 3.867 , time : 39.17072582244873: 100%|██████████| 1898/1898 [00:39<00:00, 48.41it/s] \n",
      "Epoch: 15. Validation. Loss: 4.397 , time : 2.122116804122925: 100%|██████████| 475/475 [00:02<00:00, 219.84it/s] \n",
      "Epoch: 16. Train.      Loss: 3.784 , time : 39.14076113700867: 100%|██████████| 1898/1898 [00:39<00:00, 48.44it/s] \n",
      "Epoch: 16. Validation. Loss: 4.342 , time : 2.2108170986175537: 100%|██████████| 475/475 [00:02<00:00, 211.12it/s]\n",
      "Epoch: 17. Train.      Loss: 3.706 , time : 38.57268285751343: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 17. Validation. Loss: 4.298 , time : 2.133496046066284: 100%|██████████| 475/475 [00:02<00:00, 218.65it/s] \n",
      "Epoch: 18. Train.      Loss: 3.631 , time : 38.70812797546387: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 18. Validation. Loss: 4.246 , time : 2.208611011505127: 100%|██████████| 475/475 [00:02<00:00, 211.42it/s] \n",
      "Epoch: 19. Train.      Loss: 3.557 , time : 38.74137878417969: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 19. Validation. Loss: 4.200 , time : 2.1229546070098877: 100%|██████████| 475/475 [00:02<00:00, 219.76it/s]\n",
      "Epoch: 20. Train.      Loss: 3.491 , time : 38.61195707321167: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 20. Validation. Loss: 4.137 , time : 2.1743509769439697: 100%|██████████| 475/475 [00:02<00:00, 214.69it/s]\n",
      "Epoch: 21. Train.      Loss: 3.425 , time : 38.5090069770813: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s]  \n",
      "Epoch: 21. Validation. Loss: 4.097 , time : 2.1210126876831055: 100%|██████████| 475/475 [00:02<00:00, 219.87it/s]\n",
      "Epoch: 22. Train.      Loss: 3.363 , time : 39.08222556114197: 100%|██████████| 1898/1898 [00:39<00:00, 48.51it/s] \n",
      "Epoch: 22. Validation. Loss: 4.075 , time : 2.2952024936676025: 100%|██████████| 475/475 [00:02<00:00, 203.53it/s]\n",
      "Epoch: 23. Train.      Loss: 3.300 , time : 38.61628723144531: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 23. Validation. Loss: 4.041 , time : 2.205561876296997: 100%|██████████| 475/475 [00:02<00:00, 211.64it/s] \n",
      "Epoch: 24. Train.      Loss: 3.244 , time : 38.95102047920227: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 24. Validation. Loss: 4.015 , time : 2.1414759159088135: 100%|██████████| 475/475 [00:02<00:00, 217.84it/s]\n",
      "Epoch: 25. Train.      Loss: 3.190 , time : 39.33718466758728: 100%|██████████| 1898/1898 [00:39<00:00, 48.20it/s] \n",
      "Epoch: 25. Validation. Loss: 3.983 , time : 2.0910990238189697: 100%|██████████| 475/475 [00:02<00:00, 222.97it/s]\n",
      "Epoch: 26. Train.      Loss: 3.139 , time : 38.68075132369995: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s] \n",
      "Epoch: 26. Validation. Loss: 3.922 , time : 2.1764419078826904: 100%|██████████| 475/475 [00:02<00:00, 214.26it/s]\n",
      "Epoch: 27. Train.      Loss: 3.087 , time : 38.91170954704285: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 27. Validation. Loss: 3.907 , time : 2.1459882259368896: 100%|██████████| 475/475 [00:02<00:00, 217.39it/s]\n",
      "Epoch: 28. Train.      Loss: 3.038 , time : 39.0412814617157: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s]  \n",
      "Epoch: 28. Validation. Loss: 3.874 , time : 2.2132625579833984: 100%|██████████| 475/475 [00:02<00:00, 210.35it/s]\n",
      "Epoch: 29. Train.      Loss: 2.996 , time : 38.589131116867065: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s]\n",
      "Epoch: 29. Validation. Loss: 3.857 , time : 2.137709856033325: 100%|██████████| 475/475 [00:02<00:00, 218.23it/s] \n",
      "Epoch: 30. Train.      Loss: 2.952 , time : 39.075942039489746: 100%|██████████| 1898/1898 [00:39<00:00, 48.52it/s]\n",
      "Epoch: 30. Validation. Loss: 3.836 , time : 2.1849498748779297: 100%|██████████| 475/475 [00:02<00:00, 213.57it/s]\n",
      "Epoch: 31. Train.      Loss: 2.907 , time : 38.84704113006592: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s] \n",
      "Epoch: 31. Validation. Loss: 3.814 , time : 2.156139373779297: 100%|██████████| 475/475 [00:02<00:00, 216.23it/s] \n",
      "Epoch: 32. Train.      Loss: 2.865 , time : 38.51943635940552: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 32. Validation. Loss: 3.818 , time : 2.124399423599243: 100%|██████████| 475/475 [00:02<00:00, 219.47it/s] \n",
      "Epoch: 33. Train.      Loss: 2.831 , time : 38.87984609603882: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 33. Validation. Loss: 3.782 , time : 2.1297740936279297: 100%|██████████| 475/475 [00:02<00:00, 218.89it/s]\n",
      "Epoch: 34. Train.      Loss: 2.792 , time : 39.197723150253296: 100%|██████████| 1898/1898 [00:39<00:00, 48.37it/s]\n",
      "Epoch: 34. Validation. Loss: 3.758 , time : 2.1676905155181885: 100%|██████████| 475/475 [00:02<00:00, 215.23it/s]\n",
      "Epoch: 35. Train.      Loss: 2.755 , time : 38.854729890823364: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s]\n",
      "Epoch: 35. Validation. Loss: 3.775 , time : 2.166954755783081: 100%|██████████| 475/475 [00:02<00:00, 213.44it/s] \n",
      "Epoch: 36. Train.      Loss: 2.718 , time : 38.77610731124878: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 36. Validation. Loss: 3.751 , time : 2.1102917194366455: 100%|██████████| 475/475 [00:02<00:00, 221.01it/s]\n",
      "Epoch: 37. Train.      Loss: 2.686 , time : 39.006648778915405: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s]\n",
      "Epoch: 37. Validation. Loss: 3.693 , time : 2.092989444732666: 100%|██████████| 475/475 [00:02<00:00, 222.66it/s] \n",
      "Epoch: 38. Train.      Loss: 2.654 , time : 38.62370014190674: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 38. Validation. Loss: 3.685 , time : 2.1598315238952637: 100%|██████████| 475/475 [00:02<00:00, 214.66it/s]\n",
      "Epoch: 39. Train.      Loss: 2.622 , time : 38.346911668777466: 100%|██████████| 1898/1898 [00:38<00:00, 49.44it/s]\n",
      "Epoch: 39. Validation. Loss: 3.693 , time : 2.0962955951690674: 100%|██████████| 475/475 [00:02<00:00, 222.51it/s]\n",
      "Epoch: 40. Train.      Loss: 2.590 , time : 39.018200635910034: 100%|██████████| 1898/1898 [00:39<00:00, 48.60it/s]\n",
      "Epoch: 40. Validation. Loss: 3.681 , time : 2.1590802669525146: 100%|██████████| 475/475 [00:02<00:00, 216.16it/s]\n",
      "Epoch: 41. Train.      Loss: 2.561 , time : 38.63690638542175: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 41. Validation. Loss: 3.685 , time : 2.177941083908081: 100%|██████████| 475/475 [00:02<00:00, 214.22it/s] \n",
      "Epoch: 42. Train.      Loss: 2.532 , time : 38.51065969467163: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 42. Validation. Loss: 3.668 , time : 2.165343999862671: 100%|██████████| 475/475 [00:02<00:00, 215.34it/s] \n",
      "Epoch: 43. Train.      Loss: 2.501 , time : 38.405412912368774: 100%|██████████| 1898/1898 [00:38<00:00, 49.37it/s]\n",
      "Epoch: 43. Validation. Loss: 3.653 , time : 2.1539297103881836: 100%|██████████| 475/475 [00:02<00:00, 216.46it/s]\n",
      "Epoch: 44. Train.      Loss: 2.478 , time : 38.70095682144165: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s] \n",
      "Epoch: 44. Validation. Loss: 3.657 , time : 2.1611833572387695: 100%|██████████| 475/475 [00:02<00:00, 215.91it/s]\n",
      "Epoch: 45. Train.      Loss: 2.449 , time : 38.800544023513794: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s]\n",
      "Epoch: 45. Validation. Loss: 3.630 , time : 2.15602707862854: 100%|██████████| 475/475 [00:02<00:00, 216.50it/s]  \n",
      "Epoch: 46. Train.      Loss: 2.425 , time : 38.36987638473511: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 46. Validation. Loss: 3.633 , time : 2.139690399169922: 100%|██████████| 475/475 [00:02<00:00, 218.06it/s] \n",
      "Epoch: 47. Train.      Loss: 2.397 , time : 38.92756962776184: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 47. Validation. Loss: 3.661 , time : 2.1324963569641113: 100%|██████████| 475/475 [00:02<00:00, 218.80it/s]\n",
      "Epoch: 48. Train.      Loss: 2.375 , time : 38.18120002746582: 100%|██████████| 1898/1898 [00:38<00:00, 49.66it/s] \n",
      "Epoch: 48. Validation. Loss: 3.641 , time : 2.1961777210235596: 100%|██████████| 475/475 [00:02<00:00, 212.51it/s]\n",
      "Epoch: 49. Train.      Loss: 2.347 , time : 38.53627610206604: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 49. Validation. Loss: 3.612 , time : 2.174659013748169: 100%|██████████| 475/475 [00:02<00:00, 214.63it/s] \n",
      "Epoch: 50. Train.      Loss: 2.252 , time : 10.400585889816284:  27%|██▋       | 517/1898 [00:10<00:27, 49.39it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "Epoch: 50. Train.      Loss: 2.273 , time : 20.616817474365234:  54%|█████▍    | 1021/1898 [00:20<00:18, 48.67it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "Epoch: 50. Train.      Loss: 2.282 , time : 23.891951322555542:  62%|██████▏   | 1181/1898 [00:23<00:14, 49.08it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n",
      "Epoch: 50. Train.      Loss: 2.326 , time : 38.418034076690674: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]\n",
      "Epoch: 50. Validation. Loss: 3.641 , time : 2.164473533630371: 100%|██████████| 475/475 [00:02<00:00, 215.55it/s] \n",
      "Epoch: 51. Train.      Loss: 2.303 , time : 38.6537344455719: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]  \n",
      "Epoch: 51. Validation. Loss: 3.604 , time : 2.1740939617156982: 100%|██████████| 475/475 [00:02<00:00, 214.67it/s]\n",
      "Epoch: 52. Train.      Loss: 2.275 , time : 38.62180471420288: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 52. Validation. Loss: 3.617 , time : 2.2153778076171875: 100%|██████████| 475/475 [00:02<00:00, 210.60it/s]\n",
      "Epoch: 53. Train.      Loss: 2.257 , time : 38.675015926361084: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s]\n",
      "Epoch: 53. Validation. Loss: 3.600 , time : 2.1493427753448486: 100%|██████████| 475/475 [00:02<00:00, 217.08it/s]\n",
      "Epoch: 54. Train.      Loss: 2.231 , time : 38.688679218292236: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 54. Validation. Loss: 3.597 , time : 2.167238235473633: 100%|██████████| 475/475 [00:02<00:00, 215.32it/s] \n",
      "Epoch: 55. Train.      Loss: 2.211 , time : 38.468854665756226: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s]\n",
      "Epoch: 55. Validation. Loss: 3.593 , time : 2.143278121948242: 100%|██████████| 475/475 [00:02<00:00, 217.72it/s] \n",
      "Epoch: 56. Train.      Loss: 2.192 , time : 39.247742652893066: 100%|██████████| 1898/1898 [00:39<00:00, 48.31it/s]\n",
      "Epoch: 56. Validation. Loss: 3.581 , time : 2.1834158897399902: 100%|██████████| 475/475 [00:02<00:00, 213.52it/s]\n",
      "Epoch: 57. Train.      Loss: 2.169 , time : 38.8340265750885: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]  \n",
      "Epoch: 57. Validation. Loss: 3.607 , time : 2.081143379211426: 100%|██████████| 475/475 [00:02<00:00, 222.03it/s] \n",
      "Epoch: 58. Train.      Loss: 2.148 , time : 38.894755125045776: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 58. Validation. Loss: 3.601 , time : 2.148648262023926: 100%|██████████| 475/475 [00:02<00:00, 217.19it/s] \n",
      "Epoch: 59. Train.      Loss: 2.128 , time : 38.77935171127319: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 59. Validation. Loss: 3.615 , time : 2.2165465354919434: 100%|██████████| 475/475 [00:02<00:00, 210.59it/s]\n",
      "Epoch: 60. Train.      Loss: 2.111 , time : 39.05046463012695: 100%|██████████| 1898/1898 [00:39<00:00, 48.55it/s] \n",
      "Epoch: 60. Validation. Loss: 3.591 , time : 2.0988070964813232: 100%|██████████| 475/475 [00:02<00:00, 222.08it/s]\n",
      "Epoch: 61. Train.      Loss: 2.090 , time : 38.64520263671875: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 61. Validation. Loss: 3.617 , time : 2.2077696323394775: 100%|██████████| 475/475 [00:02<00:00, 211.39it/s]\n",
      "Epoch: 62. Train.      Loss: 2.069 , time : 38.5757269859314: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]  \n",
      "Epoch: 62. Validation. Loss: 3.600 , time : 2.114421844482422: 100%|██████████| 475/475 [00:02<00:00, 218.72it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17687... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▇▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▇▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.09013</td></tr><tr><td>Min_Val_Loss</td><td>3.58061</td></tr><tr><td>Val_Loss</td><td>3.61696</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">upbeat-sweep-25</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5wqe5sqs\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5wqe5sqs</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_204523-5wqe5sqs/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y5921bzy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/y5921bzy\" target=\"_blank\">drawn-sweep-26</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.092 , time : 38.5696918964386: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.622 , time : 2.2557032108306885: 100%|██████████| 475/475 [00:02<00:00, 205.32it/s]\n",
      "Epoch: 1. Train.      Loss: 2.033 , time : 38.49535584449768: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 1. Validation. Loss: 3.608 , time : 2.1501200199127197: 100%|██████████| 475/475 [00:02<00:00, 216.89it/s]\n",
      "Epoch: 2. Train.      Loss: 2.018 , time : 38.92938041687012: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 2. Validation. Loss: 3.612 , time : 2.1331288814544678: 100%|██████████| 475/475 [00:02<00:00, 218.70it/s]\n",
      "Epoch: 3. Train.      Loss: 2.000 , time : 38.46063828468323: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 3. Validation. Loss: 3.603 , time : 2.1736252307891846: 100%|██████████| 475/475 [00:02<00:00, 214.73it/s]\n",
      "Epoch: 4. Train.      Loss: 1.977 , time : 38.27375245094299: 100%|██████████| 1898/1898 [00:38<00:00, 49.54it/s] \n",
      "Epoch: 4. Validation. Loss: 3.603 , time : 2.1660091876983643: 100%|██████████| 475/475 [00:02<00:00, 215.49it/s]\n",
      "Epoch: 5. Train.      Loss: 1.961 , time : 38.79038381576538: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 5. Validation. Loss: 3.624 , time : 2.128474473953247: 100%|██████████| 475/475 [00:02<00:00, 219.17it/s] \n",
      "Epoch: 6. Train.      Loss: 1.947 , time : 38.505781412124634: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s]\n",
      "Epoch: 6. Validation. Loss: 3.616 , time : 2.153771162033081: 100%|██████████| 475/475 [00:02<00:00, 216.49it/s] \n",
      "Epoch: 7. Train.      Loss: 1.929 , time : 38.9950225353241: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.614 , time : 2.169971227645874: 100%|██████████| 475/475 [00:02<00:00, 215.07it/s] \n",
      "Epoch: 8. Train.      Loss: 1.911 , time : 39.595850467681885: 100%|██████████| 1898/1898 [00:39<00:00, 47.89it/s]\n",
      "Epoch: 8. Validation. Loss: 3.608 , time : 2.1420187950134277: 100%|██████████| 475/475 [00:02<00:00, 217.81it/s]\n",
      "Epoch: 9. Train.      Loss: 1.898 , time : 38.682616233825684: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 9. Validation. Loss: 3.619 , time : 2.1606240272521973: 100%|██████████| 475/475 [00:02<00:00, 215.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29075... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▃▃▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▇▃▄▁▁█▅▅▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.91075</td></tr><tr><td>Min_Val_Loss</td><td>3.60304</td></tr><tr><td>Val_Loss</td><td>3.60812</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">drawn-sweep-26</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/y5921bzy\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/y5921bzy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_212839-y5921bzy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1sgunbu4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1sgunbu4\" target=\"_blank\">divine-sweep-27</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.922 , time : 38.473092555999756: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s]\n",
      "Epoch: 0. Validation. Loss: 3.602 , time : 2.163344383239746: 100%|██████████| 475/475 [00:02<00:00, 215.66it/s] \n",
      "Epoch: 1. Train.      Loss: 1.867 , time : 38.7323522567749: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s]  \n",
      "Epoch: 1. Validation. Loss: 3.619 , time : 2.1657052040100098: 100%|██████████| 475/475 [00:02<00:00, 215.45it/s]\n",
      "Epoch: 2. Train.      Loss: 1.853 , time : 39.295891523361206: 100%|██████████| 1898/1898 [00:39<00:00, 48.22it/s]\n",
      "Epoch: 2. Validation. Loss: 3.645 , time : 2.270343780517578: 100%|██████████| 475/475 [00:02<00:00, 205.70it/s] \n",
      "Epoch: 3. Train.      Loss: 1.841 , time : 38.70764970779419: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 3. Validation. Loss: 3.624 , time : 2.2074761390686035: 100%|██████████| 475/475 [00:02<00:00, 211.46it/s]\n",
      "Epoch: 4. Train.      Loss: 1.822 , time : 38.48619365692139: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 4. Validation. Loss: 3.636 , time : 2.1381781101226807: 100%|██████████| 475/475 [00:02<00:00, 218.16it/s]\n",
      "Epoch: 5. Train.      Loss: 1.811 , time : 38.59389781951904: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 5. Validation. Loss: 3.651 , time : 2.132347583770752: 100%|██████████| 475/475 [00:02<00:00, 218.73it/s] \n",
      "Epoch: 6. Train.      Loss: 1.794 , time : 38.763911485672: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]   \n",
      "Epoch: 6. Validation. Loss: 3.632 , time : 2.141993522644043: 100%|██████████| 475/475 [00:02<00:00, 217.82it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30923... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▇▄▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.8113</td></tr><tr><td>Min_Val_Loss</td><td>3.60183</td></tr><tr><td>Val_Loss</td><td>3.65072</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">divine-sweep-27</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1sgunbu4\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1sgunbu4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_213541-1sgunbu4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5k1kjq3g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5k1kjq3g\" target=\"_blank\">stellar-sweep-28</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.818 , time : 38.440950870513916: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s]\n",
      "Epoch: 0. Validation. Loss: 3.656 , time : 2.093775987625122: 100%|██████████| 475/475 [00:02<00:00, 222.67it/s] \n",
      "Epoch: 1. Train.      Loss: 1.773 , time : 38.33867311477661: 100%|██████████| 1898/1898 [00:38<00:00, 49.45it/s] \n",
      "Epoch: 1. Validation. Loss: 3.650 , time : 2.123623847961426: 100%|██████████| 475/475 [00:02<00:00, 219.66it/s] \n",
      "Epoch: 2. Train.      Loss: 1.760 , time : 38.6174042224884: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.643 , time : 2.1706385612487793: 100%|██████████| 475/475 [00:02<00:00, 214.80it/s]\n",
      "Epoch: 3. Train.      Loss: 1.747 , time : 38.44543933868408: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s] \n",
      "Epoch: 3. Validation. Loss: 3.642 , time : 2.1549124717712402: 100%|██████████| 475/475 [00:02<00:00, 216.49it/s]\n",
      "Epoch: 4. Train.      Loss: 1.734 , time : 38.556575536727905: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s]\n",
      "Epoch: 4. Validation. Loss: 3.627 , time : 2.1465818881988525: 100%|██████████| 475/475 [00:02<00:00, 217.34it/s]\n",
      "Epoch: 5. Train.      Loss: 1.724 , time : 38.43698048591614: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s] \n",
      "Epoch: 5. Validation. Loss: 3.633 , time : 2.172909736633301: 100%|██████████| 475/475 [00:02<00:00, 214.78it/s] \n",
      "Epoch: 6. Train.      Loss: 1.710 , time : 38.5372588634491: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s]  \n",
      "Epoch: 6. Validation. Loss: 3.648 , time : 2.13339900970459: 100%|██████████| 475/475 [00:02<00:00, 218.65it/s]  \n",
      "Epoch: 7. Train.      Loss: 1.698 , time : 38.8258273601532: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.660 , time : 2.155752182006836: 100%|██████████| 475/475 [00:02<00:00, 216.41it/s] \n",
      "Epoch: 8. Train.      Loss: 1.683 , time : 38.93218445777893: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 8. Validation. Loss: 3.647 , time : 2.186715602874756: 100%|██████████| 475/475 [00:02<00:00, 213.42it/s] \n",
      "Epoch: 9. Train.      Loss: 1.673 , time : 38.64844012260437: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 9. Validation. Loss: 3.683 , time : 2.1485838890075684: 100%|██████████| 475/475 [00:02<00:00, 214.65it/s]\n",
      "Epoch: 10. Train.      Loss: 1.662 , time : 38.778098344802856: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 10. Validation. Loss: 3.646 , time : 2.117549180984497: 100%|██████████| 475/475 [00:02<00:00, 220.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32252... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▅▅▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▄▃▃▁▂▄▅▃█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.6734</td></tr><tr><td>Min_Val_Loss</td><td>3.62746</td></tr><tr><td>Val_Loss</td><td>3.6829</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stellar-sweep-28</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5k1kjq3g\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5k1kjq3g</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_214040-5k1kjq3g/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ytft695q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ytft695q\" target=\"_blank\">smart-sweep-29</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.574 , time : 23.80403232574463: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s] \n",
      "Epoch: 0. Validation. Loss: 3.637 , time : 2.2012650966644287: 100%|██████████| 475/475 [00:02<00:00, 212.00it/s]\n",
      "Epoch: 1. Train.      Loss: 1.563 , time : 24.137288570404053: 100%|██████████| 1898/1898 [00:24<00:00, 78.50it/s]\n",
      "Epoch: 1. Validation. Loss: 3.626 , time : 2.2335524559020996: 100%|██████████| 475/475 [00:02<00:00, 208.86it/s]\n",
      "Epoch: 2. Train.      Loss: 1.558 , time : 23.61220121383667: 100%|██████████| 1898/1898 [00:23<00:00, 80.25it/s] \n",
      "Epoch: 2. Validation. Loss: 3.624 , time : 2.114431858062744: 100%|██████████| 475/475 [00:02<00:00, 220.50it/s] \n",
      "Epoch: 3. Train.      Loss: 1.553 , time : 23.58492612838745: 100%|██████████| 1898/1898 [00:23<00:00, 80.34it/s] \n",
      "Epoch: 3. Validation. Loss: 3.634 , time : 2.123814105987549: 100%|██████████| 475/475 [00:02<00:00, 219.57it/s] \n",
      "Epoch: 4. Train.      Loss: 1.549 , time : 23.632015705108643: 100%|██████████| 1898/1898 [00:23<00:00, 80.18it/s]\n",
      "Epoch: 4. Validation. Loss: 3.620 , time : 2.206526517868042: 100%|██████████| 475/475 [00:02<00:00, 211.48it/s] \n",
      "Epoch: 5. Train.      Loss: 1.549 , time : 23.418435096740723: 100%|██████████| 1898/1898 [00:23<00:00, 80.91it/s]\n",
      "Epoch: 5. Validation. Loss: 3.625 , time : 2.178884744644165: 100%|██████████| 475/475 [00:02<00:00, 214.16it/s] \n",
      "Epoch: 6. Train.      Loss: 1.545 , time : 23.230611562728882: 100%|██████████| 1898/1898 [00:23<00:00, 81.56it/s]\n",
      "Epoch: 6. Validation. Loss: 3.625 , time : 2.0832159519195557: 100%|██████████| 475/475 [00:02<00:00, 223.80it/s]\n",
      "Epoch: 7. Train.      Loss: 1.545 , time : 23.505321979522705: 100%|██████████| 1898/1898 [00:23<00:00, 80.61it/s]\n",
      "Epoch: 7. Validation. Loss: 3.631 , time : 2.1405625343322754: 100%|██████████| 475/475 [00:02<00:00, 217.82it/s]\n",
      "Epoch: 8. Train.      Loss: 1.542 , time : 23.79463529586792: 100%|██████████| 1898/1898 [00:23<00:00, 79.63it/s] \n",
      "Epoch: 8. Validation. Loss: 3.639 , time : 2.1661415100097656: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s]\n",
      "Epoch: 9. Train.      Loss: 1.541 , time : 23.634737730026245: 100%|██████████| 1898/1898 [00:23<00:00, 80.17it/s]\n",
      "Epoch: 9. Validation. Loss: 3.629 , time : 2.203554153442383: 100%|██████████| 475/475 [00:02<00:00, 211.67it/s] \n",
      "Epoch: 10. Train.      Loss: 1.540 , time : 24.020142078399658: 100%|██████████| 1898/1898 [00:24<00:00, 78.88it/s]\n",
      "Epoch: 10. Validation. Loss: 3.631 , time : 2.198162794113159: 100%|██████████| 475/475 [00:02<00:00, 212.15it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1938... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▃▃▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▇▃▂▆▁▃▃▅█▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.54089</td></tr><tr><td>Min_Val_Loss</td><td>3.62047</td></tr><tr><td>Val_Loss</td><td>3.62916</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">smart-sweep-29</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ytft695q\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ytft695q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_214820-ytft695q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f5vaxhg3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f5vaxhg3\" target=\"_blank\">revived-sweep-30</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.539 , time : 23.91877269744873: 100%|██████████| 1898/1898 [00:23<00:00, 79.22it/s] \n",
      "Epoch: 0. Validation. Loss: 3.630 , time : 2.1959760189056396: 100%|██████████| 475/475 [00:02<00:00, 212.38it/s]\n",
      "Epoch: 1. Train.      Loss: 1.537 , time : 23.655672550201416: 100%|██████████| 1898/1898 [00:23<00:00, 80.10it/s]\n",
      "Epoch: 1. Validation. Loss: 3.634 , time : 2.1365106105804443: 100%|██████████| 475/475 [00:02<00:00, 218.14it/s]\n",
      "Epoch: 2. Train.      Loss: 1.537 , time : 23.550960302352905: 100%|██████████| 1898/1898 [00:23<00:00, 80.45it/s]\n",
      "Epoch: 2. Validation. Loss: 3.644 , time : 2.183638572692871: 100%|██████████| 475/475 [00:02<00:00, 213.51it/s] \n",
      "Epoch: 3. Train.      Loss: 1.536 , time : 23.964285612106323: 100%|██████████| 1898/1898 [00:24<00:00, 79.07it/s]\n",
      "Epoch: 3. Validation. Loss: 3.634 , time : 2.1582295894622803: 100%|██████████| 475/475 [00:02<00:00, 216.09it/s]\n",
      "Epoch: 4. Train.      Loss: 1.535 , time : 23.751078128814697: 100%|██████████| 1898/1898 [00:23<00:00, 79.69it/s]\n",
      "Epoch: 4. Validation. Loss: 3.638 , time : 2.1052863597869873: 100%|██████████| 475/475 [00:02<00:00, 221.44it/s]\n",
      "Epoch: 5. Train.      Loss: 1.535 , time : 23.544166326522827: 100%|██████████| 1898/1898 [00:23<00:00, 80.47it/s]\n",
      "Epoch: 5. Validation. Loss: 3.639 , time : 2.2126870155334473: 100%|██████████| 475/475 [00:02<00:00, 210.75it/s]\n",
      "Epoch: 6. Train.      Loss: 1.533 , time : 23.682335376739502: 100%|██████████| 1898/1898 [00:23<00:00, 80.01it/s]\n",
      "Epoch: 6. Validation. Loss: 3.646 , time : 2.1389689445495605: 100%|██████████| 475/475 [00:02<00:00, 218.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3379... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃█▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.53472</td></tr><tr><td>Min_Val_Loss</td><td>3.63049</td></tr><tr><td>Val_Loss</td><td>3.6388</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">revived-sweep-30</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f5vaxhg3\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f5vaxhg3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_215318-f5vaxhg3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0kdikcsw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0kdikcsw\" target=\"_blank\">trim-sweep-31</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.533 , time : 23.904940366744995: 100%|██████████| 1898/1898 [00:23<00:00, 79.27it/s]\n",
      "Epoch: 0. Validation. Loss: 3.639 , time : 2.1762630939483643: 100%|██████████| 475/475 [00:02<00:00, 214.18it/s]\n",
      "Epoch: 1. Train.      Loss: 1.532 , time : 23.86103892326355: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s] \n",
      "Epoch: 1. Validation. Loss: 3.641 , time : 2.1227872371673584: 100%|██████████| 475/475 [00:02<00:00, 219.65it/s]\n",
      "Epoch: 2. Train.      Loss: 1.534 , time : 23.88773274421692: 100%|██████████| 1898/1898 [00:23<00:00, 79.26it/s] \n",
      "Epoch: 2. Validation. Loss: 3.642 , time : 2.143174886703491: 100%|██████████| 475/475 [00:02<00:00, 216.75it/s] \n",
      "Epoch: 3. Train.      Loss: 1.531 , time : 23.746733903884888: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 3. Validation. Loss: 3.647 , time : 2.1424825191497803: 100%|██████████| 475/475 [00:02<00:00, 217.51it/s]\n",
      "Epoch: 4. Train.      Loss: 1.531 , time : 23.66205358505249: 100%|██████████| 1898/1898 [00:23<00:00, 80.08it/s] \n",
      "Epoch: 4. Validation. Loss: 3.649 , time : 2.2190613746643066: 100%|██████████| 475/475 [00:02<00:00, 210.14it/s]\n",
      "Epoch: 5. Train.      Loss: 1.531 , time : 23.755140781402588: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s]\n",
      "Epoch: 5. Validation. Loss: 3.647 , time : 2.1584579944610596: 100%|██████████| 475/475 [00:02<00:00, 216.02it/s]\n",
      "Epoch: 6. Train.      Loss: 1.529 , time : 23.752479314804077: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s]\n",
      "Epoch: 6. Validation. Loss: 3.652 , time : 2.1340370178222656: 100%|██████████| 475/475 [00:02<00:00, 218.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4274... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▆▄█▂▁▃</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▃▆█▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.53132</td></tr><tr><td>Min_Val_Loss</td><td>3.63928</td></tr><tr><td>Val_Loss</td><td>3.64667</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">trim-sweep-31</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0kdikcsw\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0kdikcsw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_215632-0kdikcsw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5s0fnsxm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5s0fnsxm\" target=\"_blank\">olive-sweep-32</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.529 , time : 23.79828715324402: 100%|██████████| 1898/1898 [00:23<00:00, 79.62it/s] \n",
      "Epoch: 0. Validation. Loss: 3.660 , time : 2.128096342086792: 100%|██████████| 475/475 [00:02<00:00, 218.66it/s] \n",
      "Epoch: 1. Train.      Loss: 1.528 , time : 23.54326605796814: 100%|██████████| 1898/1898 [00:23<00:00, 80.48it/s] \n",
      "Epoch: 1. Validation. Loss: 3.654 , time : 2.135564088821411: 100%|██████████| 475/475 [00:02<00:00, 218.36it/s] \n",
      "Epoch: 2. Train.      Loss: 1.528 , time : 23.71253800392151: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s] \n",
      "Epoch: 2. Validation. Loss: 3.653 , time : 2.0866141319274902: 100%|██████████| 475/475 [00:02<00:00, 223.33it/s]\n",
      "Epoch: 3. Train.      Loss: 1.527 , time : 23.509634017944336: 100%|██████████| 1898/1898 [00:23<00:00, 80.60it/s]\n",
      "Epoch: 3. Validation. Loss: 3.657 , time : 2.118654489517212: 100%|██████████| 475/475 [00:02<00:00, 218.90it/s] \n",
      "Epoch: 4. Train.      Loss: 1.527 , time : 23.776674509048462: 100%|██████████| 1898/1898 [00:23<00:00, 79.69it/s]\n",
      "Epoch: 4. Validation. Loss: 3.657 , time : 2.1261186599731445: 100%|██████████| 475/475 [00:02<00:00, 219.25it/s]\n",
      "Epoch: 5. Train.      Loss: 1.526 , time : 23.79834485054016: 100%|██████████| 1898/1898 [00:23<00:00, 79.62it/s] \n",
      "Epoch: 5. Validation. Loss: 3.658 , time : 2.1282997131347656: 100%|██████████| 475/475 [00:02<00:00, 218.86it/s]\n",
      "Epoch: 6. Train.      Loss: 1.526 , time : 23.803310871124268: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s]\n",
      "Epoch: 6. Validation. Loss: 3.656 , time : 2.208574056625366: 100%|██████████| 475/475 [00:02<00:00, 211.24it/s] \n",
      "Epoch: 7. Train.      Loss: 1.525 , time : 23.59724998474121: 100%|██████████| 1898/1898 [00:23<00:00, 80.29it/s] \n",
      "Epoch: 7. Validation. Loss: 3.659 , time : 2.1793980598449707: 100%|██████████| 475/475 [00:02<00:00, 214.02it/s]\n",
      "Epoch: 8. Train.      Loss: 1.524 , time : 23.747494220733643: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 8. Validation. Loss: 3.662 , time : 2.2493672370910645: 100%|██████████| 475/475 [00:02<00:00, 207.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5183... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▂▁▅▅▆▄▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.52548</td></tr><tr><td>Min_Val_Loss</td><td>3.65273</td></tr><tr><td>Val_Loss</td><td>3.65931</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-32</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5s0fnsxm\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5s0fnsxm</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_215945-5s0fnsxm/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n4tumhua with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/n4tumhua\" target=\"_blank\">lucky-sweep-33</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.178 , time : 38.34084177017212: 100%|██████████| 1898/1898 [00:38<00:00, 49.45it/s] \n",
      "Epoch: 0. Validation. Loss: 6.236 , time : 2.104705333709717: 100%|██████████| 475/475 [00:02<00:00, 221.50it/s] \n",
      "Epoch: 1. Train.      Loss: 5.979 , time : 38.40071940422058: 100%|██████████| 1898/1898 [00:38<00:00, 49.37it/s] \n",
      "Epoch: 1. Validation. Loss: 6.148 , time : 2.1852288246154785: 100%|██████████| 475/475 [00:02<00:00, 213.44it/s]\n",
      "Epoch: 2. Train.      Loss: 5.844 , time : 38.72227191925049: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 2. Validation. Loss: 6.026 , time : 2.2092015743255615: 100%|██████████| 475/475 [00:02<00:00, 211.14it/s]\n",
      "Epoch: 3. Train.      Loss: 5.678 , time : 38.28809690475464: 100%|██████████| 1898/1898 [00:38<00:00, 49.52it/s] \n",
      "Epoch: 3. Validation. Loss: 5.895 , time : 2.1538901329040527: 100%|██████████| 475/475 [00:02<00:00, 216.42it/s]\n",
      "Epoch: 4. Train.      Loss: 5.488 , time : 38.30338501930237: 100%|██████████| 1898/1898 [00:38<00:00, 49.50it/s] \n",
      "Epoch: 4. Validation. Loss: 5.745 , time : 2.1111550331115723: 100%|██████████| 475/475 [00:02<00:00, 220.84it/s]\n",
      "Epoch: 5. Train.      Loss: 5.289 , time : 38.64354681968689: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 5. Validation. Loss: 5.560 , time : 2.1184136867523193: 100%|██████████| 475/475 [00:02<00:00, 220.07it/s]\n",
      "Epoch: 6. Train.      Loss: 5.088 , time : 38.45723533630371: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 6. Validation. Loss: 5.384 , time : 2.220632553100586: 100%|██████████| 475/475 [00:02<00:00, 210.06it/s] \n",
      "Epoch: 7. Train.      Loss: 4.901 , time : 38.575886964797974: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 7. Validation. Loss: 5.209 , time : 2.179384469985962: 100%|██████████| 475/475 [00:02<00:00, 214.02it/s] \n",
      "Epoch: 8. Train.      Loss: 4.726 , time : 38.42953324317932: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 8. Validation. Loss: 5.063 , time : 2.1454222202301025: 100%|██████████| 475/475 [00:02<00:00, 217.41it/s]\n",
      "Epoch: 9. Train.      Loss: 4.567 , time : 38.80152416229248: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 9. Validation. Loss: 4.919 , time : 2.1205999851226807: 100%|██████████| 475/475 [00:02<00:00, 219.67it/s]\n",
      "Epoch: 10. Train.      Loss: 4.423 , time : 38.84750056266785: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 10. Validation. Loss: 4.803 , time : 2.1475422382354736: 100%|██████████| 475/475 [00:02<00:00, 216.94it/s]\n",
      "Epoch: 11. Train.      Loss: 4.291 , time : 38.560118198394775: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s]\n",
      "Epoch: 11. Validation. Loss: 4.703 , time : 2.184830904006958: 100%|██████████| 475/475 [00:02<00:00, 213.35it/s] \n",
      "Epoch: 12. Train.      Loss: 4.176 , time : 38.79184627532959: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 12. Validation. Loss: 4.620 , time : 2.184006929397583: 100%|██████████| 475/475 [00:02<00:00, 213.55it/s] \n",
      "Epoch: 13. Train.      Loss: 4.065 , time : 38.90120005607605: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 13. Validation. Loss: 4.538 , time : 2.2160747051239014: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s]\n",
      "Epoch: 14. Train.      Loss: 3.969 , time : 38.660505294799805: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]\n",
      "Epoch: 14. Validation. Loss: 4.476 , time : 2.1577701568603516: 100%|██████████| 475/475 [00:02<00:00, 216.07it/s]\n",
      "Epoch: 15. Train.      Loss: 3.881 , time : 38.534003496170044: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s]\n",
      "Epoch: 15. Validation. Loss: 4.395 , time : 2.1567752361297607: 100%|██████████| 475/475 [00:02<00:00, 216.29it/s]\n",
      "Epoch: 16. Train.      Loss: 3.793 , time : 38.80128598213196: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 16. Validation. Loss: 4.327 , time : 2.0830957889556885: 100%|██████████| 475/475 [00:02<00:00, 223.76it/s]\n",
      "Epoch: 17. Train.      Loss: 3.716 , time : 38.837886095047: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s]   \n",
      "Epoch: 17. Validation. Loss: 4.291 , time : 2.1439743041992188: 100%|██████████| 475/475 [00:02<00:00, 217.53it/s]\n",
      "Epoch: 18. Train.      Loss: 3.638 , time : 38.52726125717163: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 18. Validation. Loss: 4.254 , time : 2.1776394844055176: 100%|██████████| 475/475 [00:02<00:00, 214.29it/s]\n",
      "Epoch: 19. Train.      Loss: 3.568 , time : 39.10591506958008: 100%|██████████| 1898/1898 [00:39<00:00, 48.49it/s] \n",
      "Epoch: 19. Validation. Loss: 4.195 , time : 2.13242244720459: 100%|██████████| 475/475 [00:02<00:00, 218.66it/s]  \n",
      "Epoch: 20. Train.      Loss: 3.498 , time : 38.98345065116882: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 20. Validation. Loss: 4.189 , time : 2.0895614624023438: 100%|██████████| 475/475 [00:02<00:00, 223.11it/s]\n",
      "Epoch: 21. Train.      Loss: 3.436 , time : 38.57525157928467: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 21. Validation. Loss: 4.134 , time : 2.1117796897888184: 100%|██████████| 475/475 [00:02<00:00, 220.76it/s]\n",
      "Epoch: 22. Train.      Loss: 3.373 , time : 39.09713363647461: 100%|██████████| 1898/1898 [00:39<00:00, 48.50it/s] \n",
      "Epoch: 22. Validation. Loss: 4.074 , time : 2.2058310508728027: 100%|██████████| 475/475 [00:02<00:00, 211.34it/s]\n",
      "Epoch: 23. Train.      Loss: 3.311 , time : 39.265634298324585: 100%|██████████| 1898/1898 [00:39<00:00, 48.27it/s]\n",
      "Epoch: 23. Validation. Loss: 4.069 , time : 2.1624488830566406: 100%|██████████| 475/475 [00:02<00:00, 215.53it/s]\n",
      "Epoch: 24. Train.      Loss: 3.255 , time : 38.16392660140991: 100%|██████████| 1898/1898 [00:38<00:00, 49.68it/s] \n",
      "Epoch: 24. Validation. Loss: 4.011 , time : 2.0689079761505127: 100%|██████████| 475/475 [00:02<00:00, 225.28it/s]\n",
      "Epoch: 25. Train.      Loss: 3.200 , time : 38.54716968536377: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 25. Validation. Loss: 3.986 , time : 2.135061740875244: 100%|██████████| 475/475 [00:02<00:00, 218.39it/s] \n",
      "Epoch: 26. Train.      Loss: 3.153 , time : 38.47919297218323: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 26. Validation. Loss: 3.950 , time : 2.1780738830566406: 100%|██████████| 475/475 [00:02<00:00, 214.14it/s]\n",
      "Epoch: 27. Train.      Loss: 3.099 , time : 38.27796792984009: 100%|██████████| 1898/1898 [00:38<00:00, 49.53it/s] \n",
      "Epoch: 27. Validation. Loss: 3.935 , time : 2.1638684272766113: 100%|██████████| 475/475 [00:02<00:00, 215.62it/s]\n",
      "Epoch: 28. Train.      Loss: 3.052 , time : 39.28536772727966: 100%|██████████| 1898/1898 [00:39<00:00, 48.26it/s] \n",
      "Epoch: 28. Validation. Loss: 3.905 , time : 2.1865434646606445: 100%|██████████| 475/475 [00:02<00:00, 213.40it/s]\n",
      "Epoch: 29. Train.      Loss: 3.003 , time : 38.67141580581665: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s] \n",
      "Epoch: 29. Validation. Loss: 3.879 , time : 2.1095869541168213: 100%|██████████| 475/475 [00:02<00:00, 221.01it/s]\n",
      "Epoch: 30. Train.      Loss: 2.955 , time : 38.368499994277954: 100%|██████████| 1898/1898 [00:38<00:00, 49.41it/s]\n",
      "Epoch: 30. Validation. Loss: 3.854 , time : 2.0899369716644287: 100%|██████████| 475/475 [00:02<00:00, 223.02it/s]\n",
      "Epoch: 31. Train.      Loss: 2.911 , time : 38.25222659111023: 100%|██████████| 1898/1898 [00:38<00:00, 49.57it/s] \n",
      "Epoch: 31. Validation. Loss: 3.830 , time : 2.201927423477173: 100%|██████████| 475/475 [00:02<00:00, 211.91it/s] \n",
      "Epoch: 32. Train.      Loss: 2.867 , time : 38.76583433151245: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 32. Validation. Loss: 3.840 , time : 2.1599838733673096: 100%|██████████| 475/475 [00:02<00:00, 215.96it/s]\n",
      "Epoch: 33. Train.      Loss: 2.825 , time : 38.53619170188904: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 33. Validation. Loss: 3.802 , time : 2.101428747177124: 100%|██████████| 475/475 [00:02<00:00, 221.86it/s] \n",
      "Epoch: 34. Train.      Loss: 2.783 , time : 38.56381678581238: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 34. Validation. Loss: 3.799 , time : 2.1390037536621094: 100%|██████████| 475/475 [00:02<00:00, 218.00it/s]\n",
      "Epoch: 35. Train.      Loss: 2.746 , time : 38.52280783653259: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 35. Validation. Loss: 3.762 , time : 2.160806179046631: 100%|██████████| 475/475 [00:02<00:00, 215.83it/s] \n",
      "Epoch: 36. Train.      Loss: 2.706 , time : 38.29840850830078: 100%|██████████| 1898/1898 [00:38<00:00, 49.50it/s] \n",
      "Epoch: 36. Validation. Loss: 3.754 , time : 2.1469151973724365: 100%|██████████| 475/475 [00:02<00:00, 217.25it/s]\n",
      "Epoch: 37. Train.      Loss: 2.665 , time : 38.604045152664185: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s]\n",
      "Epoch: 37. Validation. Loss: 3.738 , time : 2.1718332767486572: 100%|██████████| 475/475 [00:02<00:00, 214.63it/s]\n",
      "Epoch: 38. Train.      Loss: 2.633 , time : 38.7908980846405: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]  \n",
      "Epoch: 38. Validation. Loss: 3.716 , time : 2.1004440784454346: 100%|██████████| 475/475 [00:02<00:00, 221.81it/s]\n",
      "Epoch: 39. Train.      Loss: 2.593 , time : 38.51201248168945: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s] \n",
      "Epoch: 39. Validation. Loss: 3.741 , time : 2.1850013732910156: 100%|██████████| 475/475 [00:02<00:00, 213.43it/s]\n",
      "Epoch: 40. Train.      Loss: 2.563 , time : 38.70814514160156: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 40. Validation. Loss: 3.699 , time : 2.087022066116333: 100%|██████████| 475/475 [00:02<00:00, 223.37it/s] \n",
      "Epoch: 41. Train.      Loss: 2.526 , time : 38.55447721481323: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 41. Validation. Loss: 3.702 , time : 2.1582565307617188: 100%|██████████| 475/475 [00:02<00:00, 216.11it/s]\n",
      "Epoch: 42. Train.      Loss: 2.496 , time : 38.56735587120056: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 42. Validation. Loss: 3.685 , time : 2.1268961429595947: 100%|██████████| 475/475 [00:02<00:00, 219.21it/s]\n",
      "Epoch: 43. Train.      Loss: 2.463 , time : 38.80814719200134: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 43. Validation. Loss: 3.660 , time : 2.1178483963012695: 100%|██████████| 475/475 [00:02<00:00, 220.11it/s]\n",
      "Epoch: 44. Train.      Loss: 2.431 , time : 38.6094126701355: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]  \n",
      "Epoch: 44. Validation. Loss: 3.679 , time : 2.2010233402252197: 100%|██████████| 475/475 [00:02<00:00, 211.73it/s]\n",
      "Epoch: 45. Train.      Loss: 2.398 , time : 38.716076612472534: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 45. Validation. Loss: 3.619 , time : 2.1531994342803955: 100%|██████████| 475/475 [00:02<00:00, 216.62it/s]\n",
      "Epoch: 46. Train.      Loss: 2.368 , time : 41.28657054901123: 100%|██████████| 1898/1898 [00:41<00:00, 45.93it/s] \n",
      "Epoch: 46. Validation. Loss: 3.680 , time : 2.2541704177856445: 100%|██████████| 475/475 [00:02<00:00, 207.07it/s]\n",
      "Epoch: 47. Train.      Loss: 2.338 , time : 39.16745448112488: 100%|██████████| 1898/1898 [00:39<00:00, 48.41it/s] \n",
      "Epoch: 47. Validation. Loss: 3.648 , time : 2.1830155849456787: 100%|██████████| 475/475 [00:02<00:00, 213.60it/s]\n",
      "Epoch: 48. Train.      Loss: 2.309 , time : 38.67442226409912: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 48. Validation. Loss: 3.642 , time : 2.131246328353882: 100%|██████████| 475/475 [00:02<00:00, 218.62it/s] \n",
      "Epoch: 49. Train.      Loss: 2.283 , time : 38.79116868972778: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 49. Validation. Loss: 3.661 , time : 2.157026529312134: 100%|██████████| 475/475 [00:02<00:00, 216.20it/s] \n",
      "Epoch: 50. Train.      Loss: 2.254 , time : 38.48646306991577: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 50. Validation. Loss: 3.634 , time : 2.1550889015197754: 100%|██████████| 475/475 [00:02<00:00, 216.33it/s]\n",
      "Epoch: 51. Train.      Loss: 2.225 , time : 38.55611848831177: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 51. Validation. Loss: 3.658 , time : 2.1630351543426514: 100%|██████████| 475/475 [00:02<00:00, 215.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6863... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▇▆▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.25397</td></tr><tr><td>Min_Val_Loss</td><td>3.61933</td></tr><tr><td>Val_Loss</td><td>3.63441</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lucky-sweep-33</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/n4tumhua\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/n4tumhua</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_220602-n4tumhua/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rv7k80hl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv7k80hl\" target=\"_blank\">lively-sweep-34</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.250 , time : 38.26704239845276: 100%|██████████| 1898/1898 [00:38<00:00, 49.54it/s] \n",
      "Epoch: 0. Validation. Loss: 3.679 , time : 2.222404956817627: 100%|██████████| 475/475 [00:02<00:00, 209.95it/s] \n",
      "Epoch: 1. Train.      Loss: 2.174 , time : 38.75544881820679: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s] \n",
      "Epoch: 1. Validation. Loss: 3.634 , time : 2.1708884239196777: 100%|██████████| 475/475 [00:02<00:00, 212.77it/s]\n",
      "Epoch: 2. Train.      Loss: 2.151 , time : 38.326862812042236: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s]\n",
      "Epoch: 2. Validation. Loss: 3.637 , time : 2.111466407775879: 100%|██████████| 475/475 [00:02<00:00, 220.62it/s] \n",
      "Epoch: 3. Train.      Loss: 2.126 , time : 38.34490728378296: 100%|██████████| 1898/1898 [00:38<00:00, 49.45it/s] \n",
      "Epoch: 3. Validation. Loss: 3.650 , time : 2.1344988346099854: 100%|██████████| 475/475 [00:02<00:00, 218.49it/s]\n",
      "Epoch: 4. Train.      Loss: 2.100 , time : 38.93208026885986: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 4. Validation. Loss: 3.667 , time : 2.1133248805999756: 100%|██████████| 475/475 [00:02<00:00, 218.87it/s]\n",
      "Epoch: 5. Train.      Loss: 2.077 , time : 38.48189926147461: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 5. Validation. Loss: 3.653 , time : 2.123347043991089: 100%|██████████| 475/475 [00:02<00:00, 219.62it/s] \n",
      "Epoch: 6. Train.      Loss: 2.054 , time : 38.626020193099976: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s]\n",
      "Epoch: 6. Validation. Loss: 3.725 , time : 2.1815764904022217: 100%|██████████| 475/475 [00:02<00:00, 213.68it/s]\n",
      "Epoch: 7. Train.      Loss: 2.031 , time : 38.925392627716064: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s]\n",
      "Epoch: 7. Validation. Loss: 3.672 , time : 2.200119733810425: 100%|██████████| 475/475 [00:02<00:00, 210.30it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16208... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▁▂▄▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.05374</td></tr><tr><td>Min_Val_Loss</td><td>3.63369</td></tr><tr><td>Val_Loss</td><td>3.72501</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lively-sweep-34</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv7k80hl\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv7k80hl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_224141-rv7k80hl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q3345ogk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q3345ogk\" target=\"_blank\">charmed-sweep-35</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.050 , time : 39.10402965545654: 100%|██████████| 1898/1898 [00:39<00:00, 48.49it/s] \n",
      "Epoch: 0. Validation. Loss: 3.674 , time : 2.2214343547821045: 100%|██████████| 475/475 [00:02<00:00, 210.01it/s]\n",
      "Epoch: 1. Train.      Loss: 1.984 , time : 39.52012753486633: 100%|██████████| 1898/1898 [00:39<00:00, 47.98it/s] \n",
      "Epoch: 1. Validation. Loss: 3.699 , time : 2.216966152191162: 100%|██████████| 475/475 [00:02<00:00, 210.97it/s] \n",
      "Epoch: 2. Train.      Loss: 1.965 , time : 38.55330038070679: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 2. Validation. Loss: 3.679 , time : 2.1552443504333496: 100%|██████████| 475/475 [00:02<00:00, 216.31it/s]\n",
      "Epoch: 3. Train.      Loss: 1.947 , time : 39.10650277137756: 100%|██████████| 1898/1898 [00:39<00:00, 48.45it/s] \n",
      "Epoch: 3. Validation. Loss: 3.667 , time : 2.1865017414093018: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s]\n",
      "Epoch: 4. Train.      Loss: 1.926 , time : 38.91136050224304: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 4. Validation. Loss: 3.720 , time : 2.144564151763916: 100%|██████████| 475/475 [00:02<00:00, 217.49it/s] \n",
      "Epoch: 5. Train.      Loss: 1.907 , time : 38.6855046749115: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]  \n",
      "Epoch: 5. Validation. Loss: 3.711 , time : 2.2057182788848877: 100%|██████████| 475/475 [00:02<00:00, 211.39it/s]\n",
      "Epoch: 6. Train.      Loss: 1.886 , time : 38.55925440788269: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 6. Validation. Loss: 3.745 , time : 2.1264145374298096: 100%|██████████| 475/475 [00:02<00:00, 219.30it/s]\n",
      "Epoch: 7. Train.      Loss: 1.862 , time : 38.670785903930664: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s]\n",
      "Epoch: 7. Validation. Loss: 3.685 , time : 2.181633472442627: 100%|██████████| 475/475 [00:02<00:00, 213.89it/s] \n",
      "Epoch: 8. Train.      Loss: 1.847 , time : 38.97606062889099: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 8. Validation. Loss: 3.722 , time : 2.1280100345611572: 100%|██████████| 475/475 [00:02<00:00, 219.11it/s]\n",
      "Epoch: 9. Train.      Loss: 1.829 , time : 38.738725900650024: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]\n",
      "Epoch: 9. Validation. Loss: 3.701 , time : 2.1169145107269287: 100%|██████████| 475/475 [00:02<00:00, 220.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17722... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▄▂▁▆▅█▃▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.84704</td></tr><tr><td>Min_Val_Loss</td><td>3.66742</td></tr><tr><td>Val_Loss</td><td>3.72215</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">charmed-sweep-35</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q3345ogk\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q3345ogk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_224721-q3345ogk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kc27v1yt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kc27v1yt\" target=\"_blank\">mild-sweep-36</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.846 , time : 39.948315382003784: 100%|██████████| 1898/1898 [00:39<00:00, 47.46it/s]\n",
      "Epoch: 0. Validation. Loss: 3.721 , time : 2.1402268409729004: 100%|██████████| 475/475 [00:02<00:00, 217.91it/s]\n",
      "Epoch: 1. Train.      Loss: 1.795 , time : 38.39721441268921: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 1. Validation. Loss: 3.767 , time : 2.1071455478668213: 100%|██████████| 475/475 [00:02<00:00, 221.21it/s]\n",
      "Epoch: 2. Train.      Loss: 1.778 , time : 38.61255741119385: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 2. Validation. Loss: 3.736 , time : 2.123950719833374: 100%|██████████| 475/475 [00:02<00:00, 219.41it/s] \n",
      "Epoch: 3. Train.      Loss: 1.762 , time : 38.87922024726868: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 3. Validation. Loss: 3.752 , time : 2.1967036724090576: 100%|██████████| 475/475 [00:02<00:00, 212.28it/s]\n",
      "Epoch: 4. Train.      Loss: 1.744 , time : 38.91416001319885: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 4. Validation. Loss: 3.787 , time : 2.2089669704437256: 100%|██████████| 475/475 [00:02<00:00, 211.12it/s]\n",
      "Epoch: 5. Train.      Loss: 1.725 , time : 38.61443853378296: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 5. Validation. Loss: 3.807 , time : 2.2520394325256348: 100%|██████████| 475/475 [00:02<00:00, 207.27it/s]\n",
      "Epoch: 6. Train.      Loss: 1.711 , time : 39.05130934715271: 100%|██████████| 1898/1898 [00:39<00:00, 48.55it/s] \n",
      "Epoch: 6. Validation. Loss: 3.804 , time : 2.1641674041748047: 100%|██████████| 475/475 [00:02<00:00, 215.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20125... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▂▄▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.72496</td></tr><tr><td>Min_Val_Loss</td><td>3.72071</td></tr><tr><td>Val_Loss</td><td>3.80727</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">mild-sweep-36</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kc27v1yt\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kc27v1yt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_225634-kc27v1yt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cszti7es with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cszti7es\" target=\"_blank\">skilled-sweep-37</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.622 , time : 23.569754362106323: 100%|██████████| 1898/1898 [00:23<00:00, 80.39it/s]\n",
      "Epoch: 0. Validation. Loss: 3.785 , time : 2.111210346221924: 100%|██████████| 475/475 [00:02<00:00, 218.64it/s] \n",
      "Epoch: 1. Train.      Loss: 1.610 , time : 23.728171348571777: 100%|██████████| 1898/1898 [00:23<00:00, 79.86it/s]\n",
      "Epoch: 1. Validation. Loss: 3.782 , time : 2.143388509750366: 100%|██████████| 475/475 [00:02<00:00, 217.59it/s] \n",
      "Epoch: 2. Train.      Loss: 1.602 , time : 23.689958810806274: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 2. Validation. Loss: 3.772 , time : 2.11738920211792: 100%|██████████| 475/475 [00:02<00:00, 220.20it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.596 , time : 23.45393967628479: 100%|██████████| 1898/1898 [00:23<00:00, 80.79it/s] \n",
      "Epoch: 3. Validation. Loss: 3.772 , time : 2.08028244972229: 100%|██████████| 475/475 [00:02<00:00, 223.69it/s]  \n",
      "Epoch: 4. Train.      Loss: 1.593 , time : 23.76910638809204: 100%|██████████| 1898/1898 [00:23<00:00, 79.72it/s] \n",
      "Epoch: 4. Validation. Loss: 3.775 , time : 2.1120803356170654: 100%|██████████| 475/475 [00:02<00:00, 220.75it/s]\n",
      "Epoch: 5. Train.      Loss: 1.589 , time : 23.764005184173584: 100%|██████████| 1898/1898 [00:23<00:00, 79.73it/s]\n",
      "Epoch: 5. Validation. Loss: 3.773 , time : 2.1024155616760254: 100%|██████████| 475/475 [00:02<00:00, 221.67it/s]\n",
      "Epoch: 6. Train.      Loss: 1.587 , time : 23.620493173599243: 100%|██████████| 1898/1898 [00:23<00:00, 80.22it/s]\n",
      "Epoch: 6. Validation. Loss: 3.779 , time : 2.1428792476654053: 100%|██████████| 475/475 [00:02<00:00, 216.62it/s]\n",
      "Epoch: 7. Train.      Loss: 1.585 , time : 23.84191608428955: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s] \n",
      "Epoch: 7. Validation. Loss: 3.774 , time : 2.1434359550476074: 100%|██████████| 475/475 [00:02<00:00, 217.57it/s]\n",
      "Epoch: 8. Train.      Loss: 1.583 , time : 24.228909015655518: 100%|██████████| 1898/1898 [00:24<00:00, 78.21it/s]\n",
      "Epoch: 8. Validation. Loss: 3.775 , time : 2.08349609375: 100%|██████████| 475/475 [00:02<00:00, 223.62it/s]     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21965... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▆▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▆▁▁▃▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.58496</td></tr><tr><td>Min_Val_Loss</td><td>3.77196</td></tr><tr><td>Val_Loss</td><td>3.7735</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">skilled-sweep-37</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cszti7es\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/cszti7es</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_230347-cszti7es/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wz9v2uo2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wz9v2uo2\" target=\"_blank\">olive-sweep-38</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.583 , time : 23.753517627716064: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s]\n",
      "Epoch: 0. Validation. Loss: 3.774 , time : 2.233306646347046: 100%|██████████| 475/475 [00:02<00:00, 208.97it/s] \n",
      "Epoch: 1. Train.      Loss: 1.580 , time : 23.66732668876648: 100%|██████████| 1898/1898 [00:23<00:00, 80.05it/s] \n",
      "Epoch: 1. Validation. Loss: 3.782 , time : 2.1939809322357178: 100%|██████████| 475/475 [00:02<00:00, 212.68it/s]\n",
      "Epoch: 2. Train.      Loss: 1.580 , time : 23.7244656085968: 100%|██████████| 1898/1898 [00:23<00:00, 79.87it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.772 , time : 2.145726442337036: 100%|██████████| 475/475 [00:02<00:00, 217.37it/s] \n",
      "Epoch: 3. Train.      Loss: 1.577 , time : 23.805469512939453: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s]\n",
      "Epoch: 3. Validation. Loss: 3.784 , time : 2.2081332206726074: 100%|██████████| 475/475 [00:02<00:00, 211.21it/s]\n",
      "Epoch: 4. Train.      Loss: 1.576 , time : 23.698342323303223: 100%|██████████| 1898/1898 [00:23<00:00, 79.95it/s]\n",
      "Epoch: 4. Validation. Loss: 3.779 , time : 2.1154866218566895: 100%|██████████| 475/475 [00:02<00:00, 219.48it/s]\n",
      "Epoch: 5. Train.      Loss: 1.576 , time : 23.462886095046997: 100%|██████████| 1898/1898 [00:23<00:00, 80.76it/s]\n",
      "Epoch: 5. Validation. Loss: 3.782 , time : 2.143599033355713: 100%|██████████| 475/475 [00:02<00:00, 217.59it/s] \n",
      "Epoch: 6. Train.      Loss: 1.574 , time : 23.440505027770996: 100%|██████████| 1898/1898 [00:23<00:00, 80.83it/s]\n",
      "Epoch: 6. Validation. Loss: 3.784 , time : 2.2041192054748535: 100%|██████████| 475/475 [00:02<00:00, 211.52it/s]\n",
      "Epoch: 7. Train.      Loss: 1.574 , time : 23.666831493377686: 100%|██████████| 1898/1898 [00:23<00:00, 80.06it/s]\n",
      "Epoch: 7. Validation. Loss: 3.786 , time : 2.1565349102020264: 100%|██████████| 475/475 [00:02<00:00, 216.26it/s]\n",
      "Epoch: 8. Train.      Loss: 1.574 , time : 23.809218883514404: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s]\n",
      "Epoch: 8. Validation. Loss: 3.795 , time : 2.221363067626953: 100%|██████████| 475/475 [00:02<00:00, 210.14it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23657... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▆▄▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▆▁▇▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.5737</td></tr><tr><td>Min_Val_Loss</td><td>3.77164</td></tr><tr><td>Val_Loss</td><td>3.78632</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-38</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wz9v2uo2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wz9v2uo2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_231003-wz9v2uo2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dtsuapcf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dtsuapcf\" target=\"_blank\">deep-sweep-39</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.572 , time : 23.763213872909546: 100%|██████████| 1898/1898 [00:23<00:00, 79.74it/s]\n",
      "Epoch: 0. Validation. Loss: 3.778 , time : 2.3173649311065674: 100%|██████████| 475/475 [00:02<00:00, 199.36it/s]\n",
      "Epoch: 1. Train.      Loss: 1.571 , time : 23.665860414505005: 100%|██████████| 1898/1898 [00:23<00:00, 80.06it/s]\n",
      "Epoch: 1. Validation. Loss: 3.800 , time : 2.205667495727539: 100%|██████████| 475/475 [00:02<00:00, 211.53it/s] \n",
      "Epoch: 2. Train.      Loss: 1.570 , time : 23.693769454956055: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s]\n",
      "Epoch: 2. Validation. Loss: 3.797 , time : 2.113436698913574: 100%|██████████| 475/475 [00:02<00:00, 220.52it/s] \n",
      "Epoch: 3. Train.      Loss: 1.569 , time : 23.82493495941162: 100%|██████████| 1898/1898 [00:23<00:00, 79.52it/s] \n",
      "Epoch: 3. Validation. Loss: 3.793 , time : 2.184360980987549: 100%|██████████| 475/475 [00:02<00:00, 213.37it/s] \n",
      "Epoch: 4. Train.      Loss: 1.568 , time : 23.797202348709106: 100%|██████████| 1898/1898 [00:23<00:00, 79.62it/s]\n",
      "Epoch: 4. Validation. Loss: 3.789 , time : 2.192614793777466: 100%|██████████| 475/475 [00:02<00:00, 212.73it/s] \n",
      "Epoch: 5. Train.      Loss: 1.567 , time : 23.60775852203369: 100%|██████████| 1898/1898 [00:23<00:00, 80.25it/s] \n",
      "Epoch: 5. Validation. Loss: 3.784 , time : 2.148698329925537: 100%|██████████| 475/475 [00:02<00:00, 216.89it/s] \n",
      "Epoch: 6. Train.      Loss: 1.567 , time : 24.190041303634644: 100%|██████████| 1898/1898 [00:24<00:00, 78.33it/s]\n",
      "Epoch: 6. Validation. Loss: 3.796 , time : 2.079986810684204: 100%|██████████| 475/475 [00:02<00:00, 223.41it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25397... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▄▃▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁█▇▆▅▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.56744</td></tr><tr><td>Min_Val_Loss</td><td>3.77838</td></tr><tr><td>Val_Loss</td><td>3.78447</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deep-sweep-39</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dtsuapcf\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dtsuapcf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_231618-dtsuapcf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gcbs78hw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/gcbs78hw\" target=\"_blank\">fluent-sweep-40</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.566 , time : 23.50595998764038: 100%|██████████| 1898/1898 [00:23<00:00, 80.56it/s] \n",
      "Epoch: 0. Validation. Loss: 3.803 , time : 2.1293869018554688: 100%|██████████| 475/475 [00:02<00:00, 218.99it/s]\n",
      "Epoch: 1. Train.      Loss: 1.566 , time : 23.480162858963013: 100%|██████████| 1898/1898 [00:23<00:00, 80.71it/s]\n",
      "Epoch: 1. Validation. Loss: 3.806 , time : 2.1342241764068604: 100%|██████████| 475/475 [00:02<00:00, 218.34it/s]\n",
      "Epoch: 2. Train.      Loss: 1.565 , time : 23.63219404220581: 100%|██████████| 1898/1898 [00:23<00:00, 80.18it/s] \n",
      "Epoch: 2. Validation. Loss: 3.795 , time : 2.108853578567505: 100%|██████████| 475/475 [00:02<00:00, 221.14it/s] \n",
      "Epoch: 3. Train.      Loss: 1.565 , time : 23.78635287284851: 100%|██████████| 1898/1898 [00:23<00:00, 79.66it/s] \n",
      "Epoch: 3. Validation. Loss: 3.802 , time : 2.1138346195220947: 100%|██████████| 475/475 [00:02<00:00, 220.58it/s]\n",
      "Epoch: 4. Train.      Loss: 1.563 , time : 23.72345781326294: 100%|██████████| 1898/1898 [00:23<00:00, 79.87it/s] \n",
      "Epoch: 4. Validation. Loss: 3.820 , time : 2.308455228805542: 100%|██████████| 475/475 [00:02<00:00, 202.28it/s] \n",
      "Epoch: 5. Train.      Loss: 1.563 , time : 23.518219470977783: 100%|██████████| 1898/1898 [00:23<00:00, 80.56it/s]\n",
      "Epoch: 5. Validation. Loss: 3.804 , time : 2.112989664077759: 100%|██████████| 475/475 [00:02<00:00, 220.58it/s] \n",
      "Epoch: 6. Train.      Loss: 1.562 , time : 23.643659353256226: 100%|██████████| 1898/1898 [00:23<00:00, 80.14it/s]\n",
      "Epoch: 6. Validation. Loss: 3.805 , time : 2.1411283016204834: 100%|██████████| 475/475 [00:02<00:00, 217.85it/s]\n",
      "Epoch: 7. Train.      Loss: 1.561 , time : 23.736703634262085: 100%|██████████| 1898/1898 [00:23<00:00, 79.82it/s]\n",
      "Epoch: 7. Validation. Loss: 3.806 , time : 2.239609956741333: 100%|██████████| 475/475 [00:02<00:00, 208.34it/s] \n",
      "Epoch: 8. Train.      Loss: 1.561 , time : 23.709702014923096: 100%|██████████| 1898/1898 [00:23<00:00, 79.92it/s]\n",
      "Epoch: 8. Validation. Loss: 3.812 , time : 2.1723201274871826: 100%|██████████| 475/475 [00:02<00:00, 214.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26824... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▄▁▃█▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.56093</td></tr><tr><td>Min_Val_Loss</td><td>3.79456</td></tr><tr><td>Val_Loss</td><td>3.80565</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fluent-sweep-40</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/gcbs78hw\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/gcbs78hw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_232141-gcbs78hw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t71xzzlj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/t71xzzlj\" target=\"_blank\">autumn-sweep-41</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.159 , time : 38.4284942150116: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]  \n",
      "Epoch: 0. Validation. Loss: 6.192 , time : 2.1001477241516113: 100%|██████████| 475/475 [00:02<00:00, 221.99it/s]\n",
      "Epoch: 1. Train.      Loss: 5.913 , time : 38.69441080093384: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 1. Validation. Loss: 6.070 , time : 2.1595728397369385: 100%|██████████| 475/475 [00:02<00:00, 215.98it/s]\n",
      "Epoch: 2. Train.      Loss: 5.708 , time : 38.2802631855011: 100%|██████████| 1898/1898 [00:38<00:00, 49.53it/s]  \n",
      "Epoch: 2. Validation. Loss: 5.881 , time : 2.1740148067474365: 100%|██████████| 475/475 [00:02<00:00, 214.56it/s]\n",
      "Epoch: 3. Train.      Loss: 5.449 , time : 38.89864706993103: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 3. Validation. Loss: 5.670 , time : 2.109992265701294: 100%|██████████| 475/475 [00:02<00:00, 220.97it/s] \n",
      "Epoch: 4. Train.      Loss: 5.178 , time : 38.782490491867065: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 4. Validation. Loss: 5.442 , time : 2.204396963119507: 100%|██████████| 475/475 [00:02<00:00, 211.65it/s] \n",
      "Epoch: 5. Train.      Loss: 4.929 , time : 38.52365684509277: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 5. Validation. Loss: 5.232 , time : 2.193866729736328: 100%|██████████| 475/475 [00:02<00:00, 212.60it/s] \n",
      "Epoch: 6. Train.      Loss: 4.727 , time : 38.665531873703: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]   \n",
      "Epoch: 6. Validation. Loss: 5.051 , time : 2.144549608230591: 100%|██████████| 475/475 [00:02<00:00, 217.50it/s] \n",
      "Epoch: 7. Train.      Loss: 4.557 , time : 38.58519744873047: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 7. Validation. Loss: 4.916 , time : 2.210984468460083: 100%|██████████| 475/475 [00:02<00:00, 211.04it/s] \n",
      "Epoch: 8. Train.      Loss: 4.414 , time : 38.88417315483093: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 8. Validation. Loss: 4.810 , time : 2.120746612548828: 100%|██████████| 475/475 [00:02<00:00, 219.66it/s] \n",
      "Epoch: 9. Train.      Loss: 4.286 , time : 38.69658350944519: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 9. Validation. Loss: 4.701 , time : 2.15749192237854: 100%|██████████| 475/475 [00:02<00:00, 216.17it/s]  \n",
      "Epoch: 10. Train.      Loss: 4.170 , time : 38.841493129730225: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s]\n",
      "Epoch: 10. Validation. Loss: 4.601 , time : 2.1089394092559814: 100%|██████████| 475/475 [00:02<00:00, 221.09it/s]\n",
      "Epoch: 11. Train.      Loss: 4.062 , time : 38.90489649772644: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 11. Validation. Loss: 4.539 , time : 2.1514952182769775: 100%|██████████| 475/475 [00:02<00:00, 216.79it/s]\n",
      "Epoch: 12. Train.      Loss: 3.959 , time : 38.48678517341614: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 12. Validation. Loss: 4.456 , time : 2.167163372039795: 100%|██████████| 475/475 [00:02<00:00, 215.05it/s] \n",
      "Epoch: 13. Train.      Loss: 3.866 , time : 38.66136121749878: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 13. Validation. Loss: 4.399 , time : 2.1003799438476562: 100%|██████████| 475/475 [00:02<00:00, 221.93it/s]\n",
      "Epoch: 14. Train.      Loss: 3.778 , time : 38.625174045562744: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s]\n",
      "Epoch: 14. Validation. Loss: 4.331 , time : 2.1326162815093994: 100%|██████████| 475/475 [00:02<00:00, 218.66it/s]\n",
      "Epoch: 15. Train.      Loss: 3.692 , time : 39.05229878425598: 100%|██████████| 1898/1898 [00:39<00:00, 48.55it/s] \n",
      "Epoch: 15. Validation. Loss: 4.280 , time : 2.162440299987793: 100%|██████████| 475/475 [00:02<00:00, 215.46it/s] \n",
      "Epoch: 16. Train.      Loss: 3.615 , time : 38.38969302177429: 100%|██████████| 1898/1898 [00:38<00:00, 49.39it/s] \n",
      "Epoch: 16. Validation. Loss: 4.213 , time : 2.168086528778076: 100%|██████████| 475/475 [00:02<00:00, 215.09it/s] \n",
      "Epoch: 17. Train.      Loss: 3.544 , time : 38.57246422767639: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 17. Validation. Loss: 4.178 , time : 2.14888334274292: 100%|██████████| 475/475 [00:02<00:00, 216.94it/s]  \n",
      "Epoch: 18. Train.      Loss: 3.473 , time : 39.254520893096924: 100%|██████████| 1898/1898 [00:39<00:00, 48.30it/s]\n",
      "Epoch: 18. Validation. Loss: 4.134 , time : 2.111097574234009: 100%|██████████| 475/475 [00:02<00:00, 220.88it/s] \n",
      "Epoch: 19. Train.      Loss: 3.405 , time : 39.50259065628052: 100%|██████████| 1898/1898 [00:39<00:00, 47.99it/s] \n",
      "Epoch: 19. Validation. Loss: 4.118 , time : 2.153064250946045: 100%|██████████| 475/475 [00:02<00:00, 216.66it/s] \n",
      "Epoch: 20. Train.      Loss: 3.345 , time : 38.4194016456604: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]  \n",
      "Epoch: 20. Validation. Loss: 4.060 , time : 2.1227667331695557: 100%|██████████| 475/475 [00:02<00:00, 219.65it/s]\n",
      "Epoch: 21. Train.      Loss: 3.284 , time : 38.647592306137085: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]\n",
      "Epoch: 21. Validation. Loss: 4.014 , time : 2.1485910415649414: 100%|██████████| 475/475 [00:02<00:00, 217.08it/s]\n",
      "Epoch: 22. Train.      Loss: 3.230 , time : 38.82878279685974: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 22. Validation. Loss: 3.982 , time : 2.1525259017944336: 100%|██████████| 475/475 [00:02<00:00, 216.66it/s]\n",
      "Epoch: 23. Train.      Loss: 3.174 , time : 38.62325382232666: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 23. Validation. Loss: 3.962 , time : 2.2302329540252686: 100%|██████████| 475/475 [00:02<00:00, 209.26it/s]\n",
      "Epoch: 24. Train.      Loss: 3.122 , time : 38.65676736831665: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 24. Validation. Loss: 3.963 , time : 2.1161983013153076: 100%|██████████| 475/475 [00:02<00:00, 220.31it/s]\n",
      "Epoch: 25. Train.      Loss: 3.073 , time : 38.62914991378784: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 25. Validation. Loss: 3.945 , time : 2.1364903450012207: 100%|██████████| 475/475 [00:02<00:00, 218.29it/s]\n",
      "Epoch: 26. Train.      Loss: 3.027 , time : 38.47973346710205: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 26. Validation. Loss: 3.895 , time : 2.1422877311706543: 100%|██████████| 475/475 [00:02<00:00, 217.67it/s]\n",
      "Epoch: 27. Train.      Loss: 2.983 , time : 38.50383257865906: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 27. Validation. Loss: 3.869 , time : 2.1881206035614014: 100%|██████████| 475/475 [00:02<00:00, 213.19it/s]\n",
      "Epoch: 28. Train.      Loss: 2.941 , time : 38.7723274230957: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]  \n",
      "Epoch: 28. Validation. Loss: 3.866 , time : 2.1113688945770264: 100%|██████████| 475/475 [00:02<00:00, 220.78it/s]\n",
      "Epoch: 29. Train.      Loss: 2.896 , time : 38.945976972579956: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s]\n",
      "Epoch: 29. Validation. Loss: 3.828 , time : 2.134049654006958: 100%|██████████| 475/475 [00:02<00:00, 217.25it/s] \n",
      "Epoch: 30. Train.      Loss: 2.859 , time : 38.703896284103394: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 30. Validation. Loss: 3.841 , time : 2.15163516998291: 100%|██████████| 475/475 [00:02<00:00, 216.78it/s]  \n",
      "Epoch: 31. Train.      Loss: 2.821 , time : 38.98843717575073: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 31. Validation. Loss: 3.811 , time : 2.1544899940490723: 100%|██████████| 475/475 [00:02<00:00, 216.14it/s]\n",
      "Epoch: 32. Train.      Loss: 2.785 , time : 38.90788650512695: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 32. Validation. Loss: 3.780 , time : 2.1661019325256348: 100%|██████████| 475/475 [00:02<00:00, 215.17it/s]\n",
      "Epoch: 33. Train.      Loss: 2.750 , time : 39.04809355735779: 100%|██████████| 1898/1898 [00:39<00:00, 48.56it/s] \n",
      "Epoch: 33. Validation. Loss: 3.773 , time : 2.1772525310516357: 100%|██████████| 475/475 [00:02<00:00, 214.28it/s]\n",
      "Epoch: 34. Train.      Loss: 2.715 , time : 38.747002840042114: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]\n",
      "Epoch: 34. Validation. Loss: 3.730 , time : 2.166696786880493: 100%|██████████| 475/475 [00:02<00:00, 214.40it/s] \n",
      "Epoch: 35. Train.      Loss: 2.681 , time : 38.72323703765869: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 35. Validation. Loss: 3.755 , time : 2.141286849975586: 100%|██████████| 475/475 [00:02<00:00, 217.64it/s] \n",
      "Epoch: 36. Train.      Loss: 2.646 , time : 38.92462182044983: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 36. Validation. Loss: 3.756 , time : 2.2464752197265625: 100%|██████████| 475/475 [00:02<00:00, 207.15it/s]\n",
      "Epoch: 37. Train.      Loss: 2.613 , time : 39.228166341781616: 100%|██████████| 1898/1898 [00:39<00:00, 48.33it/s]\n",
      "Epoch: 37. Validation. Loss: 3.733 , time : 2.171046495437622: 100%|██████████| 475/475 [00:02<00:00, 214.66it/s] \n",
      "Epoch: 38. Train.      Loss: 2.586 , time : 38.546709299087524: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s]\n",
      "Epoch: 38. Validation. Loss: 3.737 , time : 2.2238712310791016: 100%|██████████| 475/475 [00:02<00:00, 209.87it/s]\n",
      "Epoch: 39. Train.      Loss: 2.560 , time : 38.82493591308594: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 39. Validation. Loss: 3.712 , time : 2.2174904346466064: 100%|██████████| 475/475 [00:02<00:00, 210.46it/s]\n",
      "Epoch: 40. Train.      Loss: 2.527 , time : 38.993510484695435: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s]\n",
      "Epoch: 40. Validation. Loss: 3.708 , time : 2.1791226863861084: 100%|██████████| 475/475 [00:02<00:00, 214.06it/s]\n",
      "Epoch: 41. Train.      Loss: 2.499 , time : 38.63548803329468: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 41. Validation. Loss: 3.692 , time : 2.1400365829467773: 100%|██████████| 475/475 [00:02<00:00, 217.94it/s]\n",
      "Epoch: 42. Train.      Loss: 2.470 , time : 38.39857602119446: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 42. Validation. Loss: 3.710 , time : 2.1544647216796875: 100%|██████████| 475/475 [00:02<00:00, 216.33it/s]\n",
      "Epoch: 43. Train.      Loss: 2.446 , time : 38.818398237228394: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]\n",
      "Epoch: 43. Validation. Loss: 3.678 , time : 2.104281187057495: 100%|██████████| 475/475 [00:02<00:00, 221.54it/s] \n",
      "Epoch: 44. Train.      Loss: 2.416 , time : 38.72342562675476: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 44. Validation. Loss: 3.686 , time : 2.1276803016662598: 100%|██████████| 475/475 [00:02<00:00, 219.07it/s]\n",
      "Epoch: 45. Train.      Loss: 2.394 , time : 38.57852244377136: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 45. Validation. Loss: 3.679 , time : 2.213926315307617: 100%|██████████| 475/475 [00:02<00:00, 210.75it/s] \n",
      "Epoch: 46. Train.      Loss: 2.369 , time : 38.81285095214844: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 46. Validation. Loss: 3.658 , time : 2.1638879776000977: 100%|██████████| 475/475 [00:02<00:00, 215.55it/s]\n",
      "Epoch: 47. Train.      Loss: 2.346 , time : 38.93056011199951: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 47. Validation. Loss: 3.665 , time : 2.258333444595337: 100%|██████████| 475/475 [00:02<00:00, 206.72it/s] \n",
      "Epoch: 48. Train.      Loss: 2.324 , time : 38.519009828567505: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s]\n",
      "Epoch: 48. Validation. Loss: 3.642 , time : 2.214322805404663: 100%|██████████| 475/475 [00:02<00:00, 210.69it/s] \n",
      "Epoch: 49. Train.      Loss: 2.295 , time : 38.494736433029175: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s]\n",
      "Epoch: 49. Validation. Loss: 3.641 , time : 2.2114923000335693: 100%|██████████| 475/475 [00:02<00:00, 210.99it/s]\n",
      "Epoch: 50. Train.      Loss: 2.275 , time : 38.654871463775635: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]\n",
      "Epoch: 50. Validation. Loss: 3.649 , time : 2.1566057205200195: 100%|██████████| 475/475 [00:02<00:00, 216.25it/s]\n",
      "Epoch: 51. Train.      Loss: 2.250 , time : 38.794726848602295: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s]\n",
      "Epoch: 51. Validation. Loss: 3.628 , time : 2.2326300144195557: 100%|██████████| 475/475 [00:02<00:00, 209.05it/s]\n",
      "Epoch: 52. Train.      Loss: 2.226 , time : 38.65023636817932: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 52. Validation. Loss: 3.652 , time : 2.163033962249756: 100%|██████████| 475/475 [00:02<00:00, 215.60it/s] \n",
      "Epoch: 53. Train.      Loss: 2.207 , time : 38.45287036895752: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s] \n",
      "Epoch: 53. Validation. Loss: 3.660 , time : 2.105915069580078: 100%|██████████| 475/475 [00:02<00:00, 221.38it/s] \n",
      "Epoch: 54. Train.      Loss: 2.188 , time : 38.481337547302246: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]\n",
      "Epoch: 54. Validation. Loss: 3.652 , time : 2.1660385131835938: 100%|██████████| 475/475 [00:02<00:00, 215.36it/s]\n",
      "Epoch: 55. Train.      Loss: 2.164 , time : 38.60213541984558: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 55. Validation. Loss: 3.633 , time : 2.193850517272949: 100%|██████████| 475/475 [00:02<00:00, 212.66it/s] \n",
      "Epoch: 56. Train.      Loss: 2.143 , time : 38.77107071876526: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 56. Validation. Loss: 3.659 , time : 2.1931655406951904: 100%|██████████| 475/475 [00:02<00:00, 212.73it/s]\n",
      "Epoch: 57. Train.      Loss: 2.121 , time : 39.004964113235474: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s]\n",
      "Epoch: 57. Validation. Loss: 3.649 , time : 2.191270351409912: 100%|██████████| 475/475 [00:02<00:00, 211.03it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28465... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.14347</td></tr><tr><td>Min_Val_Loss</td><td>3.62829</td></tr><tr><td>Val_Loss</td><td>3.65889</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">autumn-sweep-41</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/t71xzzlj\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/t71xzzlj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220121_232753-t71xzzlj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: miz6qi5o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/miz6qi5o\" target=\"_blank\">driven-sweep-42</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.147 , time : 38.62736797332764: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 0. Validation. Loss: 3.661 , time : 2.2050912380218506: 100%|██████████| 475/475 [00:02<00:00, 211.53it/s]\n",
      "Epoch: 1. Train.      Loss: 2.085 , time : 38.76433992385864: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 1. Validation. Loss: 3.639 , time : 2.1799561977386475: 100%|██████████| 475/475 [00:02<00:00, 214.02it/s]\n",
      "Epoch: 2. Train.      Loss: 2.063 , time : 38.73995900154114: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 2. Validation. Loss: 3.637 , time : 2.1901028156280518: 100%|██████████| 475/475 [00:02<00:00, 212.88it/s]\n",
      "Epoch: 3. Train.      Loss: 2.044 , time : 38.765106201171875: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]\n",
      "Epoch: 3. Validation. Loss: 3.661 , time : 2.1751766204833984: 100%|██████████| 475/475 [00:02<00:00, 214.40it/s]\n",
      "Epoch: 4. Train.      Loss: 2.023 , time : 39.02718186378479: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s] \n",
      "Epoch: 4. Validation. Loss: 3.645 , time : 2.146101474761963: 100%|██████████| 475/475 [00:02<00:00, 217.17it/s] \n",
      "Epoch: 5. Train.      Loss: 2.010 , time : 38.42846179008484: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 5. Validation. Loss: 3.652 , time : 2.179041624069214: 100%|██████████| 475/475 [00:02<00:00, 213.02it/s] \n",
      "Epoch: 6. Train.      Loss: 1.986 , time : 38.43613910675049: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s] \n",
      "Epoch: 6. Validation. Loss: 3.638 , time : 2.1582837104797363: 100%|██████████| 475/475 [00:02<00:00, 216.01it/s]\n",
      "Epoch: 7. Train.      Loss: 1.969 , time : 38.7771053314209: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.648 , time : 2.111224889755249: 100%|██████████| 475/475 [00:02<00:00, 220.64it/s] \n",
      "Epoch: 8. Train.      Loss: 1.948 , time : 38.93945813179016: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 8. Validation. Loss: 3.637 , time : 2.1358492374420166: 100%|██████████| 475/475 [00:02<00:00, 217.54it/s]\n",
      "Epoch: 9. Train.      Loss: 1.935 , time : 38.87583899497986: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 9. Validation. Loss: 3.658 , time : 2.2469863891601562: 100%|██████████| 475/475 [00:02<00:00, 207.61it/s]\n",
      "Epoch: 10. Train.      Loss: 1.916 , time : 38.60826921463013: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 10. Validation. Loss: 3.661 , time : 2.1981005668640137: 100%|██████████| 475/475 [00:02<00:00, 212.27it/s]\n",
      "Epoch: 11. Train.      Loss: 1.898 , time : 38.825491189956665: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 11. Validation. Loss: 3.688 , time : 2.1524038314819336: 100%|██████████| 475/475 [00:02<00:00, 216.69it/s]\n",
      "Epoch: 12. Train.      Loss: 1.879 , time : 38.73510408401489: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 12. Validation. Loss: 3.658 , time : 2.1752800941467285: 100%|██████████| 475/475 [00:02<00:00, 214.41it/s]\n",
      "Epoch: 13. Train.      Loss: 1.865 , time : 38.288918256759644: 100%|██████████| 1898/1898 [00:38<00:00, 49.52it/s]\n",
      "Epoch: 13. Validation. Loss: 3.690 , time : 2.1382195949554443: 100%|██████████| 475/475 [00:02<00:00, 217.92it/s]\n",
      "Epoch: 14. Train.      Loss: 1.848 , time : 38.47727966308594: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 14. Validation. Loss: 3.649 , time : 2.159467935562134: 100%|██████████| 475/475 [00:02<00:00, 216.00it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7209... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▆▅▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▁▄▂▃▁▂▁▄▄█▄█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.86516</td></tr><tr><td>Min_Val_Loss</td><td>3.63675</td></tr><tr><td>Val_Loss</td><td>3.69003</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">driven-sweep-42</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/miz6qi5o\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/miz6qi5o</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_000743-miz6qi5o/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qr1zapeg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qr1zapeg\" target=\"_blank\">dry-sweep-43</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.868 , time : 38.52452063560486: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 0. Validation. Loss: 3.685 , time : 2.1593902111053467: 100%|██████████| 475/475 [00:02<00:00, 214.52it/s]\n",
      "Epoch: 1. Train.      Loss: 1.819 , time : 38.376617670059204: 100%|██████████| 1898/1898 [00:38<00:00, 49.40it/s]\n",
      "Epoch: 1. Validation. Loss: 3.666 , time : 2.179042100906372: 100%|██████████| 475/475 [00:02<00:00, 213.94it/s] \n",
      "Epoch: 2. Train.      Loss: 1.801 , time : 38.87554049491882: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 2. Validation. Loss: 3.691 , time : 2.1065874099731445: 100%|██████████| 475/475 [00:02<00:00, 221.34it/s]\n",
      "Epoch: 3. Train.      Loss: 1.787 , time : 38.50097370147705: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 3. Validation. Loss: 3.679 , time : 2.1362180709838867: 100%|██████████| 475/475 [00:02<00:00, 218.16it/s]\n",
      "Epoch: 4. Train.      Loss: 1.773 , time : 38.47427773475647: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 4. Validation. Loss: 3.685 , time : 2.1363942623138428: 100%|██████████| 475/475 [00:02<00:00, 218.28it/s]\n",
      "Epoch: 5. Train.      Loss: 1.757 , time : 38.49274230003357: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 5. Validation. Loss: 3.689 , time : 2.138552665710449: 100%|██████████| 475/475 [00:02<00:00, 218.09it/s] \n",
      "Epoch: 6. Train.      Loss: 1.739 , time : 38.62662172317505: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 6. Validation. Loss: 3.683 , time : 2.1692147254943848: 100%|██████████| 475/475 [00:02<00:00, 215.05it/s]\n",
      "Epoch: 7. Train.      Loss: 1.728 , time : 38.469112396240234: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s]\n",
      "Epoch: 7. Validation. Loss: 3.681 , time : 2.1309256553649902: 100%|██████████| 475/475 [00:02<00:00, 218.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9888... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▁█▅▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.7387</td></tr><tr><td>Min_Val_Loss</td><td>3.66611</td></tr><tr><td>Val_Loss</td><td>3.68349</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dry-sweep-43</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qr1zapeg\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qr1zapeg</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_001808-qr1zapeg/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aangecdi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aangecdi\" target=\"_blank\">sage-sweep-44</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.753 , time : 38.454282999038696: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]\n",
      "Epoch: 0. Validation. Loss: 3.679 , time : 2.1178817749023438: 100%|██████████| 475/475 [00:02<00:00, 220.14it/s]\n",
      "Epoch: 1. Train.      Loss: 1.704 , time : 38.567160844802856: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s]\n",
      "Epoch: 1. Validation. Loss: 3.692 , time : 2.0737156867980957: 100%|██████████| 475/475 [00:02<00:00, 224.74it/s]\n",
      "Epoch: 2. Train.      Loss: 1.691 , time : 38.55499005317688: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 2. Validation. Loss: 3.685 , time : 2.1420726776123047: 100%|██████████| 475/475 [00:02<00:00, 217.74it/s]\n",
      "Epoch: 3. Train.      Loss: 1.676 , time : 38.324150800704956: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s]\n",
      "Epoch: 3. Validation. Loss: 3.668 , time : 2.1140048503875732: 100%|██████████| 475/475 [00:02<00:00, 220.54it/s]\n",
      "Epoch: 4. Train.      Loss: 1.666 , time : 38.89776349067688: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 4. Validation. Loss: 3.691 , time : 2.165442705154419: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s] \n",
      "Epoch: 5. Train.      Loss: 1.651 , time : 38.58061099052429: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 5. Validation. Loss: 3.675 , time : 2.1650679111480713: 100%|██████████| 475/475 [00:02<00:00, 215.42it/s]\n",
      "Epoch: 6. Train.      Loss: 1.641 , time : 38.56188607215881: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 6. Validation. Loss: 3.693 , time : 2.178236961364746: 100%|██████████| 475/475 [00:02<00:00, 214.01it/s] \n",
      "Epoch: 7. Train.      Loss: 1.626 , time : 38.720420837402344: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s]\n",
      "Epoch: 7. Validation. Loss: 3.681 , time : 2.131989002227783: 100%|██████████| 475/475 [00:02<00:00, 218.70it/s] \n",
      "Epoch: 8. Train.      Loss: 1.617 , time : 38.73952388763428: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 8. Validation. Loss: 3.690 , time : 2.1116154193878174: 100%|██████████| 475/475 [00:02<00:00, 220.79it/s]\n",
      "Epoch: 9. Train.      Loss: 1.605 , time : 38.75014090538025: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 9. Validation. Loss: 3.699 , time : 2.277740001678467: 100%|██████████| 475/475 [00:02<00:00, 204.94it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11345... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▅▄▄▃▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄█▆▁▇▃█▅▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.61747</td></tr><tr><td>Min_Val_Loss</td><td>3.66842</td></tr><tr><td>Val_Loss</td><td>3.69012</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sage-sweep-44</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aangecdi\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aangecdi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_002347-aangecdi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fwj6x9gh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fwj6x9gh\" target=\"_blank\">apricot-sweep-45</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.517 , time : 23.492270708084106: 100%|██████████| 1898/1898 [00:23<00:00, 80.65it/s]\n",
      "Epoch: 0. Validation. Loss: 3.676 , time : 2.1014416217803955: 100%|██████████| 475/475 [00:02<00:00, 221.81it/s]\n",
      "Epoch: 1. Train.      Loss: 1.504 , time : 23.62963628768921: 100%|██████████| 1898/1898 [00:23<00:00, 80.19it/s] \n",
      "Epoch: 1. Validation. Loss: 3.672 , time : 2.092101573944092: 100%|██████████| 475/475 [00:02<00:00, 222.82it/s] \n",
      "Epoch: 2. Train.      Loss: 1.498 , time : 23.923657655715942: 100%|██████████| 1898/1898 [00:23<00:00, 79.20it/s]\n",
      "Epoch: 2. Validation. Loss: 3.674 , time : 2.1556386947631836: 100%|██████████| 475/475 [00:02<00:00, 216.38it/s]\n",
      "Epoch: 3. Train.      Loss: 1.493 , time : 23.52554941177368: 100%|██████████| 1898/1898 [00:23<00:00, 80.54it/s] \n",
      "Epoch: 3. Validation. Loss: 3.671 , time : 2.1556174755096436: 100%|██████████| 475/475 [00:02<00:00, 216.34it/s]\n",
      "Epoch: 4. Train.      Loss: 1.490 , time : 23.71488308906555: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s] \n",
      "Epoch: 4. Validation. Loss: 3.669 , time : 2.1294784545898438: 100%|██████████| 475/475 [00:02<00:00, 219.00it/s]\n",
      "Epoch: 5. Train.      Loss: 1.487 , time : 23.554589986801147: 100%|██████████| 1898/1898 [00:23<00:00, 80.44it/s]\n",
      "Epoch: 5. Validation. Loss: 3.672 , time : 2.15281343460083: 100%|██████████| 475/475 [00:02<00:00, 216.56it/s]  \n",
      "Epoch: 6. Train.      Loss: 1.486 , time : 23.71046757698059: 100%|██████████| 1898/1898 [00:23<00:00, 79.92it/s] \n",
      "Epoch: 6. Validation. Loss: 3.689 , time : 2.216212034225464: 100%|██████████| 475/475 [00:02<00:00, 210.38it/s] \n",
      "Epoch: 7. Train.      Loss: 1.485 , time : 23.71243929862976: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s] \n",
      "Epoch: 7. Validation. Loss: 3.676 , time : 2.10508131980896: 100%|██████████| 475/475 [00:02<00:00, 221.30it/s]  \n",
      "Epoch: 8. Train.      Loss: 1.481 , time : 23.726117372512817: 100%|██████████| 1898/1898 [00:23<00:00, 79.86it/s]\n",
      "Epoch: 8. Validation. Loss: 3.672 , time : 2.203523874282837: 100%|██████████| 475/475 [00:02<00:00, 211.76it/s] \n",
      "Epoch: 9. Train.      Loss: 1.480 , time : 23.564329385757446: 100%|██████████| 1898/1898 [00:23<00:00, 80.41it/s]\n",
      "Epoch: 9. Validation. Loss: 3.673 , time : 2.15045166015625: 100%|██████████| 475/475 [00:02<00:00, 216.79it/s]  \n",
      "Epoch: 10. Train.      Loss: 1.479 , time : 23.657522439956665: 100%|██████████| 1898/1898 [00:23<00:00, 80.09it/s]\n",
      "Epoch: 10. Validation. Loss: 3.683 , time : 2.125650405883789: 100%|██████████| 475/475 [00:02<00:00, 219.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13703... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▃▂▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▄▃▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▂▃▂▁▂█▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.48005</td></tr><tr><td>Min_Val_Loss</td><td>3.66883</td></tr><tr><td>Val_Loss</td><td>3.67257</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-45</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fwj6x9gh\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fwj6x9gh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_003259-fwj6x9gh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i8aljj41 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i8aljj41\" target=\"_blank\">volcanic-sweep-46</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.478 , time : 23.636304140090942: 100%|██████████| 1898/1898 [00:23<00:00, 80.17it/s]\n",
      "Epoch: 0. Validation. Loss: 3.680 , time : 2.1461241245269775: 100%|██████████| 475/475 [00:02<00:00, 217.14it/s]\n",
      "Epoch: 1. Train.      Loss: 1.476 , time : 23.884790897369385: 100%|██████████| 1898/1898 [00:23<00:00, 79.33it/s]\n",
      "Epoch: 1. Validation. Loss: 3.676 , time : 2.1034369468688965: 100%|██████████| 475/475 [00:02<00:00, 221.61it/s]\n",
      "Epoch: 2. Train.      Loss: 1.475 , time : 23.48368811607361: 100%|██████████| 1898/1898 [00:23<00:00, 80.68it/s] \n",
      "Epoch: 2. Validation. Loss: 3.682 , time : 2.1428158283233643: 100%|██████████| 475/475 [00:02<00:00, 217.60it/s]\n",
      "Epoch: 3. Train.      Loss: 1.475 , time : 23.561664819717407: 100%|██████████| 1898/1898 [00:23<00:00, 80.41it/s]\n",
      "Epoch: 3. Validation. Loss: 3.680 , time : 2.1912784576416016: 100%|██████████| 475/475 [00:02<00:00, 212.92it/s]\n",
      "Epoch: 4. Train.      Loss: 1.474 , time : 23.564229488372803: 100%|██████████| 1898/1898 [00:23<00:00, 80.41it/s]\n",
      "Epoch: 4. Validation. Loss: 3.690 , time : 2.1548619270324707: 100%|██████████| 475/475 [00:02<00:00, 216.45it/s]\n",
      "Epoch: 5. Train.      Loss: 1.474 , time : 23.443018198013306: 100%|██████████| 1898/1898 [00:23<00:00, 80.82it/s]\n",
      "Epoch: 5. Validation. Loss: 3.682 , time : 2.161998748779297: 100%|██████████| 475/475 [00:02<00:00, 215.54it/s] \n",
      "Epoch: 6. Train.      Loss: 1.472 , time : 23.8913414478302: 100%|██████████| 1898/1898 [00:23<00:00, 79.29it/s]  \n",
      "Epoch: 6. Validation. Loss: 3.678 , time : 2.1772027015686035: 100%|██████████| 475/475 [00:02<00:00, 214.31it/s]\n",
      "Epoch: 7. Train.      Loss: 1.471 , time : 23.471973657608032: 100%|██████████| 1898/1898 [00:23<00:00, 80.72it/s]\n",
      "Epoch: 7. Validation. Loss: 3.686 , time : 2.141568899154663: 100%|██████████| 475/475 [00:02<00:00, 217.78it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15563... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▃▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▄▃█▄▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.47224</td></tr><tr><td>Min_Val_Loss</td><td>3.676</td></tr><tr><td>Val_Loss</td><td>3.67789</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">volcanic-sweep-46</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i8aljj41\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i8aljj41</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_004006-i8aljj41/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d1c6q0c6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d1c6q0c6\" target=\"_blank\">dry-sweep-47</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.471 , time : 23.633551359176636: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s]\n",
      "Epoch: 0. Validation. Loss: 3.697 , time : 2.164607524871826: 100%|██████████| 475/475 [00:02<00:00, 215.51it/s] \n",
      "Epoch: 1. Train.      Loss: 1.470 , time : 23.778456449508667: 100%|██████████| 1898/1898 [00:23<00:00, 79.67it/s]\n",
      "Epoch: 1. Validation. Loss: 3.687 , time : 2.2001941204071045: 100%|██████████| 475/475 [00:02<00:00, 212.01it/s]\n",
      "Epoch: 2. Train.      Loss: 1.470 , time : 23.841867446899414: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s]\n",
      "Epoch: 2. Validation. Loss: 3.689 , time : 2.159524440765381: 100%|██████████| 475/475 [00:02<00:00, 215.96it/s] \n",
      "Epoch: 3. Train.      Loss: 1.469 , time : 23.71484088897705: 100%|██████████| 1898/1898 [00:23<00:00, 79.83it/s] \n",
      "Epoch: 3. Validation. Loss: 3.685 , time : 2.1748905181884766: 100%|██████████| 475/475 [00:02<00:00, 214.46it/s]\n",
      "Epoch: 4. Train.      Loss: 1.470 , time : 23.835778951644897: 100%|██████████| 1898/1898 [00:23<00:00, 79.49it/s]\n",
      "Epoch: 4. Validation. Loss: 3.685 , time : 2.1160340309143066: 100%|██████████| 475/475 [00:02<00:00, 220.12it/s]\n",
      "Epoch: 5. Train.      Loss: 1.468 , time : 23.80586814880371: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s] \n",
      "Epoch: 5. Validation. Loss: 3.691 , time : 2.089956521987915: 100%|██████████| 475/475 [00:02<00:00, 222.86it/s] \n",
      "Epoch: 6. Train.      Loss: 1.468 , time : 23.526339292526245: 100%|██████████| 1898/1898 [00:23<00:00, 80.54it/s]\n",
      "Epoch: 6. Validation. Loss: 3.693 , time : 2.1946005821228027: 100%|██████████| 475/475 [00:02<00:00, 212.51it/s]\n",
      "Epoch: 7. Train.      Loss: 1.467 , time : 23.67876672744751: 100%|██████████| 1898/1898 [00:23<00:00, 80.02it/s] \n",
      "Epoch: 7. Validation. Loss: 3.703 , time : 2.1211721897125244: 100%|██████████| 475/475 [00:02<00:00, 219.66it/s]\n",
      "Epoch: 8. Train.      Loss: 1.466 , time : 23.72676920890808: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s] \n",
      "Epoch: 8. Validation. Loss: 3.695 , time : 2.1041691303253174: 100%|██████████| 475/475 [00:02<00:00, 221.57it/s]\n",
      "Epoch: 9. Train.      Loss: 1.466 , time : 23.63087558746338: 100%|██████████| 1898/1898 [00:23<00:00, 80.18it/s] \n",
      "Epoch: 9. Validation. Loss: 3.703 , time : 2.2001190185546875: 100%|██████████| 475/475 [00:02<00:00, 211.90it/s]\n",
      "Epoch: 10. Train.      Loss: 1.466 , time : 23.867865324020386: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s]\n",
      "Epoch: 10. Validation. Loss: 3.706 , time : 2.099853038787842: 100%|██████████| 475/475 [00:02<00:00, 222.01it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17105... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▆▅▆▄▄▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▂▃▁▁▃▄█▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.466</td></tr><tr><td>Min_Val_Loss</td><td>3.6851</td></tr><tr><td>Val_Loss</td><td>3.7027</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dry-sweep-47</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d1c6q0c6\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d1c6q0c6</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_004555-d1c6q0c6/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ihf6xhkk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ihf6xhkk\" target=\"_blank\">fresh-sweep-48</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.465 , time : 23.84321665763855: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s] \n",
      "Epoch: 0. Validation. Loss: 3.696 , time : 2.1695327758789062: 100%|██████████| 475/475 [00:02<00:00, 214.97it/s]\n",
      "Epoch: 1. Train.      Loss: 1.464 , time : 23.92875576019287: 100%|██████████| 1898/1898 [00:23<00:00, 79.19it/s] \n",
      "Epoch: 1. Validation. Loss: 3.692 , time : 2.116694211959839: 100%|██████████| 475/475 [00:02<00:00, 220.20it/s] \n",
      "Epoch: 2. Train.      Loss: 1.463 , time : 23.3795382976532: 100%|██████████| 1898/1898 [00:23<00:00, 81.04it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.693 , time : 2.144742250442505: 100%|██████████| 475/475 [00:02<00:00, 216.81it/s] \n",
      "Epoch: 3. Train.      Loss: 1.464 , time : 23.70187020301819: 100%|██████████| 1898/1898 [00:23<00:00, 79.94it/s] \n",
      "Epoch: 3. Validation. Loss: 3.697 , time : 2.1180078983306885: 100%|██████████| 475/475 [00:02<00:00, 220.09it/s]\n",
      "Epoch: 4. Train.      Loss: 1.463 , time : 23.65914011001587: 100%|██████████| 1898/1898 [00:23<00:00, 80.08it/s] \n",
      "Epoch: 4. Validation. Loss: 3.696 , time : 2.098235845565796: 100%|██████████| 475/475 [00:02<00:00, 222.21it/s] \n",
      "Epoch: 5. Train.      Loss: 1.463 , time : 23.45068621635437: 100%|██████████| 1898/1898 [00:23<00:00, 80.80it/s] \n",
      "Epoch: 5. Validation. Loss: 3.697 , time : 2.083941698074341: 100%|██████████| 475/475 [00:02<00:00, 223.66it/s] \n",
      "Epoch: 6. Train.      Loss: 1.465 , time : 23.793272018432617: 100%|██████████| 1898/1898 [00:23<00:00, 79.63it/s]\n",
      "Epoch: 6. Validation. Loss: 3.696 , time : 2.1324191093444824: 100%|██████████| 475/475 [00:02<00:00, 218.51it/s]\n",
      "Epoch: 7. Train.      Loss: 1.461 , time : 23.87327742576599: 100%|██████████| 1898/1898 [00:23<00:00, 79.36it/s] \n",
      "Epoch: 7. Validation. Loss: 3.704 , time : 2.217927932739258: 100%|██████████| 475/475 [00:02<00:00, 210.39it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19005... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▁▁█</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▇▁▂█▆█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.46486</td></tr><tr><td>Min_Val_Loss</td><td>3.69202</td></tr><tr><td>Val_Loss</td><td>3.69641</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fresh-sweep-48</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ihf6xhkk\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ihf6xhkk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_005303-ihf6xhkk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w5qt6oxa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/w5qt6oxa\" target=\"_blank\">amber-sweep-49</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.153 , time : 38.28012251853943: 100%|██████████| 1898/1898 [00:38<00:00, 49.53it/s] \n",
      "Epoch: 0. Validation. Loss: 6.190 , time : 2.230588436126709: 100%|██████████| 475/475 [00:02<00:00, 209.04it/s] \n",
      "Epoch: 1. Train.      Loss: 5.888 , time : 38.61449074745178: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 1. Validation. Loss: 6.035 , time : 2.1844515800476074: 100%|██████████| 475/475 [00:02<00:00, 213.53it/s]\n",
      "Epoch: 2. Train.      Loss: 5.666 , time : 38.46067261695862: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 2. Validation. Loss: 5.840 , time : 2.1413137912750244: 100%|██████████| 475/475 [00:02<00:00, 217.75it/s]\n",
      "Epoch: 3. Train.      Loss: 5.387 , time : 38.412012577056885: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s]\n",
      "Epoch: 3. Validation. Loss: 5.606 , time : 2.2052054405212402: 100%|██████████| 475/475 [00:02<00:00, 211.54it/s]\n",
      "Epoch: 4. Train.      Loss: 5.094 , time : 38.446245431900024: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]\n",
      "Epoch: 4. Validation. Loss: 5.336 , time : 2.094297170639038: 100%|██████████| 475/475 [00:02<00:00, 222.45it/s] \n",
      "Epoch: 5. Train.      Loss: 4.839 , time : 38.46721172332764: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s] \n",
      "Epoch: 5. Validation. Loss: 5.116 , time : 2.1769115924835205: 100%|██████████| 475/475 [00:02<00:00, 214.17it/s]\n",
      "Epoch: 6. Train.      Loss: 4.629 , time : 38.72189736366272: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 6. Validation. Loss: 4.953 , time : 2.131159782409668: 100%|██████████| 475/475 [00:02<00:00, 218.65it/s] \n",
      "Epoch: 7. Train.      Loss: 4.457 , time : 38.36821699142456: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 7. Validation. Loss: 4.809 , time : 2.1259377002716064: 100%|██████████| 475/475 [00:02<00:00, 219.25it/s]\n",
      "Epoch: 8. Train.      Loss: 4.305 , time : 38.64237880706787: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 8. Validation. Loss: 4.695 , time : 2.198636054992676: 100%|██████████| 475/475 [00:02<00:00, 212.16it/s] \n",
      "Epoch: 9. Train.      Loss: 4.173 , time : 38.37321424484253: 100%|██████████| 1898/1898 [00:38<00:00, 49.41it/s] \n",
      "Epoch: 9. Validation. Loss: 4.589 , time : 2.154228448867798: 100%|██████████| 475/475 [00:02<00:00, 216.36it/s] \n",
      "Epoch: 10. Train.      Loss: 4.052 , time : 38.78124403953552: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 10. Validation. Loss: 4.486 , time : 2.1503262519836426: 100%|██████████| 475/475 [00:02<00:00, 216.87it/s]\n",
      "Epoch: 11. Train.      Loss: 3.938 , time : 38.7046422958374: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]  \n",
      "Epoch: 11. Validation. Loss: 4.421 , time : 2.194544553756714: 100%|██████████| 475/475 [00:02<00:00, 212.49it/s] \n",
      "Epoch: 12. Train.      Loss: 3.833 , time : 38.60662293434143: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 12. Validation. Loss: 4.339 , time : 2.212230682373047: 100%|██████████| 475/475 [00:02<00:00, 208.77it/s] \n",
      "Epoch: 13. Train.      Loss: 3.737 , time : 38.985278367996216: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s]\n",
      "Epoch: 13. Validation. Loss: 4.285 , time : 2.1632907390594482: 100%|██████████| 475/475 [00:02<00:00, 215.43it/s]\n",
      "Epoch: 14. Train.      Loss: 3.644 , time : 38.68626928329468: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 14. Validation. Loss: 4.230 , time : 2.2048909664154053: 100%|██████████| 475/475 [00:02<00:00, 211.61it/s]\n",
      "Epoch: 15. Train.      Loss: 3.558 , time : 38.75984477996826: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 15. Validation. Loss: 4.179 , time : 2.174374580383301: 100%|██████████| 475/475 [00:02<00:00, 213.73it/s] \n",
      "Epoch: 16. Train.      Loss: 3.477 , time : 38.31966471672058: 100%|██████████| 1898/1898 [00:38<00:00, 49.48it/s] \n",
      "Epoch: 16. Validation. Loss: 4.114 , time : 2.1391730308532715: 100%|██████████| 475/475 [00:02<00:00, 217.90it/s]\n",
      "Epoch: 17. Train.      Loss: 3.395 , time : 38.6472373008728: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]  \n",
      "Epoch: 17. Validation. Loss: 4.068 , time : 2.2684614658355713: 100%|██████████| 475/475 [00:02<00:00, 205.58it/s]\n",
      "Epoch: 18. Train.      Loss: 3.324 , time : 39.33307695388794: 100%|██████████| 1898/1898 [00:39<00:00, 48.20it/s] \n",
      "Epoch: 18. Validation. Loss: 4.047 , time : 2.1631007194519043: 100%|██████████| 475/475 [00:02<00:00, 215.59it/s]\n",
      "Epoch: 19. Train.      Loss: 3.256 , time : 38.953091859817505: 100%|██████████| 1898/1898 [00:38<00:00, 48.67it/s]\n",
      "Epoch: 19. Validation. Loss: 3.962 , time : 2.137420892715454: 100%|██████████| 475/475 [00:02<00:00, 218.12it/s] \n",
      "Epoch: 20. Train.      Loss: 3.185 , time : 38.63730311393738: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 20. Validation. Loss: 3.936 , time : 2.1519784927368164: 100%|██████████| 475/475 [00:02<00:00, 216.73it/s]\n",
      "Epoch: 21. Train.      Loss: 3.121 , time : 38.87510323524475: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 21. Validation. Loss: 3.918 , time : 2.1614456176757812: 100%|██████████| 475/475 [00:02<00:00, 215.76it/s]\n",
      "Epoch: 22. Train.      Loss: 3.058 , time : 38.80073666572571: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 22. Validation. Loss: 3.861 , time : 2.2333180904388428: 100%|██████████| 475/475 [00:02<00:00, 208.99it/s]\n",
      "Epoch: 23. Train.      Loss: 2.996 , time : 38.7418909072876: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]  \n",
      "Epoch: 23. Validation. Loss: 3.846 , time : 2.1388206481933594: 100%|██████████| 475/475 [00:02<00:00, 218.01it/s]\n",
      "Epoch: 24. Train.      Loss: 2.942 , time : 38.585333585739136: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s]\n",
      "Epoch: 24. Validation. Loss: 3.799 , time : 2.136434555053711: 100%|██████████| 475/475 [00:02<00:00, 218.25it/s] \n",
      "Epoch: 25. Train.      Loss: 2.883 , time : 38.257389545440674: 100%|██████████| 1898/1898 [00:38<00:00, 49.56it/s]\n",
      "Epoch: 25. Validation. Loss: 3.754 , time : 2.163972854614258: 100%|██████████| 475/475 [00:02<00:00, 215.53it/s] \n",
      "Epoch: 26. Train.      Loss: 2.836 , time : 38.61140990257263: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 26. Validation. Loss: 3.744 , time : 2.186640501022339: 100%|██████████| 475/475 [00:02<00:00, 213.26it/s] \n",
      "Epoch: 27. Train.      Loss: 2.782 , time : 39.01813721656799: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 27. Validation. Loss: 3.755 , time : 2.201249122619629: 100%|██████████| 475/475 [00:02<00:00, 211.90it/s] \n",
      "Epoch: 28. Train.      Loss: 2.733 , time : 38.51806569099426: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 28. Validation. Loss: 3.731 , time : 2.1895315647125244: 100%|██████████| 475/475 [00:02<00:00, 213.03it/s]\n",
      "Epoch: 29. Train.      Loss: 2.687 , time : 39.069063901901245: 100%|██████████| 1898/1898 [00:39<00:00, 48.53it/s]\n",
      "Epoch: 29. Validation. Loss: 3.717 , time : 2.1364686489105225: 100%|██████████| 475/475 [00:02<00:00, 218.15it/s]\n",
      "Epoch: 30. Train.      Loss: 2.639 , time : 38.50304841995239: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 30. Validation. Loss: 3.694 , time : 2.0972132682800293: 100%|██████████| 475/475 [00:02<00:00, 222.22it/s]\n",
      "Epoch: 31. Train.      Loss: 2.601 , time : 38.87507343292236: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 31. Validation. Loss: 3.689 , time : 2.1374454498291016: 100%|██████████| 475/475 [00:02<00:00, 218.20it/s]\n",
      "Epoch: 32. Train.      Loss: 2.556 , time : 38.599400997161865: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s]\n",
      "Epoch: 32. Validation. Loss: 3.668 , time : 2.2151026725769043: 100%|██████████| 475/475 [00:02<00:00, 210.46it/s]\n",
      "Epoch: 33. Train.      Loss: 2.518 , time : 38.50403451919556: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 33. Validation. Loss: 3.653 , time : 2.2079179286956787: 100%|██████████| 475/475 [00:02<00:00, 211.26it/s]\n",
      "Epoch: 34. Train.      Loss: 2.477 , time : 38.67526292800903: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 34. Validation. Loss: 3.702 , time : 2.176676034927368: 100%|██████████| 475/475 [00:02<00:00, 214.13it/s] \n",
      "Epoch: 35. Train.      Loss: 2.435 , time : 39.13431692123413: 100%|██████████| 1898/1898 [00:39<00:00, 48.45it/s] \n",
      "Epoch: 35. Validation. Loss: 3.680 , time : 2.2146074771881104: 100%|██████████| 475/475 [00:02<00:00, 210.59it/s]\n",
      "Epoch: 36. Train.      Loss: 2.403 , time : 38.80181908607483: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 36. Validation. Loss: 3.662 , time : 2.1633803844451904: 100%|██████████| 475/475 [00:02<00:00, 215.59it/s]\n",
      "Epoch: 37. Train.      Loss: 2.366 , time : 38.889270305633545: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 37. Validation. Loss: 3.674 , time : 2.1648001670837402: 100%|██████████| 475/475 [00:02<00:00, 215.41it/s]\n",
      "Epoch: 38. Train.      Loss: 2.328 , time : 38.68906927108765: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 38. Validation. Loss: 3.691 , time : 2.158217430114746: 100%|██████████| 475/475 [00:02<00:00, 216.04it/s] \n",
      "Epoch: 39. Train.      Loss: 2.299 , time : 38.32687759399414: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s] \n",
      "Epoch: 39. Validation. Loss: 3.640 , time : 2.1150574684143066: 100%|██████████| 475/475 [00:02<00:00, 220.42it/s]\n",
      "Epoch: 40. Train.      Loss: 2.264 , time : 38.66769099235535: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s] \n",
      "Epoch: 40. Validation. Loss: 3.684 , time : 2.165595769882202: 100%|██████████| 475/475 [00:02<00:00, 215.31it/s] \n",
      "Epoch: 41. Train.      Loss: 2.231 , time : 38.65156936645508: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 41. Validation. Loss: 3.628 , time : 2.133613109588623: 100%|██████████| 475/475 [00:02<00:00, 218.33it/s] \n",
      "Epoch: 42. Train.      Loss: 2.202 , time : 38.68430256843567: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 42. Validation. Loss: 3.685 , time : 2.1373348236083984: 100%|██████████| 475/475 [00:02<00:00, 218.20it/s]\n",
      "Epoch: 43. Train.      Loss: 2.173 , time : 38.45178556442261: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s] \n",
      "Epoch: 43. Validation. Loss: 3.650 , time : 2.099897861480713: 100%|██████████| 475/475 [00:02<00:00, 221.80it/s] \n",
      "Epoch: 44. Train.      Loss: 2.141 , time : 38.8109929561615: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s]  \n",
      "Epoch: 44. Validation. Loss: 3.695 , time : 2.120771646499634: 100%|██████████| 475/475 [00:02<00:00, 217.66it/s] \n",
      "Epoch: 45. Train.      Loss: 2.108 , time : 38.51363706588745: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s] \n",
      "Epoch: 45. Validation. Loss: 3.669 , time : 2.1127569675445557: 100%|██████████| 475/475 [00:02<00:00, 220.65it/s]\n",
      "Epoch: 46. Train.      Loss: 2.083 , time : 38.475441694259644: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s]\n",
      "Epoch: 46. Validation. Loss: 3.759 , time : 2.1729302406311035: 100%|██████████| 475/475 [00:02<00:00, 214.48it/s]\n",
      "Epoch: 47. Train.      Loss: 2.054 , time : 38.441285371780396: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s]\n",
      "Epoch: 47. Validation. Loss: 3.695 , time : 2.174654483795166: 100%|██████████| 475/475 [00:02<00:00, 214.50it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20499... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.08326</td></tr><tr><td>Min_Val_Loss</td><td>3.62779</td></tr><tr><td>Val_Loss</td><td>3.75935</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">amber-sweep-49</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/w5qt6oxa\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/w5qt6oxa</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_005852-w5qt6oxa/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jqid68u5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jqid68u5\" target=\"_blank\">autumn-sweep-50</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.070 , time : 38.78689193725586: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 0. Validation. Loss: 3.784 , time : 2.150089979171753: 100%|██████████| 475/475 [00:02<00:00, 216.89it/s] \n",
      "Epoch: 1. Train.      Loss: 2.000 , time : 38.35046744346619: 100%|██████████| 1898/1898 [00:38<00:00, 49.44it/s] \n",
      "Epoch: 1. Validation. Loss: 3.737 , time : 2.1384520530700684: 100%|██████████| 475/475 [00:02<00:00, 217.99it/s]\n",
      "Epoch: 2. Train.      Loss: 1.971 , time : 38.656652212142944: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]\n",
      "Epoch: 2. Validation. Loss: 3.765 , time : 2.1592187881469727: 100%|██████████| 475/475 [00:02<00:00, 215.33it/s]\n",
      "Epoch: 3. Train.      Loss: 1.947 , time : 38.47021436691284: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 3. Validation. Loss: 3.815 , time : 2.1384782791137695: 100%|██████████| 475/475 [00:02<00:00, 218.00it/s]\n",
      "Epoch: 4. Train.      Loss: 1.919 , time : 38.40913772583008: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s] \n",
      "Epoch: 4. Validation. Loss: 3.755 , time : 2.153728723526001: 100%|██████████| 475/475 [00:02<00:00, 216.43it/s] \n",
      "Epoch: 5. Train.      Loss: 1.893 , time : 39.57608985900879: 100%|██████████| 1898/1898 [00:39<00:00, 47.91it/s] \n",
      "Epoch: 5. Validation. Loss: 3.836 , time : 2.1842007637023926: 100%|██████████| 475/475 [00:02<00:00, 213.54it/s]\n",
      "Epoch: 6. Train.      Loss: 1.867 , time : 38.795032262802124: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s]\n",
      "Epoch: 6. Validation. Loss: 3.782 , time : 2.1368556022644043: 100%|██████████| 475/475 [00:02<00:00, 218.03it/s]\n",
      "Epoch: 7. Train.      Loss: 1.844 , time : 38.64187026023865: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 7. Validation. Loss: 3.867 , time : 2.159646987915039: 100%|██████████| 475/475 [00:02<00:00, 215.99it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28995... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▃▆▂█▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.86663</td></tr><tr><td>Min_Val_Loss</td><td>3.73674</td></tr><tr><td>Val_Loss</td><td>3.78221</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">autumn-sweep-50</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jqid68u5\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/jqid68u5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_013146-jqid68u5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 997yi4tt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/997yi4tt\" target=\"_blank\">peach-sweep-51</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.861 , time : 38.948134899139404: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s]\n",
      "Epoch: 0. Validation. Loss: 3.871 , time : 2.1734397411346436: 100%|██████████| 475/475 [00:02<00:00, 214.42it/s]\n",
      "Epoch: 1. Train.      Loss: 1.804 , time : 38.49648952484131: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 1. Validation. Loss: 3.830 , time : 2.1425178050994873: 100%|██████████| 475/475 [00:02<00:00, 217.31it/s]\n",
      "Epoch: 2. Train.      Loss: 1.782 , time : 38.655837059020996: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]\n",
      "Epoch: 2. Validation. Loss: 3.904 , time : 2.1714718341827393: 100%|██████████| 475/475 [00:02<00:00, 214.84it/s]\n",
      "Epoch: 3. Train.      Loss: 1.757 , time : 38.696223735809326: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 3. Validation. Loss: 3.918 , time : 2.1904075145721436: 100%|██████████| 475/475 [00:02<00:00, 212.69it/s]\n",
      "Epoch: 4. Train.      Loss: 1.735 , time : 38.66158604621887: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 4. Validation. Loss: 3.938 , time : 2.204592704772949: 100%|██████████| 475/475 [00:02<00:00, 211.65it/s] \n",
      "Epoch: 5. Train.      Loss: 1.715 , time : 38.72137188911438: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 5. Validation. Loss: 3.959 , time : 2.218501091003418: 100%|██████████| 475/475 [00:02<00:00, 210.33it/s] \n",
      "Epoch: 6. Train.      Loss: 1.691 , time : 38.864163398742676: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]\n",
      "Epoch: 6. Validation. Loss: 3.962 , time : 2.1385767459869385: 100%|██████████| 475/475 [00:02<00:00, 218.00it/s]\n",
      "Epoch: 7. Train.      Loss: 1.673 , time : 38.80480909347534: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 7. Validation. Loss: 4.037 , time : 2.233583450317383: 100%|██████████| 475/475 [00:02<00:00, 208.92it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30485... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.69069</td></tr><tr><td>Min_Val_Loss</td><td>3.83033</td></tr><tr><td>Val_Loss</td><td>3.96245</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">peach-sweep-51</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/997yi4tt\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/997yi4tt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_013726-997yi4tt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: akpe7a9s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/akpe7a9s\" target=\"_blank\">polar-sweep-52</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.691 , time : 38.563141107559204: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s]\n",
      "Epoch: 0. Validation. Loss: 4.018 , time : 2.1408181190490723: 100%|██████████| 475/475 [00:02<00:00, 217.38it/s]\n",
      "Epoch: 1. Train.      Loss: 1.638 , time : 38.57184863090515: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 1. Validation. Loss: 4.072 , time : 2.1541147232055664: 100%|██████████| 475/475 [00:02<00:00, 216.48it/s]\n",
      "Epoch: 2. Train.      Loss: 1.620 , time : 38.7895929813385: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]  \n",
      "Epoch: 2. Validation. Loss: 4.086 , time : 2.2101221084594727: 100%|██████████| 475/475 [00:02<00:00, 211.14it/s]\n",
      "Epoch: 3. Train.      Loss: 1.602 , time : 38.80476474761963: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 3. Validation. Loss: 4.142 , time : 2.1251060962677: 100%|██████████| 475/475 [00:02<00:00, 219.25it/s]   \n",
      "Epoch: 4. Train.      Loss: 1.582 , time : 38.83266234397888: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 4. Validation. Loss: 4.110 , time : 2.1557838916778564: 100%|██████████| 475/475 [00:02<00:00, 216.33it/s]\n",
      "Epoch: 5. Train.      Loss: 1.566 , time : 39.175272941589355: 100%|██████████| 1898/1898 [00:39<00:00, 48.40it/s]\n",
      "Epoch: 5. Validation. Loss: 4.055 , time : 2.1211671829223633: 100%|██████████| 475/475 [00:02<00:00, 219.87it/s]\n",
      "Epoch: 6. Train.      Loss: 1.548 , time : 38.092344999313354: 100%|██████████| 1898/1898 [00:38<00:00, 49.77it/s]\n",
      "Epoch: 6. Validation. Loss: 4.113 , time : 2.1519486904144287: 100%|██████████| 475/475 [00:02<00:00, 216.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31962... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄▅█▆▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.56555</td></tr><tr><td>Min_Val_Loss</td><td>4.01821</td></tr><tr><td>Val_Loss</td><td>4.05474</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">polar-sweep-52</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/akpe7a9s\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/akpe7a9s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_014305-akpe7a9s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 833swpch with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/833swpch\" target=\"_blank\">sparkling-sweep-53</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.457 , time : 23.710232496261597: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s]\n",
      "Epoch: 0. Validation. Loss: 4.123 , time : 2.242476224899292: 100%|██████████| 475/475 [00:02<00:00, 207.99it/s] \n",
      "Epoch: 1. Train.      Loss: 1.442 , time : 23.74672532081604: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s] \n",
      "Epoch: 1. Validation. Loss: 4.127 , time : 2.089642286300659: 100%|██████████| 475/475 [00:02<00:00, 222.98it/s] \n",
      "Epoch: 2. Train.      Loss: 1.434 , time : 23.663803339004517: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]\n",
      "Epoch: 2. Validation. Loss: 4.121 , time : 2.17409086227417: 100%|██████████| 475/475 [00:02<00:00, 214.48it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.428 , time : 23.730327129364014: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s]\n",
      "Epoch: 3. Validation. Loss: 4.124 , time : 2.155935049057007: 100%|██████████| 475/475 [00:02<00:00, 216.31it/s] \n",
      "Epoch: 4. Train.      Loss: 1.424 , time : 23.55238127708435: 100%|██████████| 1898/1898 [00:23<00:00, 80.44it/s] \n",
      "Epoch: 4. Validation. Loss: 4.123 , time : 2.0924558639526367: 100%|██████████| 475/475 [00:02<00:00, 222.62it/s]\n",
      "Epoch: 5. Train.      Loss: 1.420 , time : 23.717036724090576: 100%|██████████| 1898/1898 [00:23<00:00, 79.89it/s]\n",
      "Epoch: 5. Validation. Loss: 4.134 , time : 2.1868197917938232: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s]\n",
      "Epoch: 6. Train.      Loss: 1.418 , time : 23.78999423980713: 100%|██████████| 1898/1898 [00:23<00:00, 79.64it/s] \n",
      "Epoch: 6. Validation. Loss: 4.132 , time : 2.0942845344543457: 100%|██████████| 475/475 [00:02<00:00, 222.36it/s]\n",
      "Epoch: 7. Train.      Loss: 1.415 , time : 23.514862537384033: 100%|██████████| 1898/1898 [00:23<00:00, 80.58it/s]\n",
      "Epoch: 7. Validation. Loss: 4.131 , time : 2.1152472496032715: 100%|██████████| 475/475 [00:02<00:00, 220.41it/s]\n",
      "Epoch: 8. Train.      Loss: 1.412 , time : 23.990185976028442: 100%|██████████| 1898/1898 [00:24<00:00, 78.97it/s]\n",
      "Epoch: 8. Validation. Loss: 4.148 , time : 2.1353955268859863: 100%|██████████| 475/475 [00:02<00:00, 218.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 915... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▄▁▃▂█▇▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.41488</td></tr><tr><td>Min_Val_Loss</td><td>4.12057</td></tr><tr><td>Val_Loss</td><td>4.13103</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sparkling-sweep-53</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/833swpch\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/833swpch</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_014802-833swpch/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1g8b4uxv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1g8b4uxv\" target=\"_blank\">earthy-sweep-54</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.412 , time : 23.65268111228943: 100%|██████████| 1898/1898 [00:23<00:00, 80.10it/s] \n",
      "Epoch: 0. Validation. Loss: 4.156 , time : 2.211399793624878: 100%|██████████| 475/475 [00:02<00:00, 210.98it/s] \n",
      "Epoch: 1. Train.      Loss: 1.409 , time : 23.64487862586975: 100%|██████████| 1898/1898 [00:23<00:00, 80.13it/s] \n",
      "Epoch: 1. Validation. Loss: 4.143 , time : 2.176931142807007: 100%|██████████| 475/475 [00:02<00:00, 214.18it/s] \n",
      "Epoch: 2. Train.      Loss: 1.408 , time : 23.582293272018433: 100%|██████████| 1898/1898 [00:23<00:00, 80.34it/s]\n",
      "Epoch: 2. Validation. Loss: 4.157 , time : 2.226632595062256: 100%|██████████| 475/475 [00:02<00:00, 209.55it/s] \n",
      "Epoch: 3. Train.      Loss: 1.407 , time : 23.97078251838684: 100%|██████████| 1898/1898 [00:24<00:00, 79.05it/s] \n",
      "Epoch: 3. Validation. Loss: 4.146 , time : 2.1463587284088135: 100%|██████████| 475/475 [00:02<00:00, 217.25it/s]\n",
      "Epoch: 4. Train.      Loss: 1.405 , time : 23.717523097991943: 100%|██████████| 1898/1898 [00:23<00:00, 79.89it/s]\n",
      "Epoch: 4. Validation. Loss: 4.155 , time : 2.2162859439849854: 100%|██████████| 475/475 [00:02<00:00, 210.48it/s]\n",
      "Epoch: 5. Train.      Loss: 1.405 , time : 23.734000205993652: 100%|██████████| 1898/1898 [00:23<00:00, 79.83it/s]\n",
      "Epoch: 5. Validation. Loss: 4.157 , time : 2.1409263610839844: 100%|██████████| 475/475 [00:02<00:00, 217.81it/s]\n",
      "Epoch: 6. Train.      Loss: 1.403 , time : 23.811942100524902: 100%|██████████| 1898/1898 [00:23<00:00, 79.57it/s]\n",
      "Epoch: 6. Validation. Loss: 4.176 , time : 2.1606032848358154: 100%|██████████| 475/475 [00:02<00:00, 213.88it/s]\n",
      "Epoch: 7. Train.      Loss: 1.402 , time : 23.663462162017822: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]\n",
      "Epoch: 7. Validation. Loss: 4.179 , time : 2.1167285442352295: 100%|██████████| 475/475 [00:02<00:00, 220.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2116... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▄▂▄▄█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.40348</td></tr><tr><td>Min_Val_Loss</td><td>4.14303</td></tr><tr><td>Val_Loss</td><td>4.1757</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">earthy-sweep-54</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1g8b4uxv\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1g8b4uxv</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_015207-1g8b4uxv/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aksvhagq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aksvhagq\" target=\"_blank\">polished-sweep-55</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.402 , time : 23.614864110946655: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]\n",
      "Epoch: 0. Validation. Loss: 4.174 , time : 2.138245105743408: 100%|██████████| 475/475 [00:02<00:00, 218.05it/s] \n",
      "Epoch: 1. Train.      Loss: 1.400 , time : 23.813122749328613: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s]\n",
      "Epoch: 1. Validation. Loss: 4.182 , time : 2.209080934524536: 100%|██████████| 475/475 [00:02<00:00, 211.17it/s] \n",
      "Epoch: 2. Train.      Loss: 1.399 , time : 23.770073890686035: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s]\n",
      "Epoch: 2. Validation. Loss: 4.172 , time : 2.1756374835968018: 100%|██████████| 475/475 [00:02<00:00, 214.29it/s]\n",
      "Epoch: 3. Train.      Loss: 1.399 , time : 23.46851634979248: 100%|██████████| 1898/1898 [00:23<00:00, 80.74it/s] \n",
      "Epoch: 3. Validation. Loss: 4.179 , time : 2.163910388946533: 100%|██████████| 475/475 [00:02<00:00, 215.55it/s] \n",
      "Epoch: 4. Train.      Loss: 1.398 , time : 24.018147230148315: 100%|██████████| 1898/1898 [00:24<00:00, 78.89it/s]\n",
      "Epoch: 4. Validation. Loss: 4.175 , time : 2.2183661460876465: 100%|██████████| 475/475 [00:02<00:00, 210.33it/s]\n",
      "Epoch: 5. Train.      Loss: 1.398 , time : 23.546694040298462: 100%|██████████| 1898/1898 [00:23<00:00, 80.47it/s]\n",
      "Epoch: 5. Validation. Loss: 4.178 , time : 2.251182794570923: 100%|██████████| 475/475 [00:02<00:00, 207.16it/s] \n",
      "Epoch: 6. Train.      Loss: 1.396 , time : 23.77526831626892: 100%|██████████| 1898/1898 [00:23<00:00, 79.69it/s] \n",
      "Epoch: 6. Validation. Loss: 4.187 , time : 2.103766918182373: 100%|██████████| 475/475 [00:02<00:00, 220.49it/s] \n",
      "Epoch: 7. Train.      Loss: 1.396 , time : 23.798972129821777: 100%|██████████| 1898/1898 [00:23<00:00, 79.61it/s]\n",
      "Epoch: 7. Validation. Loss: 4.193 , time : 2.2322747707366943: 100%|██████████| 475/475 [00:02<00:00, 208.93it/s]\n",
      "Epoch: 8. Train.      Loss: 1.396 , time : 23.938090801239014: 100%|██████████| 1898/1898 [00:23<00:00, 79.09it/s]\n",
      "Epoch: 8. Validation. Loss: 4.182 , time : 2.3100953102111816: 100%|██████████| 475/475 [00:02<00:00, 201.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3147... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▃▃▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▄▁▄▂▃▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.39649</td></tr><tr><td>Min_Val_Loss</td><td>4.17166</td></tr><tr><td>Val_Loss</td><td>4.19269</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">polished-sweep-55</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aksvhagq\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/aksvhagq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_015546-aksvhagq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xgalsfjx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/xgalsfjx\" target=\"_blank\">glamorous-sweep-56</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.394 , time : 23.707818746566772: 100%|██████████| 1898/1898 [00:23<00:00, 79.92it/s]\n",
      "Epoch: 0. Validation. Loss: 4.193 , time : 2.161813259124756: 100%|██████████| 475/475 [00:02<00:00, 215.55it/s] \n",
      "Epoch: 1. Train.      Loss: 1.394 , time : 23.690043687820435: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 1. Validation. Loss: 4.197 , time : 2.166045665740967: 100%|██████████| 475/475 [00:02<00:00, 215.67it/s] \n",
      "Epoch: 2. Train.      Loss: 1.393 , time : 23.6934232711792: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s]  \n",
      "Epoch: 2. Validation. Loss: 4.220 , time : 2.107245445251465: 100%|██████████| 475/475 [00:02<00:00, 221.24it/s] \n",
      "Epoch: 3. Train.      Loss: 1.393 , time : 23.42060899734497: 100%|██████████| 1898/1898 [00:23<00:00, 80.90it/s] \n",
      "Epoch: 3. Validation. Loss: 4.207 , time : 2.1844887733459473: 100%|██████████| 475/475 [00:02<00:00, 213.55it/s]\n",
      "Epoch: 4. Train.      Loss: 1.391 , time : 23.57760524749756: 100%|██████████| 1898/1898 [00:23<00:00, 80.36it/s] \n",
      "Epoch: 4. Validation. Loss: 4.212 , time : 2.1095356941223145: 100%|██████████| 475/475 [00:02<00:00, 220.99it/s]\n",
      "Epoch: 5. Train.      Loss: 1.391 , time : 23.670661687850952: 100%|██████████| 1898/1898 [00:23<00:00, 80.04it/s]\n",
      "Epoch: 5. Validation. Loss: 4.204 , time : 2.1655054092407227: 100%|██████████| 475/475 [00:02<00:00, 215.37it/s]\n",
      "Epoch: 6. Train.      Loss: 1.390 , time : 23.85722279548645: 100%|██████████| 1898/1898 [00:23<00:00, 79.42it/s] \n",
      "Epoch: 6. Validation. Loss: 4.228 , time : 2.1990890502929688: 100%|██████████| 475/475 [00:02<00:00, 212.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4277... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▅▁▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂█▅▆▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.39091</td></tr><tr><td>Min_Val_Loss</td><td>4.19307</td></tr><tr><td>Val_Loss</td><td>4.20409</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glamorous-sweep-56</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/xgalsfjx\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/xgalsfjx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_015951-xgalsfjx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eljpxzqb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/eljpxzqb\" target=\"_blank\">glowing-sweep-57</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.136 , time : 38.23452687263489: 100%|██████████| 1898/1898 [00:38<00:00, 49.59it/s] \n",
      "Epoch: 0. Validation. Loss: 6.176 , time : 2.208986282348633: 100%|██████████| 475/475 [00:02<00:00, 211.18it/s] \n",
      "Epoch: 1. Train.      Loss: 5.861 , time : 38.16780638694763: 100%|██████████| 1898/1898 [00:38<00:00, 49.67it/s] \n",
      "Epoch: 1. Validation. Loss: 6.020 , time : 2.1757683753967285: 100%|██████████| 475/475 [00:02<00:00, 214.38it/s]\n",
      "Epoch: 2. Train.      Loss: 5.641 , time : 38.535484790802: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s]   \n",
      "Epoch: 2. Validation. Loss: 5.826 , time : 2.240088939666748: 100%|██████████| 475/475 [00:02<00:00, 208.18it/s] \n",
      "Epoch: 3. Train.      Loss: 5.378 , time : 38.454306840896606: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]\n",
      "Epoch: 3. Validation. Loss: 5.610 , time : 2.237344264984131: 100%|██████████| 475/475 [00:02<00:00, 208.56it/s] \n",
      "Epoch: 4. Train.      Loss: 5.095 , time : 38.92735505104065: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 4. Validation. Loss: 5.362 , time : 2.1377711296081543: 100%|██████████| 475/475 [00:02<00:00, 218.12it/s]\n",
      "Epoch: 5. Train.      Loss: 4.832 , time : 38.39583206176758: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 5. Validation. Loss: 5.125 , time : 2.143167495727539: 100%|██████████| 475/475 [00:02<00:00, 217.48it/s] \n",
      "Epoch: 6. Train.      Loss: 4.608 , time : 38.0557758808136: 100%|██████████| 1898/1898 [00:38<00:00, 49.82it/s]  \n",
      "Epoch: 6. Validation. Loss: 4.947 , time : 2.264315366744995: 100%|██████████| 475/475 [00:02<00:00, 206.14it/s] \n",
      "Epoch: 7. Train.      Loss: 4.418 , time : 38.7894492149353: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]  \n",
      "Epoch: 7. Validation. Loss: 4.806 , time : 2.1899023056030273: 100%|██████████| 475/475 [00:02<00:00, 213.06it/s]\n",
      "Epoch: 8. Train.      Loss: 4.255 , time : 38.26170229911804: 100%|██████████| 1898/1898 [00:38<00:00, 49.55it/s] \n",
      "Epoch: 8. Validation. Loss: 4.658 , time : 2.1712794303894043: 100%|██████████| 475/475 [00:02<00:00, 214.82it/s]\n",
      "Epoch: 9. Train.      Loss: 4.113 , time : 38.606202125549316: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]\n",
      "Epoch: 9. Validation. Loss: 4.566 , time : 2.1815848350524902: 100%|██████████| 475/475 [00:02<00:00, 213.80it/s]\n",
      "Epoch: 10. Train.      Loss: 3.983 , time : 39.209824562072754: 100%|██████████| 1898/1898 [00:39<00:00, 48.34it/s]\n",
      "Epoch: 10. Validation. Loss: 4.485 , time : 2.158329486846924: 100%|██████████| 475/475 [00:02<00:00, 216.07it/s] \n",
      "Epoch: 11. Train.      Loss: 3.870 , time : 38.48351788520813: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 11. Validation. Loss: 4.392 , time : 2.116719961166382: 100%|██████████| 475/475 [00:02<00:00, 220.08it/s] \n",
      "Epoch: 12. Train.      Loss: 3.764 , time : 38.55596375465393: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 12. Validation. Loss: 4.301 , time : 2.1391122341156006: 100%|██████████| 475/475 [00:02<00:00, 217.16it/s]\n",
      "Epoch: 13. Train.      Loss: 3.663 , time : 38.64980983734131: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 13. Validation. Loss: 4.271 , time : 2.127955675125122: 100%|██████████| 475/475 [00:02<00:00, 218.97it/s] \n",
      "Epoch: 14. Train.      Loss: 3.573 , time : 38.33179521560669: 100%|██████████| 1898/1898 [00:38<00:00, 49.46it/s] \n",
      "Epoch: 14. Validation. Loss: 4.176 , time : 2.1918258666992188: 100%|██████████| 475/475 [00:02<00:00, 212.79it/s]\n",
      "Epoch: 15. Train.      Loss: 3.492 , time : 38.56362771987915: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 15. Validation. Loss: 4.129 , time : 2.1397812366485596: 100%|██████████| 475/475 [00:02<00:00, 217.96it/s]\n",
      "Epoch: 16. Train.      Loss: 3.413 , time : 38.40756368637085: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 16. Validation. Loss: 4.095 , time : 2.069340229034424: 100%|██████████| 475/475 [00:02<00:00, 225.21it/s] \n",
      "Epoch: 17. Train.      Loss: 3.336 , time : 39.21483254432678: 100%|██████████| 1898/1898 [00:39<00:00, 48.35it/s] \n",
      "Epoch: 17. Validation. Loss: 4.087 , time : 2.1723971366882324: 100%|██████████| 475/475 [00:02<00:00, 214.29it/s]\n",
      "Epoch: 18. Train.      Loss: 3.269 , time : 39.15635919570923: 100%|██████████| 1898/1898 [00:39<00:00, 48.42it/s] \n",
      "Epoch: 18. Validation. Loss: 3.990 , time : 2.2153701782226562: 100%|██████████| 475/475 [00:02<00:00, 210.66it/s]\n",
      "Epoch: 19. Train.      Loss: 3.200 , time : 38.87536096572876: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 19. Validation. Loss: 3.975 , time : 2.152892827987671: 100%|██████████| 475/475 [00:02<00:00, 216.57it/s] \n",
      "Epoch: 20. Train.      Loss: 3.142 , time : 38.64402103424072: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 20. Validation. Loss: 3.962 , time : 2.1254518032073975: 100%|██████████| 475/475 [00:02<00:00, 217.52it/s]\n",
      "Epoch: 21. Train.      Loss: 3.080 , time : 38.77049517631531: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 21. Validation. Loss: 3.934 , time : 2.1821911334991455: 100%|██████████| 475/475 [00:02<00:00, 213.73it/s]\n",
      "Epoch: 22. Train.      Loss: 3.027 , time : 38.30254125595093: 100%|██████████| 1898/1898 [00:38<00:00, 49.50it/s] \n",
      "Epoch: 22. Validation. Loss: 3.903 , time : 2.1509711742401123: 100%|██████████| 475/475 [00:02<00:00, 216.77it/s]\n",
      "Epoch: 23. Train.      Loss: 2.976 , time : 38.32642602920532: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s] \n",
      "Epoch: 23. Validation. Loss: 3.899 , time : 2.109869956970215: 100%|██████████| 475/475 [00:02<00:00, 220.90it/s] \n",
      "Epoch: 24. Train.      Loss: 2.925 , time : 38.47154188156128: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 24. Validation. Loss: 3.874 , time : 2.119750738143921: 100%|██████████| 475/475 [00:02<00:00, 219.94it/s] \n",
      "Epoch: 25. Train.      Loss: 2.877 , time : 38.69523525238037: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 25. Validation. Loss: 3.891 , time : 2.182147264480591: 100%|██████████| 475/475 [00:02<00:00, 213.81it/s] \n",
      "Epoch: 26. Train.      Loss: 2.832 , time : 38.90436410903931: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 26. Validation. Loss: 3.909 , time : 2.118140697479248: 100%|██████████| 475/475 [00:02<00:00, 219.99it/s] \n",
      "Epoch: 27. Train.      Loss: 2.791 , time : 38.74040961265564: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 27. Validation. Loss: 3.838 , time : 2.1866824626922607: 100%|██████████| 475/475 [00:02<00:00, 213.30it/s]\n",
      "Epoch: 28. Train.      Loss: 2.747 , time : 37.842020988464355: 100%|██████████| 1898/1898 [00:37<00:00, 50.10it/s]\n",
      "Epoch: 28. Validation. Loss: 3.826 , time : 2.0896830558776855: 100%|██████████| 475/475 [00:02<00:00, 223.04it/s]\n",
      "Epoch: 29. Train.      Loss: 2.706 , time : 38.479873180389404: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]\n",
      "Epoch: 29. Validation. Loss: 3.847 , time : 2.141740083694458: 100%|██████████| 475/475 [00:02<00:00, 217.74it/s] \n",
      "Epoch: 30. Train.      Loss: 2.667 , time : 38.529865980148315: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]\n",
      "Epoch: 30. Validation. Loss: 3.819 , time : 2.1397955417633057: 100%|██████████| 475/475 [00:02<00:00, 217.93it/s]\n",
      "Epoch: 31. Train.      Loss: 2.635 , time : 38.29902243614197: 100%|██████████| 1898/1898 [00:38<00:00, 49.51it/s] \n",
      "Epoch: 31. Validation. Loss: 3.812 , time : 2.1376912593841553: 100%|██████████| 475/475 [00:02<00:00, 218.11it/s]\n",
      "Epoch: 32. Train.      Loss: 2.595 , time : 38.32523036003113: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s] \n",
      "Epoch: 32. Validation. Loss: 3.859 , time : 2.133401393890381: 100%|██████████| 475/475 [00:02<00:00, 218.56it/s] \n",
      "Epoch: 33. Train.      Loss: 2.560 , time : 38.57225298881531: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 33. Validation. Loss: 3.893 , time : 2.0979764461517334: 100%|██████████| 475/475 [00:02<00:00, 222.12it/s]\n",
      "Epoch: 34. Train.      Loss: 2.529 , time : 38.581161975860596: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s]\n",
      "Epoch: 34. Validation. Loss: 3.857 , time : 2.1182103157043457: 100%|██████████| 475/475 [00:02<00:00, 220.07it/s]\n",
      "Epoch: 35. Train.      Loss: 2.500 , time : 37.90451192855835: 100%|██████████| 1898/1898 [00:37<00:00, 50.02it/s] \n",
      "Epoch: 35. Validation. Loss: 3.849 , time : 2.1564908027648926: 100%|██████████| 475/475 [00:02<00:00, 216.13it/s]\n",
      "Epoch: 36. Train.      Loss: 2.466 , time : 38.25521969795227: 100%|██████████| 1898/1898 [00:38<00:00, 49.56it/s] \n",
      "Epoch: 36. Validation. Loss: 3.856 , time : 2.160217046737671: 100%|██████████| 475/475 [00:02<00:00, 215.84it/s] \n",
      "Epoch: 37. Train.      Loss: 2.435 , time : 38.30258893966675: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s] \n",
      "Epoch: 37. Validation. Loss: 3.897 , time : 2.1764183044433594: 100%|██████████| 475/475 [00:02<00:00, 212.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5184... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.46588</td></tr><tr><td>Min_Val_Loss</td><td>3.81192</td></tr><tr><td>Val_Loss</td><td>3.85642</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-57</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/eljpxzqb\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/eljpxzqb</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_020304-eljpxzqb/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 34mg4bxw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/34mg4bxw\" target=\"_blank\">morning-sweep-58</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.461 , time : 38.1277916431427: 100%|██████████| 1898/1898 [00:38<00:00, 49.73it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.880 , time : 2.0779316425323486: 100%|██████████| 475/475 [00:02<00:00, 222.35it/s]\n",
      "Epoch: 1. Train.      Loss: 2.380 , time : 38.58520221710205: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 1. Validation. Loss: 3.890 , time : 2.2056312561035156: 100%|██████████| 475/475 [00:02<00:00, 211.51it/s]\n",
      "Epoch: 2. Train.      Loss: 2.350 , time : 38.35493540763855: 100%|██████████| 1898/1898 [00:38<00:00, 49.43it/s] \n",
      "Epoch: 2. Validation. Loss: 3.950 , time : 2.1396992206573486: 100%|██████████| 475/475 [00:02<00:00, 217.91it/s]\n",
      "Epoch: 3. Train.      Loss: 2.323 , time : 38.447149991989136: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s]\n",
      "Epoch: 3. Validation. Loss: 3.932 , time : 2.154179573059082: 100%|██████████| 475/475 [00:02<00:00, 216.29it/s] \n",
      "Epoch: 4. Train.      Loss: 2.300 , time : 39.064213275909424: 100%|██████████| 1898/1898 [00:39<00:00, 48.54it/s]\n",
      "Epoch: 4. Validation. Loss: 3.914 , time : 2.1709351539611816: 100%|██████████| 475/475 [00:02<00:00, 214.77it/s]\n",
      "Epoch: 5. Train.      Loss: 2.268 , time : 38.37864327430725: 100%|██████████| 1898/1898 [00:38<00:00, 49.40it/s] \n",
      "Epoch: 5. Validation. Loss: 3.931 , time : 2.1824657917022705: 100%|██████████| 475/475 [00:02<00:00, 213.72it/s]\n",
      "Epoch: 6. Train.      Loss: 2.251 , time : 38.46529507637024: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s] \n",
      "Epoch: 6. Validation. Loss: 3.901 , time : 2.2168986797332764: 100%|██████████| 475/475 [00:02<00:00, 210.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11831... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂█▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.26817</td></tr><tr><td>Min_Val_Loss</td><td>3.8803</td></tr><tr><td>Val_Loss</td><td>3.93144</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">morning-sweep-58</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/34mg4bxw\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/34mg4bxw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_022904-34mg4bxw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0pqs7ilr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pqs7ilr\" target=\"_blank\">autumn-sweep-59</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.275 , time : 38.60944199562073: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 0. Validation. Loss: 3.981 , time : 2.155578374862671: 100%|██████████| 475/475 [00:02<00:00, 216.12it/s] \n",
      "Epoch: 1. Train.      Loss: 2.200 , time : 38.590670108795166: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s]\n",
      "Epoch: 1. Validation. Loss: 3.946 , time : 2.178776741027832: 100%|██████████| 475/475 [00:02<00:00, 212.44it/s] \n",
      "Epoch: 2. Train.      Loss: 2.182 , time : 38.61001944541931: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 2. Validation. Loss: 3.921 , time : 2.241180896759033: 100%|██████████| 475/475 [00:02<00:00, 208.21it/s] \n",
      "Epoch: 3. Train.      Loss: 2.158 , time : 38.6042366027832: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]  \n",
      "Epoch: 3. Validation. Loss: 4.004 , time : 2.1278274059295654: 100%|██████████| 475/475 [00:02<00:00, 219.05it/s]\n",
      "Epoch: 4. Train.      Loss: 2.137 , time : 38.54990577697754: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 4. Validation. Loss: 4.013 , time : 2.1144819259643555: 100%|██████████| 475/475 [00:02<00:00, 218.74it/s]\n",
      "Epoch: 5. Train.      Loss: 2.119 , time : 38.51344871520996: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s] \n",
      "Epoch: 5. Validation. Loss: 4.014 , time : 2.1670875549316406: 100%|██████████| 475/475 [00:02<00:00, 215.14it/s]\n",
      "Epoch: 6. Train.      Loss: 2.096 , time : 38.605098485946655: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]\n",
      "Epoch: 6. Validation. Loss: 4.081 , time : 2.1580753326416016: 100%|██████████| 475/475 [00:02<00:00, 215.94it/s]\n",
      "Epoch: 7. Train.      Loss: 2.077 , time : 38.42417573928833: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 7. Validation. Loss: 4.019 , time : 2.1389341354370117: 100%|██████████| 475/475 [00:02<00:00, 217.97it/s]\n",
      "Epoch: 8. Train.      Loss: 2.056 , time : 38.35619616508484: 100%|██████████| 1898/1898 [00:38<00:00, 49.43it/s] \n",
      "Epoch: 8. Validation. Loss: 4.048 , time : 2.2010648250579834: 100%|██████████| 475/475 [00:02<00:00, 211.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13144... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▂▁▅▅▅█▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.07688</td></tr><tr><td>Min_Val_Loss</td><td>3.92103</td></tr><tr><td>Val_Loss</td><td>4.019</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">autumn-sweep-59</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pqs7ilr\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pqs7ilr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_023402-0pqs7ilr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ehd1ri18 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ehd1ri18\" target=\"_blank\">apricot-sweep-60</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.080 , time : 38.07746696472168: 100%|██████████| 1898/1898 [00:38<00:00, 49.79it/s] \n",
      "Epoch: 0. Validation. Loss: 4.113 , time : 2.193469285964966: 100%|██████████| 475/475 [00:02<00:00, 212.53it/s] \n",
      "Epoch: 1. Train.      Loss: 2.024 , time : 38.41152834892273: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s] \n",
      "Epoch: 1. Validation. Loss: 4.071 , time : 2.197850465774536: 100%|██████████| 475/475 [00:02<00:00, 212.26it/s] \n",
      "Epoch: 2. Train.      Loss: 2.003 , time : 38.6590690612793: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]  \n",
      "Epoch: 2. Validation. Loss: 4.111 , time : 2.156263828277588: 100%|██████████| 475/475 [00:02<00:00, 216.24it/s] \n",
      "Epoch: 3. Train.      Loss: 1.988 , time : 38.693015575408936: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 3. Validation. Loss: 4.185 , time : 2.142190933227539: 100%|██████████| 475/475 [00:02<00:00, 217.69it/s] \n",
      "Epoch: 4. Train.      Loss: 1.971 , time : 38.62046480178833: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 4. Validation. Loss: 4.145 , time : 2.125673294067383: 100%|██████████| 475/475 [00:02<00:00, 219.23it/s] \n",
      "Epoch: 5. Train.      Loss: 1.951 , time : 38.36628174781799: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 5. Validation. Loss: 4.222 , time : 2.1311378479003906: 100%|██████████| 475/475 [00:02<00:00, 218.74it/s]\n",
      "Epoch: 6. Train.      Loss: 1.935 , time : 38.701765060424805: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 6. Validation. Loss: 4.235 , time : 2.1248321533203125: 100%|██████████| 475/475 [00:02<00:00, 218.67it/s]\n",
      "Epoch: 7. Train.      Loss: 1.924 , time : 38.58282828330994: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 7. Validation. Loss: 4.188 , time : 2.130703926086426: 100%|██████████| 475/475 [00:02<00:00, 218.62it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14788... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▃▆▄▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.93539</td></tr><tr><td>Min_Val_Loss</td><td>4.07076</td></tr><tr><td>Val_Loss</td><td>4.23508</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">apricot-sweep-60</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ehd1ri18\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ehd1ri18</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_024022-ehd1ri18/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yrlsf5hf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/yrlsf5hf\" target=\"_blank\">dauntless-sweep-61</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.825 , time : 23.621293544769287: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]\n",
      "Epoch: 0. Validation. Loss: 4.195 , time : 2.1607184410095215: 100%|██████████| 475/475 [00:02<00:00, 215.77it/s]\n",
      "Epoch: 1. Train.      Loss: 1.810 , time : 23.65035057067871: 100%|██████████| 1898/1898 [00:23<00:00, 80.11it/s] \n",
      "Epoch: 1. Validation. Loss: 4.193 , time : 2.1169207096099854: 100%|██████████| 475/475 [00:02<00:00, 220.19it/s]\n",
      "Epoch: 2. Train.      Loss: 1.802 , time : 23.490736722946167: 100%|██████████| 1898/1898 [00:23<00:00, 80.65it/s]\n",
      "Epoch: 2. Validation. Loss: 4.194 , time : 2.1508357524871826: 100%|██████████| 475/475 [00:02<00:00, 216.60it/s]\n",
      "Epoch: 3. Train.      Loss: 1.798 , time : 23.68515968322754: 100%|██████████| 1898/1898 [00:23<00:00, 79.93it/s] \n",
      "Epoch: 3. Validation. Loss: 4.186 , time : 2.126352310180664: 100%|██████████| 475/475 [00:02<00:00, 216.48it/s] \n",
      "Epoch: 4. Train.      Loss: 1.793 , time : 23.575859308242798: 100%|██████████| 1898/1898 [00:23<00:00, 80.36it/s]\n",
      "Epoch: 4. Validation. Loss: 4.212 , time : 2.090217351913452: 100%|██████████| 475/475 [00:02<00:00, 222.93it/s] \n",
      "Epoch: 5. Train.      Loss: 1.789 , time : 23.6346116065979: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s]  \n",
      "Epoch: 5. Validation. Loss: 4.192 , time : 2.1650805473327637: 100%|██████████| 475/475 [00:02<00:00, 215.43it/s]\n",
      "Epoch: 6. Train.      Loss: 1.787 , time : 23.88439393043518: 100%|██████████| 1898/1898 [00:23<00:00, 79.32it/s] \n",
      "Epoch: 6. Validation. Loss: 4.204 , time : 2.1740598678588867: 100%|██████████| 475/475 [00:02<00:00, 214.53it/s]\n",
      "Epoch: 7. Train.      Loss: 1.786 , time : 23.688417434692383: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 7. Validation. Loss: 4.204 , time : 2.0902929306030273: 100%|██████████| 475/475 [00:02<00:00, 222.89it/s]\n",
      "Epoch: 8. Train.      Loss: 1.782 , time : 23.45080256462097: 100%|██████████| 1898/1898 [00:23<00:00, 80.79it/s] \n",
      "Epoch: 8. Validation. Loss: 4.206 , time : 2.119687557220459: 100%|██████████| 475/475 [00:02<00:00, 219.78it/s] \n",
      "Epoch: 9. Train.      Loss: 1.779 , time : 23.27513337135315: 100%|██████████| 1898/1898 [00:23<00:00, 81.40it/s] \n",
      "Epoch: 9. Validation. Loss: 4.213 , time : 2.1082983016967773: 100%|██████████| 475/475 [00:02<00:00, 219.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16280... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▃▂▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▇▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▃▁█▃▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.78191</td></tr><tr><td>Min_Val_Loss</td><td>4.18578</td></tr><tr><td>Val_Loss</td><td>4.20601</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dauntless-sweep-61</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/yrlsf5hf\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/yrlsf5hf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_024601-yrlsf5hf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s7ox97nu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s7ox97nu\" target=\"_blank\">cerulean-sweep-62</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.778 , time : 23.57106304168701: 100%|██████████| 1898/1898 [00:23<00:00, 80.38it/s] \n",
      "Epoch: 0. Validation. Loss: 4.202 , time : 2.1849496364593506: 100%|██████████| 475/475 [00:02<00:00, 213.47it/s]\n",
      "Epoch: 1. Train.      Loss: 1.777 , time : 23.54637575149536: 100%|██████████| 1898/1898 [00:23<00:00, 80.47it/s] \n",
      "Epoch: 1. Validation. Loss: 4.213 , time : 2.141911029815674: 100%|██████████| 475/475 [00:02<00:00, 217.63it/s] \n",
      "Epoch: 2. Train.      Loss: 1.776 , time : 23.45725703239441: 100%|██████████| 1898/1898 [00:23<00:00, 80.77it/s] \n",
      "Epoch: 2. Validation. Loss: 4.211 , time : 2.121297836303711: 100%|██████████| 475/475 [00:02<00:00, 219.57it/s] \n",
      "Epoch: 3. Train.      Loss: 1.774 , time : 23.373828887939453: 100%|██████████| 1898/1898 [00:23<00:00, 81.06it/s]\n",
      "Epoch: 3. Validation. Loss: 4.221 , time : 2.2714900970458984: 100%|██████████| 475/475 [00:02<00:00, 205.26it/s]\n",
      "Epoch: 4. Train.      Loss: 1.773 , time : 23.73016357421875: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s] \n",
      "Epoch: 4. Validation. Loss: 4.228 , time : 2.278383731842041: 100%|██████████| 475/475 [00:02<00:00, 204.69it/s] \n",
      "Epoch: 5. Train.      Loss: 1.772 , time : 23.621761798858643: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]\n",
      "Epoch: 5. Validation. Loss: 4.235 , time : 2.171293020248413: 100%|██████████| 475/475 [00:02<00:00, 214.66it/s] \n",
      "Epoch: 6. Train.      Loss: 1.771 , time : 23.074281454086304: 100%|██████████| 1898/1898 [00:23<00:00, 82.11it/s]\n",
      "Epoch: 6. Validation. Loss: 4.234 , time : 2.1343886852264404: 100%|██████████| 475/475 [00:02<00:00, 218.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17415... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▃▅▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.77234</td></tr><tr><td>Min_Val_Loss</td><td>4.2021</td></tr><tr><td>Val_Loss</td><td>4.235</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cerulean-sweep-62</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s7ox97nu\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s7ox97nu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_025032-s7ox97nu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q9balgyl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q9balgyl\" target=\"_blank\">swift-sweep-63</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.771 , time : 23.254425048828125: 100%|██████████| 1898/1898 [00:23<00:00, 81.48it/s]\n",
      "Epoch: 0. Validation. Loss: 4.242 , time : 2.1282870769500732: 100%|██████████| 475/475 [00:02<00:00, 218.89it/s]\n",
      "Epoch: 1. Train.      Loss: 1.770 , time : 23.45923376083374: 100%|██████████| 1898/1898 [00:23<00:00, 80.76it/s] \n",
      "Epoch: 1. Validation. Loss: 4.241 , time : 2.112912178039551: 100%|██████████| 475/475 [00:02<00:00, 220.59it/s] \n",
      "Epoch: 2. Train.      Loss: 1.768 , time : 23.227446794509888: 100%|██████████| 1898/1898 [00:23<00:00, 81.56it/s]\n",
      "Epoch: 2. Validation. Loss: 4.241 , time : 2.1101672649383545: 100%|██████████| 475/475 [00:02<00:00, 220.89it/s]\n",
      "Epoch: 3. Train.      Loss: 1.768 , time : 23.014175176620483: 100%|██████████| 1898/1898 [00:23<00:00, 82.32it/s]\n",
      "Epoch: 3. Validation. Loss: 4.257 , time : 2.0882935523986816: 100%|██████████| 475/475 [00:02<00:00, 223.18it/s]\n",
      "Epoch: 4. Train.      Loss: 1.767 , time : 23.17185616493225: 100%|██████████| 1898/1898 [00:23<00:00, 81.76it/s] \n",
      "Epoch: 4. Validation. Loss: 4.261 , time : 2.0708091259002686: 100%|██████████| 475/475 [00:02<00:00, 224.79it/s]\n",
      "Epoch: 5. Train.      Loss: 1.766 , time : 23.150519847869873: 100%|██████████| 1898/1898 [00:23<00:00, 81.84it/s]\n",
      "Epoch: 5. Validation. Loss: 4.244 , time : 2.101656675338745: 100%|██████████| 475/475 [00:02<00:00, 221.65it/s] \n",
      "Epoch: 6. Train.      Loss: 1.766 , time : 23.30041766166687: 100%|██████████| 1898/1898 [00:23<00:00, 81.32it/s] \n",
      "Epoch: 6. Validation. Loss: 4.259 , time : 2.155304193496704: 100%|██████████| 475/475 [00:02<00:00, 216.24it/s] \n",
      "Epoch: 7. Train.      Loss: 1.765 , time : 23.309653520584106: 100%|██████████| 1898/1898 [00:23<00:00, 81.28it/s]\n",
      "Epoch: 7. Validation. Loss: 4.255 , time : 2.102614164352417: 100%|██████████| 475/475 [00:02<00:00, 221.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17783... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▁▁▆█▂▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.76573</td></tr><tr><td>Min_Val_Loss</td><td>4.24065</td></tr><tr><td>Val_Loss</td><td>4.25852</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">swift-sweep-63</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q9balgyl\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/q9balgyl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_025345-q9balgyl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9cms6q7e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9cms6q7e\" target=\"_blank\">legendary-sweep-64</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.766 , time : 23.075918674468994: 100%|██████████| 1898/1898 [00:23<00:00, 82.10it/s]\n",
      "Epoch: 0. Validation. Loss: 4.265 , time : 2.0511128902435303: 100%|██████████| 475/475 [00:02<00:00, 227.04it/s]\n",
      "Epoch: 1. Train.      Loss: 1.764 , time : 22.97282910346985: 100%|██████████| 1898/1898 [00:23<00:00, 82.47it/s] \n",
      "Epoch: 1. Validation. Loss: 4.263 , time : 2.193438768386841: 100%|██████████| 475/475 [00:02<00:00, 212.58it/s] \n",
      "Epoch: 2. Train.      Loss: 1.763 , time : 23.14681077003479: 100%|██████████| 1898/1898 [00:23<00:00, 81.85it/s] \n",
      "Epoch: 2. Validation. Loss: 4.266 , time : 2.1138551235198975: 100%|██████████| 475/475 [00:02<00:00, 220.25it/s]\n",
      "Epoch: 3. Train.      Loss: 1.763 , time : 23.08315873146057: 100%|██████████| 1898/1898 [00:23<00:00, 82.08it/s] \n",
      "Epoch: 3. Validation. Loss: 4.278 , time : 2.075685501098633: 100%|██████████| 475/475 [00:02<00:00, 224.28it/s] \n",
      "Epoch: 4. Train.      Loss: 1.762 , time : 22.82898235321045: 100%|██████████| 1898/1898 [00:22<00:00, 82.99it/s] \n",
      "Epoch: 4. Validation. Loss: 4.289 , time : 2.15524959564209: 100%|██████████| 475/475 [00:02<00:00, 216.27it/s]  \n",
      "Epoch: 5. Train.      Loss: 1.762 , time : 23.026023626327515: 100%|██████████| 1898/1898 [00:23<00:00, 82.28it/s]\n",
      "Epoch: 5. Validation. Loss: 4.278 , time : 2.0854501724243164: 100%|██████████| 475/475 [00:02<00:00, 223.37it/s]\n",
      "Epoch: 6. Train.      Loss: 1.762 , time : 22.85476279258728: 100%|██████████| 1898/1898 [00:22<00:00, 82.89it/s] \n",
      "Epoch: 6. Validation. Loss: 4.285 , time : 2.1312155723571777: 100%|██████████| 475/475 [00:02<00:00, 218.71it/s]\n",
      "Epoch: 7. Train.      Loss: 1.760 , time : 22.729913473129272: 100%|██████████| 1898/1898 [00:22<00:00, 83.35it/s]\n",
      "Epoch: 7. Validation. Loss: 4.283 , time : 2.111541748046875: 100%|██████████| 475/475 [00:02<00:00, 220.70it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18271... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▁▂▅█▅▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.76158</td></tr><tr><td>Min_Val_Loss</td><td>4.26284</td></tr><tr><td>Val_Loss</td><td>4.28522</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">legendary-sweep-64</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9cms6q7e\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9cms6q7e</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_025719-9cms6q7e/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kepf7yjc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kepf7yjc\" target=\"_blank\">frosty-sweep-65</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.133 , time : 37.78418827056885: 100%|██████████| 1898/1898 [00:37<00:00, 50.18it/s] \n",
      "Epoch: 0. Validation. Loss: 6.152 , time : 2.1101014614105225: 100%|██████████| 475/475 [00:02<00:00, 220.80it/s]\n",
      "Epoch: 1. Train.      Loss: 5.829 , time : 37.45434832572937: 100%|██████████| 1898/1898 [00:37<00:00, 50.62it/s] \n",
      "Epoch: 1. Validation. Loss: 5.982 , time : 2.0883424282073975: 100%|██████████| 475/475 [00:02<00:00, 223.10it/s]\n",
      "Epoch: 2. Train.      Loss: 5.567 , time : 37.39149785041809: 100%|██████████| 1898/1898 [00:37<00:00, 50.70it/s] \n",
      "Epoch: 2. Validation. Loss: 5.755 , time : 2.0961852073669434: 100%|██████████| 475/475 [00:02<00:00, 222.24it/s]\n",
      "Epoch: 3. Train.      Loss: 5.259 , time : 38.38879942893982: 100%|██████████| 1898/1898 [00:38<00:00, 49.39it/s] \n",
      "Epoch: 3. Validation. Loss: 5.494 , time : 2.0851080417633057: 100%|██████████| 475/475 [00:02<00:00, 223.39it/s]\n",
      "Epoch: 4. Train.      Loss: 4.951 , time : 38.23716974258423: 100%|██████████| 1898/1898 [00:38<00:00, 49.58it/s] \n",
      "Epoch: 4. Validation. Loss: 5.234 , time : 2.171947717666626: 100%|██████████| 475/475 [00:02<00:00, 214.20it/s] \n",
      "Epoch: 5. Train.      Loss: 4.688 , time : 37.91500973701477: 100%|██████████| 1898/1898 [00:37<00:00, 50.01it/s] \n",
      "Epoch: 5. Validation. Loss: 5.016 , time : 2.143939733505249: 100%|██████████| 475/475 [00:02<00:00, 217.19it/s] \n",
      "Epoch: 6. Train.      Loss: 4.474 , time : 38.026861906051636: 100%|██████████| 1898/1898 [00:38<00:00, 49.86it/s]\n",
      "Epoch: 6. Validation. Loss: 4.826 , time : 2.0895869731903076: 100%|██████████| 475/475 [00:02<00:00, 222.80it/s]\n",
      "Epoch: 7. Train.      Loss: 4.290 , time : 37.82305145263672: 100%|██████████| 1898/1898 [00:37<00:00, 50.13it/s] \n",
      "Epoch: 7. Validation. Loss: 4.694 , time : 2.172445058822632: 100%|██████████| 475/475 [00:02<00:00, 214.52it/s] \n",
      "Epoch: 8. Train.      Loss: 4.124 , time : 38.373729944229126: 100%|██████████| 1898/1898 [00:38<00:00, 49.41it/s]\n",
      "Epoch: 8. Validation. Loss: 4.580 , time : 2.0815179347991943: 100%|██████████| 475/475 [00:02<00:00, 223.82it/s]\n",
      "Epoch: 9. Train.      Loss: 3.980 , time : 37.36742448806763: 100%|██████████| 1898/1898 [00:37<00:00, 50.74it/s] \n",
      "Epoch: 9. Validation. Loss: 4.477 , time : 2.112947463989258: 100%|██████████| 475/475 [00:02<00:00, 220.34it/s] \n",
      "Epoch: 10. Train.      Loss: 3.845 , time : 37.41806197166443: 100%|██████████| 1898/1898 [00:37<00:00, 50.67it/s] \n",
      "Epoch: 10. Validation. Loss: 4.410 , time : 2.0759201049804688: 100%|██████████| 475/475 [00:02<00:00, 224.39it/s]\n",
      "Epoch: 11. Train.      Loss: 3.724 , time : 37.70193696022034: 100%|██████████| 1898/1898 [00:37<00:00, 50.29it/s] \n",
      "Epoch: 11. Validation. Loss: 4.300 , time : 2.129971981048584: 100%|██████████| 475/475 [00:02<00:00, 218.63it/s] \n",
      "Epoch: 12. Train.      Loss: 3.617 , time : 37.52310514450073: 100%|██████████| 1898/1898 [00:37<00:00, 50.53it/s] \n",
      "Epoch: 12. Validation. Loss: 4.262 , time : 2.1033670902252197: 100%|██████████| 475/475 [00:02<00:00, 221.45it/s]\n",
      "Epoch: 13. Train.      Loss: 3.514 , time : 37.91858196258545: 100%|██████████| 1898/1898 [00:37<00:00, 50.00it/s] \n",
      "Epoch: 13. Validation. Loss: 4.183 , time : 2.140328884124756: 100%|██████████| 475/475 [00:02<00:00, 217.75it/s] \n",
      "Epoch: 14. Train.      Loss: 3.417 , time : 38.4523720741272: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]  \n",
      "Epoch: 14. Validation. Loss: 4.131 , time : 2.1615638732910156: 100%|██████████| 475/475 [00:02<00:00, 215.68it/s]\n",
      "Epoch: 15. Train.      Loss: 3.330 , time : 38.905524253845215: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s]\n",
      "Epoch: 15. Validation. Loss: 4.077 , time : 2.204716444015503: 100%|██████████| 475/475 [00:02<00:00, 211.49it/s] \n",
      "Epoch: 16. Train.      Loss: 3.246 , time : 38.591973543167114: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s]\n",
      "Epoch: 16. Validation. Loss: 4.020 , time : 2.137259006500244: 100%|██████████| 475/475 [00:02<00:00, 217.87it/s] \n",
      "Epoch: 17. Train.      Loss: 3.169 , time : 38.31444454193115: 100%|██████████| 1898/1898 [00:38<00:00, 49.48it/s] \n",
      "Epoch: 17. Validation. Loss: 3.990 , time : 2.2064545154571533: 100%|██████████| 475/475 [00:02<00:00, 211.31it/s]\n",
      "Epoch: 18. Train.      Loss: 3.093 , time : 38.408103942871094: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s]\n",
      "Epoch: 18. Validation. Loss: 3.931 , time : 2.149409532546997: 100%|██████████| 475/475 [00:02<00:00, 216.66it/s] \n",
      "Epoch: 19. Train.      Loss: 3.027 , time : 38.325589179992676: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s]\n",
      "Epoch: 19. Validation. Loss: 3.889 , time : 2.2690556049346924: 100%|██████████| 475/475 [00:02<00:00, 205.33it/s]\n",
      "Epoch: 20. Train.      Loss: 2.961 , time : 38.89164400100708: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s] \n",
      "Epoch: 20. Validation. Loss: 3.890 , time : 2.170783042907715: 100%|██████████| 475/475 [00:02<00:00, 214.76it/s] \n",
      "Epoch: 21. Train.      Loss: 2.898 , time : 38.74711084365845: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 21. Validation. Loss: 3.829 , time : 2.1086602210998535: 100%|██████████| 475/475 [00:02<00:00, 220.41it/s]\n",
      "Epoch: 22. Train.      Loss: 2.839 , time : 38.529133319854736: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]\n",
      "Epoch: 22. Validation. Loss: 3.834 , time : 2.1488492488861084: 100%|██████████| 475/475 [00:02<00:00, 216.75it/s]\n",
      "Epoch: 23. Train.      Loss: 2.784 , time : 38.7732937335968: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]  \n",
      "Epoch: 23. Validation. Loss: 3.784 , time : 2.1060903072357178: 100%|██████████| 475/475 [00:02<00:00, 221.20it/s]\n",
      "Epoch: 24. Train.      Loss: 2.728 , time : 38.744216442108154: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]\n",
      "Epoch: 24. Validation. Loss: 3.747 , time : 2.1157639026641846: 100%|██████████| 475/475 [00:02<00:00, 220.09it/s]\n",
      "Epoch: 25. Train.      Loss: 2.676 , time : 38.82166934013367: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 25. Validation. Loss: 3.710 , time : 2.1832234859466553: 100%|██████████| 475/475 [00:02<00:00, 213.53it/s]\n",
      "Epoch: 26. Train.      Loss: 2.623 , time : 38.64633822441101: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 26. Validation. Loss: 3.721 , time : 2.168196678161621: 100%|██████████| 475/475 [00:02<00:00, 214.95it/s] \n",
      "Epoch: 27. Train.      Loss: 2.577 , time : 38.67303442955017: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 27. Validation. Loss: 3.679 , time : 2.1469223499298096: 100%|██████████| 475/475 [00:02<00:00, 215.63it/s]\n",
      "Epoch: 28. Train.      Loss: 2.528 , time : 38.51627564430237: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 28. Validation. Loss: 3.670 , time : 2.247145891189575: 100%|██████████| 475/475 [00:02<00:00, 207.53it/s] \n",
      "Epoch: 29. Train.      Loss: 2.488 , time : 38.85331392288208: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 29. Validation. Loss: 3.643 , time : 2.182386875152588: 100%|██████████| 475/475 [00:02<00:00, 213.60it/s] \n",
      "Epoch: 30. Train.      Loss: 2.440 , time : 38.44985055923462: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s] \n",
      "Epoch: 30. Validation. Loss: 3.661 , time : 2.216601610183716: 100%|██████████| 475/475 [00:02<00:00, 210.42it/s] \n",
      "Epoch: 31. Train.      Loss: 2.402 , time : 38.515589237213135: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s]\n",
      "Epoch: 31. Validation. Loss: 3.645 , time : 2.117340087890625: 100%|██████████| 475/475 [00:02<00:00, 220.06it/s] \n",
      "Epoch: 32. Train.      Loss: 2.361 , time : 38.9306845664978: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s]  \n",
      "Epoch: 32. Validation. Loss: 3.601 , time : 2.164473056793213: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s] \n",
      "Epoch: 33. Train.      Loss: 2.323 , time : 38.74423861503601: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 33. Validation. Loss: 3.635 , time : 2.0890517234802246: 100%|██████████| 475/475 [00:02<00:00, 222.99it/s]\n",
      "Epoch: 34. Train.      Loss: 2.281 , time : 38.601221561431885: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s]\n",
      "Epoch: 34. Validation. Loss: 3.591 , time : 2.143138885498047: 100%|██████████| 475/475 [00:02<00:00, 217.47it/s] \n",
      "Epoch: 35. Train.      Loss: 2.249 , time : 38.681607723236084: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 35. Validation. Loss: 3.580 , time : 2.1444268226623535: 100%|██████████| 475/475 [00:02<00:00, 217.30it/s]\n",
      "Epoch: 36. Train.      Loss: 2.213 , time : 38.78461480140686: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 36. Validation. Loss: 3.567 , time : 2.1433982849121094: 100%|██████████| 475/475 [00:02<00:00, 217.49it/s]\n",
      "Epoch: 37. Train.      Loss: 2.176 , time : 38.83164119720459: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 37. Validation. Loss: 3.570 , time : 2.1503615379333496: 100%|██████████| 475/475 [00:02<00:00, 216.58it/s]\n",
      "Epoch: 38. Train.      Loss: 2.142 , time : 38.4844446182251: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]  \n",
      "Epoch: 38. Validation. Loss: 3.567 , time : 2.191920042037964: 100%|██████████| 475/475 [00:02<00:00, 212.69it/s] \n",
      "Epoch: 39. Train.      Loss: 2.110 , time : 39.071892976760864: 100%|██████████| 1898/1898 [00:39<00:00, 48.52it/s]\n",
      "Epoch: 39. Validation. Loss: 3.519 , time : 2.101738691329956: 100%|██████████| 475/475 [00:02<00:00, 221.69it/s] \n",
      "Epoch: 40. Train.      Loss: 2.079 , time : 38.19770956039429: 100%|██████████| 1898/1898 [00:38<00:00, 49.63it/s] \n",
      "Epoch: 40. Validation. Loss: 3.533 , time : 2.1465208530426025: 100%|██████████| 475/475 [00:02<00:00, 216.99it/s]\n",
      "Epoch: 41. Train.      Loss: 2.044 , time : 38.59050130844116: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 41. Validation. Loss: 3.542 , time : 2.266167402267456: 100%|██████████| 475/475 [00:02<00:00, 205.74it/s] \n",
      "Epoch: 42. Train.      Loss: 2.016 , time : 38.999133348464966: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s]\n",
      "Epoch: 42. Validation. Loss: 3.547 , time : 2.1728057861328125: 100%|██████████| 475/475 [00:02<00:00, 214.50it/s]\n",
      "Epoch: 43. Train.      Loss: 1.991 , time : 39.004841804504395: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s]\n",
      "Epoch: 43. Validation. Loss: 3.526 , time : 2.236025094985962: 100%|██████████| 475/475 [00:02<00:00, 208.51it/s] \n",
      "Epoch: 44. Train.      Loss: 1.955 , time : 38.78214645385742: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 44. Validation. Loss: 3.527 , time : 2.206489324569702: 100%|██████████| 475/475 [00:02<00:00, 211.30it/s] \n",
      "Epoch: 45. Train.      Loss: 1.927 , time : 38.248552560806274: 100%|██████████| 1898/1898 [00:38<00:00, 49.57it/s]\n",
      "Epoch: 45. Validation. Loss: 3.567 , time : 2.1509499549865723: 100%|██████████| 475/475 [00:02<00:00, 216.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19057... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.95509</td></tr><tr><td>Min_Val_Loss</td><td>3.51867</td></tr><tr><td>Val_Loss</td><td>3.52739</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frosty-sweep-65</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kepf7yjc\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kepf7yjc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_030303-kepf7yjc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: add5g2ue with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/add5g2ue\" target=\"_blank\">deft-sweep-66</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.949 , time : 38.74782633781433: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 0. Validation. Loss: 3.527 , time : 2.1015424728393555: 100%|██████████| 475/475 [00:02<00:00, 221.67it/s]\n",
      "Epoch: 1. Train.      Loss: 1.875 , time : 38.360146045684814: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s]\n",
      "Epoch: 1. Validation. Loss: 3.529 , time : 2.1284615993499756: 100%|██████████| 475/475 [00:02<00:00, 218.90it/s]\n",
      "Epoch: 2. Train.      Loss: 1.845 , time : 38.77921390533447: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 2. Validation. Loss: 3.549 , time : 2.150240421295166: 100%|██████████| 475/475 [00:02<00:00, 216.72it/s] \n",
      "Epoch: 3. Train.      Loss: 1.824 , time : 38.73562479019165: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s] \n",
      "Epoch: 3. Validation. Loss: 3.530 , time : 2.194356918334961: 100%|██████████| 475/475 [00:02<00:00, 212.06it/s] \n",
      "Epoch: 4. Train.      Loss: 1.794 , time : 38.76907658576965: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 4. Validation. Loss: 3.545 , time : 2.2083353996276855: 100%|██████████| 475/475 [00:02<00:00, 211.10it/s]\n",
      "Epoch: 5. Train.      Loss: 1.769 , time : 38.5925133228302: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s]  \n",
      "Epoch: 5. Validation. Loss: 3.554 , time : 2.2149288654327393: 100%|██████████| 475/475 [00:02<00:00, 210.31it/s]\n",
      "Epoch: 6. Train.      Loss: 1.747 , time : 38.66981315612793: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 6. Validation. Loss: 3.547 , time : 2.1561481952667236: 100%|██████████| 475/475 [00:02<00:00, 215.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30882... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▇▂▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.76889</td></tr><tr><td>Min_Val_Loss</td><td>3.52701</td></tr><tr><td>Val_Loss</td><td>3.55432</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-66</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/add5g2ue\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/add5g2ue</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_033425-add5g2ue/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5599jlsy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5599jlsy\" target=\"_blank\">grateful-sweep-67</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.762 , time : 38.392237424850464: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s]\n",
      "Epoch: 0. Validation. Loss: 3.535 , time : 2.1555840969085693: 100%|██████████| 475/475 [00:02<00:00, 216.15it/s]\n",
      "Epoch: 1. Train.      Loss: 1.702 , time : 38.410528898239136: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s]\n",
      "Epoch: 1. Validation. Loss: 3.537 , time : 2.095888376235962: 100%|██████████| 475/475 [00:02<00:00, 222.23it/s] \n",
      "Epoch: 2. Train.      Loss: 1.679 , time : 39.38742208480835: 100%|██████████| 1898/1898 [00:39<00:00, 48.13it/s] \n",
      "Epoch: 2. Validation. Loss: 3.508 , time : 2.1363131999969482: 100%|██████████| 475/475 [00:02<00:00, 218.11it/s]\n",
      "Epoch: 3. Train.      Loss: 1.655 , time : 38.49414086341858: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 3. Validation. Loss: 3.553 , time : 2.169400453567505: 100%|██████████| 475/475 [00:02<00:00, 214.62it/s] \n",
      "Epoch: 4. Train.      Loss: 1.634 , time : 39.045896768569946: 100%|██████████| 1898/1898 [00:39<00:00, 48.56it/s]\n",
      "Epoch: 4. Validation. Loss: 3.569 , time : 2.219048500061035: 100%|██████████| 475/475 [00:02<00:00, 208.06it/s] \n",
      "Epoch: 5. Train.      Loss: 1.614 , time : 38.780707597732544: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 5. Validation. Loss: 3.548 , time : 2.252344846725464: 100%|██████████| 475/475 [00:02<00:00, 206.94it/s] \n",
      "Epoch: 6. Train.      Loss: 1.593 , time : 39.03753089904785: 100%|██████████| 1898/1898 [00:39<00:00, 48.56it/s] \n",
      "Epoch: 6. Validation. Loss: 3.553 , time : 2.37896728515625: 100%|██████████| 475/475 [00:02<00:00, 195.84it/s]  \n",
      "Epoch: 7. Train.      Loss: 1.573 , time : 38.65442109107971: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 7. Validation. Loss: 3.592 , time : 2.128730058670044: 100%|██████████| 475/475 [00:02<00:00, 218.90it/s] \n",
      "Epoch: 8. Train.      Loss: 1.551 , time : 38.841256856918335: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s]\n",
      "Epoch: 8. Validation. Loss: 3.544 , time : 2.1525862216949463: 100%|██████████| 475/475 [00:02<00:00, 216.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1650... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▁▅▆▄▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.57341</td></tr><tr><td>Min_Val_Loss</td><td>3.50844</td></tr><tr><td>Val_Loss</td><td>3.59193</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">grateful-sweep-67</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5599jlsy\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/5599jlsy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_034133-5599jlsy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4c2hfkb2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4c2hfkb2\" target=\"_blank\">royal-sweep-68</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.568 , time : 38.91004419326782: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 0. Validation. Loss: 3.564 , time : 2.142641067504883: 100%|██████████| 475/475 [00:02<00:00, 217.34it/s] \n",
      "Epoch: 1. Train.      Loss: 1.517 , time : 38.720542907714844: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s]\n",
      "Epoch: 1. Validation. Loss: 3.568 , time : 2.1450984477996826: 100%|██████████| 475/475 [00:02<00:00, 217.24it/s]\n",
      "Epoch: 2. Train.      Loss: 1.499 , time : 38.255518674850464: 100%|██████████| 1898/1898 [00:38<00:00, 49.56it/s]\n",
      "Epoch: 2. Validation. Loss: 3.578 , time : 2.182476043701172: 100%|██████████| 475/475 [00:02<00:00, 213.48it/s] \n",
      "Epoch: 3. Train.      Loss: 1.482 , time : 38.518380880355835: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s]\n",
      "Epoch: 3. Validation. Loss: 3.560 , time : 2.123894691467285: 100%|██████████| 475/475 [00:02<00:00, 219.37it/s] \n",
      "Epoch: 4. Train.      Loss: 1.463 , time : 38.66194701194763: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 4. Validation. Loss: 3.585 , time : 2.164966106414795: 100%|██████████| 475/475 [00:02<00:00, 215.28it/s] \n",
      "Epoch: 5. Train.      Loss: 1.442 , time : 38.57758283615112: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 5. Validation. Loss: 3.596 , time : 2.1221225261688232: 100%|██████████| 475/475 [00:02<00:00, 219.53it/s]\n",
      "Epoch: 6. Train.      Loss: 1.424 , time : 38.59506297111511: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 6. Validation. Loss: 3.592 , time : 2.155785083770752: 100%|██████████| 475/475 [00:02<00:00, 216.13it/s] \n",
      "Epoch: 7. Train.      Loss: 1.411 , time : 38.808554887771606: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s]\n",
      "Epoch: 7. Validation. Loss: 3.583 , time : 2.1455936431884766: 100%|██████████| 475/475 [00:02<00:00, 217.01it/s]\n",
      "Epoch: 8. Train.      Loss: 1.393 , time : 38.83232760429382: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 8. Validation. Loss: 3.594 , time : 2.097224235534668: 100%|██████████| 475/475 [00:02<00:00, 220.02it/s] \n",
      "Epoch: 9. Train.      Loss: 1.376 , time : 38.55378437042236: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 9. Validation. Loss: 3.605 , time : 2.1655876636505127: 100%|██████████| 475/475 [00:02<00:00, 215.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4562... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▂▅▁▆█▇▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.39267</td></tr><tr><td>Min_Val_Loss</td><td>3.56021</td></tr><tr><td>Val_Loss</td><td>3.59408</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">royal-sweep-68</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4c2hfkb2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4c2hfkb2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_034754-4c2hfkb2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c56vsz7l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/c56vsz7l\" target=\"_blank\">deft-sweep-69</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.283 , time : 23.614960193634033: 100%|██████████| 1898/1898 [00:23<00:00, 80.23it/s]\n",
      "Epoch: 0. Validation. Loss: 3.583 , time : 2.119874954223633: 100%|██████████| 475/475 [00:02<00:00, 219.31it/s] \n",
      "Epoch: 1. Train.      Loss: 1.268 , time : 23.604809761047363: 100%|██████████| 1898/1898 [00:23<00:00, 80.27it/s]\n",
      "Epoch: 1. Validation. Loss: 3.569 , time : 2.2381556034088135: 100%|██████████| 475/475 [00:02<00:00, 208.31it/s]\n",
      "Epoch: 2. Train.      Loss: 1.259 , time : 23.65702223777771: 100%|██████████| 1898/1898 [00:23<00:00, 80.15it/s] \n",
      "Epoch: 2. Validation. Loss: 3.572 , time : 2.1329245567321777: 100%|██████████| 475/475 [00:02<00:00, 218.25it/s]\n",
      "Epoch: 3. Train.      Loss: 1.254 , time : 23.576692819595337: 100%|██████████| 1898/1898 [00:23<00:00, 80.36it/s]\n",
      "Epoch: 3. Validation. Loss: 3.564 , time : 2.153932809829712: 100%|██████████| 475/475 [00:02<00:00, 217.06it/s] \n",
      "Epoch: 4. Train.      Loss: 1.249 , time : 23.72178339958191: 100%|██████████| 1898/1898 [00:23<00:00, 79.87it/s] \n",
      "Epoch: 4. Validation. Loss: 3.564 , time : 2.2261948585510254: 100%|██████████| 475/475 [00:02<00:00, 209.40it/s]\n",
      "Epoch: 5. Train.      Loss: 1.245 , time : 23.759071826934814: 100%|██████████| 1898/1898 [00:23<00:00, 79.74it/s]\n",
      "Epoch: 5. Validation. Loss: 3.559 , time : 2.140475273132324: 100%|██████████| 475/475 [00:02<00:00, 217.68it/s] \n",
      "Epoch: 6. Train.      Loss: 1.242 , time : 23.636514902114868: 100%|██████████| 1898/1898 [00:23<00:00, 80.15it/s]\n",
      "Epoch: 6. Validation. Loss: 3.566 , time : 2.156310796737671: 100%|██████████| 475/475 [00:02<00:00, 215.95it/s] \n",
      "Epoch: 7. Train.      Loss: 1.240 , time : 23.67942476272583: 100%|██████████| 1898/1898 [00:23<00:00, 80.01it/s] \n",
      "Epoch: 7. Validation. Loss: 3.563 , time : 2.1493194103240967: 100%|██████████| 475/475 [00:02<00:00, 216.64it/s]\n",
      "Epoch: 8. Train.      Loss: 1.237 , time : 23.799548387527466: 100%|██████████| 1898/1898 [00:23<00:00, 79.61it/s]\n",
      "Epoch: 8. Validation. Loss: 3.574 , time : 2.09431791305542: 100%|██████████| 475/475 [00:02<00:00, 222.39it/s]  \n",
      "Epoch: 9. Train.      Loss: 1.236 , time : 23.829195261001587: 100%|██████████| 1898/1898 [00:23<00:00, 79.50it/s]\n",
      "Epoch: 9. Validation. Loss: 3.571 , time : 2.1487982273101807: 100%|██████████| 475/475 [00:02<00:00, 216.82it/s]\n",
      "Epoch: 10. Train.      Loss: 1.234 , time : 23.729236602783203: 100%|██████████| 1898/1898 [00:23<00:00, 79.83it/s]\n",
      "Epoch: 10. Validation. Loss: 3.567 , time : 2.1150929927825928: 100%|██████████| 475/475 [00:02<00:00, 220.05it/s]\n",
      "Epoch: 11. Train.      Loss: 1.232 , time : 23.92416477203369: 100%|██████████| 1898/1898 [00:23<00:00, 79.20it/s] \n",
      "Epoch: 11. Validation. Loss: 3.569 , time : 2.156691074371338: 100%|██████████| 475/475 [00:02<00:00, 214.37it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7635... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▄▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▄▅▂▂▁▃▂▅▅▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.23364</td></tr><tr><td>Min_Val_Loss</td><td>3.55928</td></tr><tr><td>Val_Loss</td><td>3.56667</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-69</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/c56vsz7l\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/c56vsz7l</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_035456-c56vsz7l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v4fxnzov with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v4fxnzov\" target=\"_blank\">cosmic-sweep-70</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.231 , time : 23.775863647460938: 100%|██████████| 1898/1898 [00:23<00:00, 79.68it/s]\n",
      "Epoch: 0. Validation. Loss: 3.578 , time : 2.1334095001220703: 100%|██████████| 475/475 [00:02<00:00, 218.40it/s]\n",
      "Epoch: 1. Train.      Loss: 1.230 , time : 23.651986598968506: 100%|██████████| 1898/1898 [00:23<00:00, 80.10it/s]\n",
      "Epoch: 1. Validation. Loss: 3.568 , time : 2.1515331268310547: 100%|██████████| 475/475 [00:02<00:00, 216.47it/s]\n",
      "Epoch: 2. Train.      Loss: 1.229 , time : 23.63457727432251: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s] \n",
      "Epoch: 2. Validation. Loss: 3.569 , time : 2.139052391052246: 100%|██████████| 475/475 [00:02<00:00, 217.76it/s] \n",
      "Epoch: 3. Train.      Loss: 1.228 , time : 23.688652276992798: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s]\n",
      "Epoch: 3. Validation. Loss: 3.572 , time : 2.151132822036743: 100%|██████████| 475/475 [00:02<00:00, 216.63it/s] \n",
      "Epoch: 4. Train.      Loss: 1.227 , time : 23.634029626846313: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s]\n",
      "Epoch: 4. Validation. Loss: 3.576 , time : 2.1518666744232178: 100%|██████████| 475/475 [00:02<00:00, 216.47it/s]\n",
      "Epoch: 5. Train.      Loss: 1.226 , time : 23.76796293258667: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s] \n",
      "Epoch: 5. Validation. Loss: 3.575 , time : 2.144366502761841: 100%|██████████| 475/475 [00:02<00:00, 215.80it/s] \n",
      "Epoch: 6. Train.      Loss: 1.226 , time : 23.637908697128296: 100%|██████████| 1898/1898 [00:23<00:00, 80.15it/s]\n",
      "Epoch: 6. Validation. Loss: 3.570 , time : 2.1235363483428955: 100%|██████████| 475/475 [00:02<00:00, 219.39it/s]\n",
      "Epoch: 7. Train.      Loss: 1.224 , time : 23.68827176094055: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s] \n",
      "Epoch: 7. Validation. Loss: 3.590 , time : 2.2153663635253906: 100%|██████████| 475/475 [00:02<00:00, 208.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10970... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▁▂▄▇▆▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.22566</td></tr><tr><td>Min_Val_Loss</td><td>3.56798</td></tr><tr><td>Val_Loss</td><td>3.57031</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cosmic-sweep-70</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v4fxnzov\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v4fxnzov</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_040229-v4fxnzov/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pdsnday7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pdsnday7\" target=\"_blank\">gallant-sweep-71</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.223 , time : 23.930869102478027: 100%|██████████| 1898/1898 [00:23<00:00, 79.17it/s]\n",
      "Epoch: 0. Validation. Loss: 3.577 , time : 2.131436824798584: 100%|██████████| 475/475 [00:02<00:00, 218.60it/s] \n",
      "Epoch: 1. Train.      Loss: 1.222 , time : 23.80403470993042: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s] \n",
      "Epoch: 1. Validation. Loss: 3.584 , time : 2.133861780166626: 100%|██████████| 475/475 [00:02<00:00, 218.36it/s] \n",
      "Epoch: 2. Train.      Loss: 1.222 , time : 23.949732542037964: 100%|██████████| 1898/1898 [00:23<00:00, 79.11it/s]\n",
      "Epoch: 2. Validation. Loss: 3.582 , time : 2.1208651065826416: 100%|██████████| 475/475 [00:02<00:00, 219.59it/s]\n",
      "Epoch: 3. Train.      Loss: 1.220 , time : 23.917118310928345: 100%|██████████| 1898/1898 [00:23<00:00, 79.21it/s]\n",
      "Epoch: 3. Validation. Loss: 3.582 , time : 2.1402697563171387: 100%|██████████| 475/475 [00:02<00:00, 217.77it/s]\n",
      "Epoch: 4. Train.      Loss: 1.220 , time : 23.808515787124634: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s]\n",
      "Epoch: 4. Validation. Loss: 3.578 , time : 2.2572853565216064: 100%|██████████| 475/475 [00:02<00:00, 206.62it/s]\n",
      "Epoch: 5. Train.      Loss: 1.220 , time : 23.96314549446106: 100%|██████████| 1898/1898 [00:24<00:00, 79.07it/s] \n",
      "Epoch: 5. Validation. Loss: 3.584 , time : 2.165595531463623: 100%|██████████| 475/475 [00:02<00:00, 213.61it/s] \n",
      "Epoch: 6. Train.      Loss: 1.218 , time : 23.484543323516846: 100%|██████████| 1898/1898 [00:23<00:00, 80.67it/s]\n",
      "Epoch: 6. Validation. Loss: 3.584 , time : 2.1326591968536377: 100%|██████████| 475/475 [00:02<00:00, 218.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13516... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁█▆▆▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.2199</td></tr><tr><td>Min_Val_Loss</td><td>3.57725</td></tr><tr><td>Val_Loss</td><td>3.58384</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gallant-sweep-71</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pdsnday7\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pdsnday7</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_040819-pdsnday7/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 28wqes72 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/28wqes72\" target=\"_blank\">confused-sweep-72</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.218 , time : 23.833266973495483: 100%|██████████| 1898/1898 [00:23<00:00, 79.49it/s]\n",
      "Epoch: 0. Validation. Loss: 3.594 , time : 2.149935722351074: 100%|██████████| 475/475 [00:02<00:00, 216.59it/s] \n",
      "Epoch: 1. Train.      Loss: 1.217 , time : 23.79058003425598: 100%|██████████| 1898/1898 [00:23<00:00, 79.64it/s] \n",
      "Epoch: 1. Validation. Loss: 3.585 , time : 2.1091530323028564: 100%|██████████| 475/475 [00:02<00:00, 220.68it/s]\n",
      "Epoch: 2. Train.      Loss: 1.216 , time : 23.680580139160156: 100%|██████████| 1898/1898 [00:23<00:00, 80.00it/s]\n",
      "Epoch: 2. Validation. Loss: 3.592 , time : 2.11391282081604: 100%|██████████| 475/475 [00:02<00:00, 220.33it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.217 , time : 23.99380087852478: 100%|██████████| 1898/1898 [00:24<00:00, 78.96it/s] \n",
      "Epoch: 3. Validation. Loss: 3.594 , time : 2.151283025741577: 100%|██████████| 475/475 [00:02<00:00, 216.58it/s] \n",
      "Epoch: 4. Train.      Loss: 1.215 , time : 23.73970937728882: 100%|██████████| 1898/1898 [00:23<00:00, 79.81it/s] \n",
      "Epoch: 4. Validation. Loss: 3.591 , time : 2.1430954933166504: 100%|██████████| 475/475 [00:02<00:00, 217.40it/s]\n",
      "Epoch: 5. Train.      Loss: 1.214 , time : 23.708632469177246: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s]\n",
      "Epoch: 5. Validation. Loss: 3.595 , time : 2.208278179168701: 100%|██████████| 475/475 [00:02<00:00, 211.14it/s] \n",
      "Epoch: 6. Train.      Loss: 1.214 , time : 23.655051231384277: 100%|██████████| 1898/1898 [00:23<00:00, 80.09it/s]\n",
      "Epoch: 6. Validation. Loss: 3.600 , time : 2.111948251724243: 100%|██████████| 475/475 [00:02<00:00, 220.54it/s] \n",
      "Epoch: 7. Train.      Loss: 1.213 , time : 23.78060293197632: 100%|██████████| 1898/1898 [00:23<00:00, 79.67it/s] \n",
      "Epoch: 7. Validation. Loss: 3.599 , time : 2.198681592941284: 100%|██████████| 475/475 [00:02<00:00, 212.05it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15860... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▆▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▁▄▅▄▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.21374</td></tr><tr><td>Min_Val_Loss</td><td>3.58468</td></tr><tr><td>Val_Loss</td><td>3.5995</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">confused-sweep-72</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/28wqes72\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/28wqes72</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_041343-28wqes72/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9yq0etc9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9yq0etc9\" target=\"_blank\">wobbly-sweep-73</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.122 , time : 38.47610545158386: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 0. Validation. Loss: 6.124 , time : 2.172086715698242: 100%|██████████| 475/475 [00:02<00:00, 214.55it/s] \n",
      "Epoch: 1. Train.      Loss: 5.770 , time : 39.6861777305603: 100%|██████████| 1898/1898 [00:39<00:00, 47.78it/s]  \n",
      "Epoch: 1. Validation. Loss: 5.932 , time : 2.191154718399048: 100%|██████████| 475/475 [00:02<00:00, 212.73it/s] \n",
      "Epoch: 2. Train.      Loss: 5.447 , time : 38.95771765708923: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 2. Validation. Loss: 5.661 , time : 2.222676992416382: 100%|██████████| 475/475 [00:02<00:00, 209.71it/s] \n",
      "Epoch: 3. Train.      Loss: 5.098 , time : 38.83395552635193: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 3. Validation. Loss: 5.361 , time : 2.117669105529785: 100%|██████████| 475/475 [00:02<00:00, 219.97it/s] \n",
      "Epoch: 4. Train.      Loss: 4.787 , time : 39.01631140708923: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 4. Validation. Loss: 5.099 , time : 2.1906723976135254: 100%|██████████| 475/475 [00:02<00:00, 212.75it/s]\n",
      "Epoch: 5. Train.      Loss: 4.529 , time : 38.7102165222168: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s]  \n",
      "Epoch: 5. Validation. Loss: 4.884 , time : 2.1612091064453125: 100%|██████████| 475/475 [00:02<00:00, 215.54it/s]\n",
      "Epoch: 6. Train.      Loss: 4.318 , time : 38.49200439453125: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 6. Validation. Loss: 4.713 , time : 2.1834447383880615: 100%|██████████| 475/475 [00:02<00:00, 213.48it/s]\n",
      "Epoch: 7. Train.      Loss: 4.137 , time : 38.71380949020386: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 7. Validation. Loss: 4.591 , time : 2.11289119720459: 100%|██████████| 475/475 [00:02<00:00, 220.35it/s]  \n",
      "Epoch: 8. Train.      Loss: 3.978 , time : 38.57821989059448: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 8. Validation. Loss: 4.467 , time : 2.1678719520568848: 100%|██████████| 475/475 [00:02<00:00, 214.96it/s]\n",
      "Epoch: 9. Train.      Loss: 3.834 , time : 38.59740400314331: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 9. Validation. Loss: 4.356 , time : 2.108978509902954: 100%|██████████| 475/475 [00:02<00:00, 220.56it/s] \n",
      "Epoch: 10. Train.      Loss: 3.711 , time : 38.60982894897461: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 10. Validation. Loss: 4.261 , time : 2.1573801040649414: 100%|██████████| 475/475 [00:02<00:00, 216.03it/s]\n",
      "Epoch: 11. Train.      Loss: 3.586 , time : 39.08262825012207: 100%|██████████| 1898/1898 [00:39<00:00, 48.51it/s] \n",
      "Epoch: 11. Validation. Loss: 4.207 , time : 2.188582420349121: 100%|██████████| 475/475 [00:02<00:00, 212.75it/s] \n",
      "Epoch: 12. Train.      Loss: 3.481 , time : 38.75615310668945: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s] \n",
      "Epoch: 12. Validation. Loss: 4.125 , time : 2.144798994064331: 100%|██████████| 475/475 [00:02<00:00, 216.27it/s] \n",
      "Epoch: 13. Train.      Loss: 3.374 , time : 38.828184604644775: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 13. Validation. Loss: 4.098 , time : 2.1735424995422363: 100%|██████████| 475/475 [00:02<00:00, 214.30it/s]\n",
      "Epoch: 14. Train.      Loss: 3.286 , time : 39.19965195655823: 100%|██████████| 1898/1898 [00:39<00:00, 48.37it/s] \n",
      "Epoch: 14. Validation. Loss: 4.028 , time : 2.1537272930145264: 100%|██████████| 475/475 [00:02<00:00, 216.25it/s]\n",
      "Epoch: 15. Train.      Loss: 3.200 , time : 38.80690264701843: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 15. Validation. Loss: 3.965 , time : 2.172725200653076: 100%|██████████| 475/475 [00:02<00:00, 214.54it/s] \n",
      "Epoch: 16. Train.      Loss: 3.112 , time : 38.749040842056274: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]\n",
      "Epoch: 16. Validation. Loss: 3.914 , time : 2.1460862159729004: 100%|██████████| 475/475 [00:02<00:00, 217.08it/s]\n",
      "Epoch: 17. Train.      Loss: 3.036 , time : 38.56575417518616: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 17. Validation. Loss: 3.867 , time : 2.2240302562713623: 100%|██████████| 475/475 [00:02<00:00, 209.62it/s]\n",
      "Epoch: 18. Train.      Loss: 2.964 , time : 39.01004338264465: 100%|██████████| 1898/1898 [00:39<00:00, 48.60it/s] \n",
      "Epoch: 18. Validation. Loss: 3.837 , time : 2.1906938552856445: 100%|██████████| 475/475 [00:02<00:00, 212.77it/s]\n",
      "Epoch: 19. Train.      Loss: 2.895 , time : 38.7368426322937: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]  \n",
      "Epoch: 19. Validation. Loss: 3.842 , time : 2.145449638366699: 100%|██████████| 475/475 [00:02<00:00, 217.19it/s] \n",
      "Epoch: 20. Train.      Loss: 2.832 , time : 38.52270793914795: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 20. Validation. Loss: 3.776 , time : 2.2244224548339844: 100%|██████████| 475/475 [00:02<00:00, 209.57it/s]\n",
      "Epoch: 21. Train.      Loss: 2.767 , time : 38.904895067214966: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s]\n",
      "Epoch: 21. Validation. Loss: 3.763 , time : 2.1163880825042725: 100%|██████████| 475/475 [00:02<00:00, 219.96it/s]\n",
      "Epoch: 22. Train.      Loss: 2.711 , time : 38.70552706718445: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 22. Validation. Loss: 3.727 , time : 2.122572183609009: 100%|██████████| 475/475 [00:02<00:00, 219.19it/s] \n",
      "Epoch: 23. Train.      Loss: 2.659 , time : 38.64425301551819: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 23. Validation. Loss: 3.706 , time : 2.1805636882781982: 100%|██████████| 475/475 [00:02<00:00, 213.21it/s]\n",
      "Epoch: 24. Train.      Loss: 2.605 , time : 38.888426303863525: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 24. Validation. Loss: 3.689 , time : 2.174401044845581: 100%|██████████| 475/475 [00:02<00:00, 214.20it/s] \n",
      "Epoch: 25. Train.      Loss: 2.548 , time : 39.09492468833923: 100%|██████████| 1898/1898 [00:39<00:00, 48.49it/s] \n",
      "Epoch: 25. Validation. Loss: 3.641 , time : 2.2094080448150635: 100%|██████████| 475/475 [00:02<00:00, 211.02it/s]\n",
      "Epoch: 26. Train.      Loss: 2.502 , time : 38.6544725894928: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]  \n",
      "Epoch: 26. Validation. Loss: 3.672 , time : 2.097001075744629: 100%|██████████| 475/475 [00:02<00:00, 222.08it/s] \n",
      "Epoch: 27. Train.      Loss: 2.455 , time : 38.91187071800232: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 27. Validation. Loss: 3.673 , time : 2.150006055831909: 100%|██████████| 475/475 [00:02<00:00, 216.12it/s] \n",
      "Epoch: 28. Train.      Loss: 2.411 , time : 38.836522579193115: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 28. Validation. Loss: 3.580 , time : 2.160320281982422: 100%|██████████| 475/475 [00:02<00:00, 215.74it/s] \n",
      "Epoch: 29. Train.      Loss: 2.367 , time : 38.92371225357056: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 29. Validation. Loss: 3.627 , time : 2.1858808994293213: 100%|██████████| 475/475 [00:02<00:00, 213.09it/s]\n",
      "Epoch: 30. Train.      Loss: 2.330 , time : 38.36457562446594: 100%|██████████| 1898/1898 [00:38<00:00, 49.42it/s] \n",
      "Epoch: 30. Validation. Loss: 3.578 , time : 2.165240526199341: 100%|██████████| 475/475 [00:02<00:00, 215.06it/s] \n",
      "Epoch: 31. Train.      Loss: 2.290 , time : 38.72688817977905: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 31. Validation. Loss: 3.544 , time : 2.176959276199341: 100%|██████████| 475/475 [00:02<00:00, 213.96it/s] \n",
      "Epoch: 32. Train.      Loss: 2.248 , time : 38.46790170669556: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 32. Validation. Loss: 3.585 , time : 2.214508533477783: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s] \n",
      "Epoch: 33. Train.      Loss: 2.213 , time : 38.24968767166138: 100%|██████████| 1898/1898 [00:38<00:00, 49.57it/s] \n",
      "Epoch: 33. Validation. Loss: 3.570 , time : 2.1244685649871826: 100%|██████████| 475/475 [00:02<00:00, 217.81it/s]\n",
      "Epoch: 34. Train.      Loss: 2.175 , time : 38.80272674560547: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 34. Validation. Loss: 3.555 , time : 2.1819965839385986: 100%|██████████| 475/475 [00:02<00:00, 213.58it/s]\n",
      "Epoch: 35. Train.      Loss: 2.138 , time : 38.93960976600647: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 35. Validation. Loss: 3.546 , time : 2.1469969749450684: 100%|██████████| 475/475 [00:02<00:00, 217.00it/s]\n",
      "Epoch: 36. Train.      Loss: 2.106 , time : 38.70289349555969: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 36. Validation. Loss: 3.532 , time : 2.1212706565856934: 100%|██████████| 475/475 [00:02<00:00, 219.43it/s]\n",
      "Epoch: 37. Train.      Loss: 2.075 , time : 38.49373412132263: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 37. Validation. Loss: 3.548 , time : 2.1280131340026855: 100%|██████████| 475/475 [00:02<00:00, 218.72it/s]\n",
      "Epoch: 38. Train.      Loss: 2.037 , time : 38.55737257003784: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 38. Validation. Loss: 3.515 , time : 2.170975923538208: 100%|██████████| 475/475 [00:02<00:00, 214.63it/s] \n",
      "Epoch: 39. Train.      Loss: 2.003 , time : 38.47874164581299: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 39. Validation. Loss: 3.519 , time : 2.1650803089141846: 100%|██████████| 475/475 [00:02<00:00, 215.24it/s]\n",
      "Epoch: 40. Train.      Loss: 1.976 , time : 38.62848424911499: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 40. Validation. Loss: 3.541 , time : 2.1850924491882324: 100%|██████████| 475/475 [00:02<00:00, 213.22it/s]\n",
      "Epoch: 41. Train.      Loss: 1.944 , time : 38.78445792198181: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 41. Validation. Loss: 3.519 , time : 2.1800506114959717: 100%|██████████| 475/475 [00:02<00:00, 213.77it/s]\n",
      "Epoch: 42. Train.      Loss: 1.916 , time : 38.573517084121704: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 42. Validation. Loss: 3.512 , time : 2.1108896732330322: 100%|██████████| 475/475 [00:02<00:00, 220.48it/s]\n",
      "Epoch: 43. Train.      Loss: 1.887 , time : 39.18559718132019: 100%|██████████| 1898/1898 [00:39<00:00, 48.38it/s] \n",
      "Epoch: 43. Validation. Loss: 3.542 , time : 2.182230234146118: 100%|██████████| 475/475 [00:02<00:00, 213.57it/s] \n",
      "Epoch: 44. Train.      Loss: 1.857 , time : 38.95044159889221: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 44. Validation. Loss: 3.555 , time : 2.2419607639312744: 100%|██████████| 475/475 [00:02<00:00, 208.00it/s]\n",
      "Epoch: 45. Train.      Loss: 1.833 , time : 38.894413232803345: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s]\n",
      "Epoch: 45. Validation. Loss: 3.546 , time : 2.2397236824035645: 100%|██████████| 475/475 [00:02<00:00, 208.13it/s]\n",
      "Epoch: 46. Train.      Loss: 1.801 , time : 38.945059299468994: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s]\n",
      "Epoch: 46. Validation. Loss: 3.550 , time : 2.181258201599121: 100%|██████████| 475/475 [00:02<00:00, 212.38it/s] \n",
      "Epoch: 47. Train.      Loss: 1.779 , time : 38.943819999694824: 100%|██████████| 1898/1898 [00:39<00:00, 48.67it/s]\n",
      "Epoch: 47. Validation. Loss: 3.530 , time : 2.1691651344299316: 100%|██████████| 475/475 [00:02<00:00, 214.73it/s]\n",
      "Epoch: 48. Train.      Loss: 1.748 , time : 38.818284034729004: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]\n",
      "Epoch: 48. Validation. Loss: 3.578 , time : 2.200538158416748: 100%|██████████| 475/475 [00:02<00:00, 211.85it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18486... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.77859</td></tr><tr><td>Min_Val_Loss</td><td>3.51213</td></tr><tr><td>Val_Loss</td><td>3.5301</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wobbly-sweep-73</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9yq0etc9\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9yq0etc9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_041932-9yq0etc9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ifq73t1t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ifq73t1t\" target=\"_blank\">swift-sweep-74</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.770 , time : 38.58641982078552: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 0. Validation. Loss: 3.559 , time : 2.1234607696533203: 100%|██████████| 475/475 [00:02<00:00, 218.72it/s]\n",
      "Epoch: 1. Train.      Loss: 1.703 , time : 38.539371490478516: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s]\n",
      "Epoch: 1. Validation. Loss: 3.597 , time : 2.144882917404175: 100%|██████████| 475/475 [00:02<00:00, 217.26it/s] \n",
      "Epoch: 2. Train.      Loss: 1.677 , time : 39.0252480506897: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.557 , time : 2.2055130004882812: 100%|██████████| 475/475 [00:02<00:00, 211.34it/s]\n",
      "Epoch: 3. Train.      Loss: 1.649 , time : 38.805883169174194: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s]\n",
      "Epoch: 3. Validation. Loss: 3.594 , time : 2.175450086593628: 100%|██████████| 475/475 [00:02<00:00, 214.11it/s] \n",
      "Epoch: 4. Train.      Loss: 1.629 , time : 38.2303946018219: 100%|██████████| 1898/1898 [00:38<00:00, 49.59it/s]  \n",
      "Epoch: 4. Validation. Loss: 3.586 , time : 2.136997938156128: 100%|██████████| 475/475 [00:02<00:00, 217.99it/s] \n",
      "Epoch: 5. Train.      Loss: 1.600 , time : 38.62987804412842: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 5. Validation. Loss: 3.621 , time : 2.1374917030334473: 100%|██████████| 475/475 [00:02<00:00, 217.96it/s]\n",
      "Epoch: 6. Train.      Loss: 1.582 , time : 38.6086905002594: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s]  \n",
      "Epoch: 6. Validation. Loss: 3.591 , time : 2.1147732734680176: 100%|██████████| 475/475 [00:02<00:00, 220.24it/s]\n",
      "Epoch: 7. Train.      Loss: 1.558 , time : 38.88010859489441: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 7. Validation. Loss: 3.637 , time : 2.25803279876709: 100%|██████████| 475/475 [00:02<00:00, 206.57it/s]  \n",
      "Epoch: 8. Train.      Loss: 1.535 , time : 38.39759635925293: 100%|██████████| 1898/1898 [00:38<00:00, 49.38it/s] \n",
      "Epoch: 8. Validation. Loss: 3.622 , time : 2.1264090538024902: 100%|██████████| 475/475 [00:02<00:00, 218.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2911... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▁▄▄▇▄█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.55772</td></tr><tr><td>Min_Val_Loss</td><td>3.55689</td></tr><tr><td>Val_Loss</td><td>3.63721</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">swift-sweep-74</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ifq73t1t\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ifq73t1t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_045524-ifq73t1t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9mv9xhr4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mv9xhr4\" target=\"_blank\">decent-sweep-75</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.549 , time : 38.55180263519287: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 0. Validation. Loss: 3.628 , time : 2.220409631729126: 100%|██████████| 475/475 [00:02<00:00, 209.97it/s] \n",
      "Epoch: 1. Train.      Loss: 1.499 , time : 38.56936955451965: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 1. Validation. Loss: 3.624 , time : 2.1727168560028076: 100%|██████████| 475/475 [00:02<00:00, 214.54it/s]\n",
      "Epoch: 2. Train.      Loss: 1.476 , time : 38.75160241127014: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 2. Validation. Loss: 3.649 , time : 2.133537769317627: 100%|██████████| 475/475 [00:02<00:00, 218.20it/s] \n",
      "Epoch: 3. Train.      Loss: 1.453 , time : 38.7282657623291: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.662 , time : 2.196662425994873: 100%|██████████| 475/475 [00:02<00:00, 212.03it/s] \n",
      "Epoch: 4. Train.      Loss: 1.433 , time : 38.828771114349365: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 4. Validation. Loss: 3.639 , time : 2.084454298019409: 100%|██████████| 475/475 [00:02<00:00, 222.40it/s] \n",
      "Epoch: 5. Train.      Loss: 1.415 , time : 38.61785387992859: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 5. Validation. Loss: 3.667 , time : 2.2189598083496094: 100%|██████████| 475/475 [00:02<00:00, 210.12it/s]\n",
      "Epoch: 6. Train.      Loss: 1.392 , time : 38.83614230155945: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 6. Validation. Loss: 3.676 , time : 2.145888090133667: 100%|██████████| 475/475 [00:02<00:00, 217.15it/s] \n",
      "Epoch: 7. Train.      Loss: 1.374 , time : 38.60310363769531: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 7. Validation. Loss: 3.698 , time : 2.2847378253936768: 100%|██████████| 475/475 [00:02<00:00, 204.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5771... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▄▆▃▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.39248</td></tr><tr><td>Min_Val_Loss</td><td>3.62431</td></tr><tr><td>Val_Loss</td><td>3.67632</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">decent-sweep-75</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mv9xhr4\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mv9xhr4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_050146-9mv9xhr4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: es5c3evn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/es5c3evn\" target=\"_blank\">snowy-sweep-76</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.391 , time : 38.765730142593384: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]\n",
      "Epoch: 0. Validation. Loss: 3.668 , time : 2.138347625732422: 100%|██████████| 475/475 [00:02<00:00, 217.92it/s] \n",
      "Epoch: 1. Train.      Loss: 1.349 , time : 38.4724178314209: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s]  \n",
      "Epoch: 1. Validation. Loss: 3.694 , time : 2.1399803161621094: 100%|██████████| 475/475 [00:02<00:00, 217.57it/s]\n",
      "Epoch: 2. Train.      Loss: 1.328 , time : 38.19916248321533: 100%|██████████| 1898/1898 [00:38<00:00, 49.63it/s] \n",
      "Epoch: 2. Validation. Loss: 3.685 , time : 2.1309685707092285: 100%|██████████| 475/475 [00:02<00:00, 218.62it/s]\n",
      "Epoch: 3. Train.      Loss: 1.314 , time : 38.84852957725525: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 3. Validation. Loss: 3.730 , time : 2.1940672397613525: 100%|██████████| 475/475 [00:02<00:00, 212.16it/s]\n",
      "Epoch: 4. Train.      Loss: 1.296 , time : 38.81610441207886: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 4. Validation. Loss: 3.758 , time : 2.2637641429901123: 100%|██████████| 475/475 [00:02<00:00, 206.03it/s]\n",
      "Epoch: 5. Train.      Loss: 1.285 , time : 39.01696014404297: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 5. Validation. Loss: 3.758 , time : 2.190101146697998: 100%|██████████| 475/475 [00:02<00:00, 212.76it/s] \n",
      "Epoch: 6. Train.      Loss: 1.260 , time : 38.45839333534241: 100%|██████████| 1898/1898 [00:38<00:00, 49.29it/s] \n",
      "Epoch: 6. Validation. Loss: 3.765 , time : 2.143310785293579: 100%|██████████| 475/475 [00:02<00:00, 217.38it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8290... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▂▆██</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.28481</td></tr><tr><td>Min_Val_Loss</td><td>3.66791</td></tr><tr><td>Val_Loss</td><td>3.75819</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">snowy-sweep-76</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/es5c3evn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/es5c3evn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_050724-es5c3evn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: je88jr04 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je88jr04\" target=\"_blank\">radiant-sweep-77</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.167 , time : 23.754549741744995: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s]\n",
      "Epoch: 0. Validation. Loss: 3.742 , time : 2.1557374000549316: 100%|██████████| 475/475 [00:02<00:00, 214.41it/s]\n",
      "Epoch: 1. Train.      Loss: 1.155 , time : 23.57393527030945: 100%|██████████| 1898/1898 [00:23<00:00, 80.37it/s] \n",
      "Epoch: 1. Validation. Loss: 3.728 , time : 2.1903076171875: 100%|██████████| 475/475 [00:02<00:00, 210.64it/s]   \n",
      "Epoch: 2. Train.      Loss: 1.146 , time : 23.85806441307068: 100%|██████████| 1898/1898 [00:23<00:00, 79.41it/s] \n",
      "Epoch: 2. Validation. Loss: 3.729 , time : 2.164062976837158: 100%|██████████| 475/475 [00:02<00:00, 215.03it/s] \n",
      "Epoch: 3. Train.      Loss: 1.140 , time : 23.82645583152771: 100%|██████████| 1898/1898 [00:23<00:00, 79.52it/s] \n",
      "Epoch: 3. Validation. Loss: 3.719 , time : 2.164306879043579: 100%|██████████| 475/475 [00:02<00:00, 215.22it/s] \n",
      "Epoch: 4. Train.      Loss: 1.136 , time : 23.768991708755493: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s]\n",
      "Epoch: 4. Validation. Loss: 3.734 , time : 2.252810478210449: 100%|██████████| 475/475 [00:02<00:00, 206.96it/s] \n",
      "Epoch: 5. Train.      Loss: 1.132 , time : 23.668402433395386: 100%|██████████| 1898/1898 [00:23<00:00, 80.04it/s]\n",
      "Epoch: 5. Validation. Loss: 3.717 , time : 2.2761993408203125: 100%|██████████| 475/475 [00:02<00:00, 204.75it/s]\n",
      "Epoch: 6. Train.      Loss: 1.129 , time : 23.95712900161743: 100%|██████████| 1898/1898 [00:24<00:00, 79.08it/s] \n",
      "Epoch: 6. Validation. Loss: 3.717 , time : 2.12286376953125: 100%|██████████| 475/475 [00:02<00:00, 219.47it/s]  \n",
      "Epoch: 7. Train.      Loss: 1.127 , time : 23.642531156539917: 100%|██████████| 1898/1898 [00:23<00:00, 80.14it/s]\n",
      "Epoch: 7. Validation. Loss: 3.712 , time : 2.129641532897949: 100%|██████████| 475/475 [00:02<00:00, 218.43it/s] \n",
      "Epoch: 8. Train.      Loss: 1.125 , time : 23.73063635826111: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s] \n",
      "Epoch: 8. Validation. Loss: 3.723 , time : 2.147852659225464: 100%|██████████| 475/475 [00:02<00:00, 216.85it/s] \n",
      "Epoch: 9. Train.      Loss: 1.123 , time : 24.102187395095825: 100%|██████████| 1898/1898 [00:24<00:00, 78.61it/s]\n",
      "Epoch: 9. Validation. Loss: 3.722 , time : 2.244894027709961: 100%|██████████| 475/475 [00:02<00:00, 207.75it/s] \n",
      "Epoch: 10. Train.      Loss: 1.122 , time : 23.63158106803894: 100%|██████████| 1898/1898 [00:23<00:00, 80.17it/s] \n",
      "Epoch: 10. Validation. Loss: 3.720 , time : 2.18056058883667: 100%|██████████| 475/475 [00:02<00:00, 213.54it/s]  \n",
      "Epoch: 11. Train.      Loss: 1.121 , time : 23.684003114700317: 100%|██████████| 1898/1898 [00:23<00:00, 79.99it/s]\n",
      "Epoch: 11. Validation. Loss: 3.730 , time : 2.2144834995269775: 100%|██████████| 475/475 [00:02<00:00, 210.36it/s]\n",
      "Epoch: 12. Train.      Loss: 1.118 , time : 23.633506059646606: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s]\n",
      "Epoch: 12. Validation. Loss: 3.734 , time : 2.1720168590545654: 100%|██████████| 475/475 [00:02<00:00, 214.58it/s]\n",
      "Epoch: 13. Train.      Loss: 1.117 , time : 23.645389318466187: 100%|██████████| 1898/1898 [00:23<00:00, 80.12it/s]\n",
      "Epoch: 13. Validation. Loss: 3.747 , time : 2.180274486541748: 100%|██████████| 475/475 [00:02<00:00, 213.74it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10472... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▅▅▃▃▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▅▅▃▆▂▂▁▄▃▃▅▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.11834</td></tr><tr><td>Min_Val_Loss</td><td>3.71207</td></tr><tr><td>Val_Loss</td><td>3.73417</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">radiant-sweep-77</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je88jr04\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/je88jr04</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_051221-je88jr04/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wfgox160 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wfgox160\" target=\"_blank\">still-sweep-78</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.116 , time : 23.77863359451294: 100%|██████████| 1898/1898 [00:23<00:00, 79.68it/s] \n",
      "Epoch: 0. Validation. Loss: 3.729 , time : 2.167881488800049: 100%|██████████| 475/475 [00:02<00:00, 215.01it/s] \n",
      "Epoch: 1. Train.      Loss: 1.115 , time : 23.853317499160767: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s]\n",
      "Epoch: 1. Validation. Loss: 3.731 , time : 2.1689021587371826: 100%|██████████| 475/475 [00:02<00:00, 214.72it/s]\n",
      "Epoch: 2. Train.      Loss: 1.114 , time : 23.619142532348633: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]\n",
      "Epoch: 2. Validation. Loss: 3.739 , time : 2.121450901031494: 100%|██████████| 475/475 [00:02<00:00, 219.59it/s] \n",
      "Epoch: 3. Train.      Loss: 1.114 , time : 23.8032546043396: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.749 , time : 2.2311363220214844: 100%|██████████| 475/475 [00:02<00:00, 208.87it/s]\n",
      "Epoch: 4. Train.      Loss: 1.112 , time : 23.58976697921753: 100%|██████████| 1898/1898 [00:23<00:00, 80.24it/s] \n",
      "Epoch: 4. Validation. Loss: 3.743 , time : 2.1185500621795654: 100%|██████████| 475/475 [00:02<00:00, 219.86it/s]\n",
      "Epoch: 5. Train.      Loss: 1.111 , time : 23.84041476249695: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s] \n",
      "Epoch: 5. Validation. Loss: 3.741 , time : 2.1506009101867676: 100%|██████████| 475/475 [00:02<00:00, 216.66it/s]\n",
      "Epoch: 6. Train.      Loss: 1.111 , time : 23.637736082077026: 100%|██████████| 1898/1898 [00:23<00:00, 80.15it/s]\n",
      "Epoch: 6. Validation. Loss: 3.747 , time : 2.139672040939331: 100%|██████████| 475/475 [00:02<00:00, 217.63it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12743... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▃▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▄█▆▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.11114</td></tr><tr><td>Min_Val_Loss</td><td>3.72922</td></tr><tr><td>Val_Loss</td><td>3.74087</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">still-sweep-78</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wfgox160\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wfgox160</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_051837-wfgox160/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ua04zuqn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ua04zuqn\" target=\"_blank\">fiery-sweep-79</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.110 , time : 23.45990777015686: 100%|██████████| 1898/1898 [00:23<00:00, 80.76it/s] \n",
      "Epoch: 0. Validation. Loss: 3.748 , time : 2.1106467247009277: 100%|██████████| 475/475 [00:02<00:00, 220.50it/s]\n",
      "Epoch: 1. Train.      Loss: 1.109 , time : 23.88243007659912: 100%|██████████| 1898/1898 [00:23<00:00, 79.33it/s] \n",
      "Epoch: 1. Validation. Loss: 3.751 , time : 2.210251569747925: 100%|██████████| 475/475 [00:02<00:00, 210.93it/s] \n",
      "Epoch: 2. Train.      Loss: 1.109 , time : 23.681036710739136: 100%|██████████| 1898/1898 [00:23<00:00, 80.00it/s]\n",
      "Epoch: 2. Validation. Loss: 3.756 , time : 2.202150344848633: 100%|██████████| 475/475 [00:02<00:00, 209.51it/s] \n",
      "Epoch: 3. Train.      Loss: 1.108 , time : 23.748172521591187: 100%|██████████| 1898/1898 [00:23<00:00, 79.78it/s]\n",
      "Epoch: 3. Validation. Loss: 3.764 , time : 2.2150652408599854: 100%|██████████| 475/475 [00:02<00:00, 208.48it/s]\n",
      "Epoch: 4. Train.      Loss: 1.109 , time : 24.041362762451172: 100%|██████████| 1898/1898 [00:24<00:00, 78.81it/s]\n",
      "Epoch: 4. Validation. Loss: 3.754 , time : 2.1070029735565186: 100%|██████████| 475/475 [00:02<00:00, 221.02it/s]\n",
      "Epoch: 5. Train.      Loss: 1.107 , time : 23.552294731140137: 100%|██████████| 1898/1898 [00:23<00:00, 80.44it/s]\n",
      "Epoch: 5. Validation. Loss: 3.762 , time : 2.236449956893921: 100%|██████████| 475/475 [00:02<00:00, 208.46it/s] \n",
      "Epoch: 6. Train.      Loss: 1.106 , time : 23.819113969802856: 100%|██████████| 1898/1898 [00:23<00:00, 79.54it/s]\n",
      "Epoch: 6. Validation. Loss: 3.761 , time : 2.167112112045288: 100%|██████████| 475/475 [00:02<00:00, 214.99it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13948... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▆▅▅▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▄█▄▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.10698</td></tr><tr><td>Min_Val_Loss</td><td>3.74788</td></tr><tr><td>Val_Loss</td><td>3.76222</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fiery-sweep-79</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ua04zuqn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ua04zuqn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_052150-ua04zuqn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u44qmiqn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u44qmiqn\" target=\"_blank\">absurd-sweep-80</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.105 , time : 23.607630252838135: 100%|██████████| 1898/1898 [00:23<00:00, 80.25it/s]\n",
      "Epoch: 0. Validation. Loss: 3.771 , time : 2.174903631210327: 100%|██████████| 475/475 [00:02<00:00, 213.80it/s] \n",
      "Epoch: 1. Train.      Loss: 1.105 , time : 23.80137348175049: 100%|██████████| 1898/1898 [00:23<00:00, 79.54it/s] \n",
      "Epoch: 1. Validation. Loss: 3.763 , time : 2.1618473529815674: 100%|██████████| 475/475 [00:02<00:00, 216.22it/s]\n",
      "Epoch: 2. Train.      Loss: 1.104 , time : 23.67722463607788: 100%|██████████| 1898/1898 [00:23<00:00, 80.02it/s] \n",
      "Epoch: 2. Validation. Loss: 3.758 , time : 2.262416362762451: 100%|██████████| 475/475 [00:02<00:00, 206.14it/s] \n",
      "Epoch: 3. Train.      Loss: 1.103 , time : 23.669098377227783: 100%|██████████| 1898/1898 [00:23<00:00, 79.99it/s]\n",
      "Epoch: 3. Validation. Loss: 3.761 , time : 2.1380414962768555: 100%|██████████| 475/475 [00:02<00:00, 217.89it/s]\n",
      "Epoch: 4. Train.      Loss: 1.102 , time : 23.86433506011963: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s] \n",
      "Epoch: 4. Validation. Loss: 3.761 , time : 2.0991032123565674: 100%|██████████| 475/475 [00:02<00:00, 221.90it/s]\n",
      "Epoch: 5. Train.      Loss: 1.102 , time : 23.699634790420532: 100%|██████████| 1898/1898 [00:23<00:00, 79.94it/s]\n",
      "Epoch: 5. Validation. Loss: 3.766 , time : 2.147515058517456: 100%|██████████| 475/475 [00:02<00:00, 216.98it/s] \n",
      "Epoch: 6. Train.      Loss: 1.102 , time : 23.801593780517578: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s]\n",
      "Epoch: 6. Validation. Loss: 3.766 , time : 2.179738759994507: 100%|██████████| 475/475 [00:02<00:00, 213.83it/s] \n",
      "Epoch: 7. Train.      Loss: 1.101 , time : 23.610780477523804: 100%|██████████| 1898/1898 [00:23<00:00, 80.25it/s]\n",
      "Epoch: 7. Validation. Loss: 3.771 , time : 2.240231513977051: 100%|██████████| 475/475 [00:02<00:00, 208.09it/s] \n",
      "Epoch: 8. Train.      Loss: 1.100 , time : 23.64642906188965: 100%|██████████| 1898/1898 [00:23<00:00, 80.12it/s] \n",
      "Epoch: 8. Validation. Loss: 3.778 , time : 2.1716814041137695: 100%|██████████| 475/475 [00:02<00:00, 214.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15122... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▅▃▃▃▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▄▁▃▂▅▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.10095</td></tr><tr><td>Min_Val_Loss</td><td>3.75777</td></tr><tr><td>Val_Loss</td><td>3.77073</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">absurd-sweep-80</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u44qmiqn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/u44qmiqn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_052503-u44qmiqn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kcate27v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kcate27v\" target=\"_blank\">charmed-sweep-81</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.108 , time : 38.54291844367981: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 0. Validation. Loss: 6.107 , time : 2.215439558029175: 100%|██████████| 475/475 [00:02<00:00, 210.21it/s] \n",
      "Epoch: 1. Train.      Loss: 5.751 , time : 38.72496175765991: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 1. Validation. Loss: 5.903 , time : 2.158592700958252: 100%|██████████| 475/475 [00:02<00:00, 215.04it/s] \n",
      "Epoch: 2. Train.      Loss: 5.437 , time : 39.1709303855896: 100%|██████████| 1898/1898 [00:39<00:00, 48.40it/s]  \n",
      "Epoch: 2. Validation. Loss: 5.623 , time : 2.120499610900879: 100%|██████████| 475/475 [00:02<00:00, 219.66it/s] \n",
      "Epoch: 3. Train.      Loss: 5.093 , time : 38.78469681739807: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 3. Validation. Loss: 5.334 , time : 2.184264898300171: 100%|██████████| 475/475 [00:02<00:00, 213.34it/s] \n",
      "Epoch: 4. Train.      Loss: 4.780 , time : 39.00396990776062: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s] \n",
      "Epoch: 4. Validation. Loss: 5.057 , time : 2.176255226135254: 100%|██████████| 475/475 [00:02<00:00, 213.99it/s] \n",
      "Epoch: 5. Train.      Loss: 4.529 , time : 38.89592432975769: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 5. Validation. Loss: 4.873 , time : 2.261204481124878: 100%|██████████| 475/475 [00:02<00:00, 206.24it/s] \n",
      "Epoch: 6. Train.      Loss: 4.319 , time : 38.61832356452942: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 6. Validation. Loss: 4.717 , time : 2.1887590885162354: 100%|██████████| 475/475 [00:02<00:00, 210.66it/s]\n",
      "Epoch: 7. Train.      Loss: 4.135 , time : 38.695637941360474: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 7. Validation. Loss: 4.590 , time : 2.1953210830688477: 100%|██████████| 475/475 [00:02<00:00, 212.33it/s]\n",
      "Epoch: 8. Train.      Loss: 3.976 , time : 38.569016456604004: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 8. Validation. Loss: 4.489 , time : 2.2515573501586914: 100%|██████████| 475/475 [00:02<00:00, 206.88it/s]\n",
      "Epoch: 9. Train.      Loss: 3.831 , time : 38.79926562309265: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 9. Validation. Loss: 4.343 , time : 2.1494646072387695: 100%|██████████| 475/475 [00:02<00:00, 216.75it/s]\n",
      "Epoch: 10. Train.      Loss: 3.694 , time : 38.55860638618469: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 10. Validation. Loss: 4.267 , time : 2.245779037475586: 100%|██████████| 475/475 [00:02<00:00, 207.62it/s] \n",
      "Epoch: 11. Train.      Loss: 3.576 , time : 38.88085579872131: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 11. Validation. Loss: 4.201 , time : 2.228245258331299: 100%|██████████| 475/475 [00:02<00:00, 209.19it/s] \n",
      "Epoch: 12. Train.      Loss: 3.468 , time : 38.62757849693298: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 12. Validation. Loss: 4.130 , time : 2.156019449234009: 100%|██████████| 475/475 [00:02<00:00, 216.00it/s] \n",
      "Epoch: 13. Train.      Loss: 3.363 , time : 39.216185569763184: 100%|██████████| 1898/1898 [00:39<00:00, 48.35it/s]\n",
      "Epoch: 13. Validation. Loss: 4.044 , time : 2.1655547618865967: 100%|██████████| 475/475 [00:02<00:00, 215.11it/s]\n",
      "Epoch: 14. Train.      Loss: 3.265 , time : 38.38691520690918: 100%|██████████| 1898/1898 [00:38<00:00, 49.39it/s] \n",
      "Epoch: 14. Validation. Loss: 4.003 , time : 2.126829147338867: 100%|██████████| 475/475 [00:02<00:00, 219.02it/s] \n",
      "Epoch: 15. Train.      Loss: 3.175 , time : 38.824816942214966: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 15. Validation. Loss: 3.928 , time : 2.211097478866577: 100%|██████████| 475/475 [00:02<00:00, 210.76it/s] \n",
      "Epoch: 16. Train.      Loss: 3.093 , time : 38.8774516582489: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s]  \n",
      "Epoch: 16. Validation. Loss: 3.892 , time : 2.206509590148926: 100%|██████████| 475/475 [00:02<00:00, 211.30it/s] \n",
      "Epoch: 17. Train.      Loss: 3.011 , time : 38.925451040267944: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s]\n",
      "Epoch: 17. Validation. Loss: 3.858 , time : 2.2217929363250732: 100%|██████████| 475/475 [00:02<00:00, 209.70it/s]\n",
      "Epoch: 18. Train.      Loss: 2.943 , time : 38.536306381225586: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s]\n",
      "Epoch: 18. Validation. Loss: 3.842 , time : 2.170964241027832: 100%|██████████| 475/475 [00:02<00:00, 214.70it/s] \n",
      "Epoch: 19. Train.      Loss: 2.870 , time : 38.661787033081055: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 19. Validation. Loss: 3.786 , time : 2.142885446548462: 100%|██████████| 475/475 [00:02<00:00, 217.55it/s] \n",
      "Epoch: 20. Train.      Loss: 2.808 , time : 39.09365248680115: 100%|██████████| 1898/1898 [00:39<00:00, 48.50it/s] \n",
      "Epoch: 20. Validation. Loss: 3.750 , time : 2.132035970687866: 100%|██████████| 475/475 [00:02<00:00, 218.50it/s] \n",
      "Epoch: 21. Train.      Loss: 2.744 , time : 38.779850482940674: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 21. Validation. Loss: 3.696 , time : 2.2346200942993164: 100%|██████████| 475/475 [00:02<00:00, 208.48it/s]\n",
      "Epoch: 22. Train.      Loss: 2.687 , time : 38.54089832305908: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 22. Validation. Loss: 3.739 , time : 2.1956164836883545: 100%|██████████| 475/475 [00:02<00:00, 212.25it/s]\n",
      "Epoch: 23. Train.      Loss: 2.634 , time : 38.78655004501343: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 23. Validation. Loss: 3.684 , time : 2.195138692855835: 100%|██████████| 475/475 [00:02<00:00, 212.34it/s] \n",
      "Epoch: 24. Train.      Loss: 2.578 , time : 38.883533239364624: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 24. Validation. Loss: 3.672 , time : 2.159205675125122: 100%|██████████| 475/475 [00:02<00:00, 215.79it/s] \n",
      "Epoch: 25. Train.      Loss: 2.534 , time : 38.76368498802185: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 25. Validation. Loss: 3.622 , time : 2.1128971576690674: 100%|██████████| 475/475 [00:02<00:00, 220.47it/s]\n",
      "Epoch: 26. Train.      Loss: 2.483 , time : 39.04536032676697: 100%|██████████| 1898/1898 [00:39<00:00, 48.56it/s] \n",
      "Epoch: 26. Validation. Loss: 3.613 , time : 2.1673996448516846: 100%|██████████| 475/475 [00:02<00:00, 215.01it/s]\n",
      "Epoch: 27. Train.      Loss: 2.439 , time : 38.512413024902344: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s]\n",
      "Epoch: 27. Validation. Loss: 3.652 , time : 2.112762689590454: 100%|██████████| 475/475 [00:02<00:00, 220.27it/s] \n",
      "Epoch: 28. Train.      Loss: 2.392 , time : 38.653398275375366: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]\n",
      "Epoch: 28. Validation. Loss: 3.611 , time : 2.2103190422058105: 100%|██████████| 475/475 [00:02<00:00, 210.84it/s]\n",
      "Epoch: 29. Train.      Loss: 2.347 , time : 38.768715143203735: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s]\n",
      "Epoch: 29. Validation. Loss: 3.641 , time : 2.169361114501953: 100%|██████████| 475/475 [00:02<00:00, 212.71it/s] \n",
      "Epoch: 30. Train.      Loss: 2.311 , time : 38.71368718147278: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 30. Validation. Loss: 3.596 , time : 2.137864828109741: 100%|██████████| 475/475 [00:02<00:00, 217.89it/s] \n",
      "Epoch: 31. Train.      Loss: 2.273 , time : 39.02538228034973: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s] \n",
      "Epoch: 31. Validation. Loss: 3.625 , time : 2.2248570919036865: 100%|██████████| 475/475 [00:02<00:00, 209.54it/s]\n",
      "Epoch: 32. Train.      Loss: 2.234 , time : 38.92036724090576: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 32. Validation. Loss: 3.609 , time : 2.1734681129455566: 100%|██████████| 475/475 [00:02<00:00, 214.40it/s]\n",
      "Epoch: 33. Train.      Loss: 2.194 , time : 38.739914655685425: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]\n",
      "Epoch: 33. Validation. Loss: 3.599 , time : 2.168140411376953: 100%|██████████| 475/475 [00:02<00:00, 214.95it/s] \n",
      "Epoch: 34. Train.      Loss: 2.165 , time : 38.714542865753174: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 34. Validation. Loss: 3.644 , time : 2.147536039352417: 100%|██████████| 475/475 [00:02<00:00, 216.95it/s] \n",
      "Epoch: 35. Train.      Loss: 2.130 , time : 38.689730405807495: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 35. Validation. Loss: 3.654 , time : 2.226318120956421: 100%|██████████| 475/475 [00:02<00:00, 209.27it/s] \n",
      "Epoch: 36. Train.      Loss: 2.096 , time : 39.02663993835449: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s] \n",
      "Epoch: 36. Validation. Loss: 3.693 , time : 2.238722562789917: 100%|██████████| 475/475 [00:02<00:00, 208.22it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16659... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>2.12965</td></tr><tr><td>Min_Val_Loss</td><td>3.59552</td></tr><tr><td>Val_Loss</td><td>3.65421</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">charmed-sweep-81</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kcate27v\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kcate27v</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_052909-kcate27v/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 101jou1b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/101jou1b\" target=\"_blank\">young-sweep-82</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 2.111 , time : 38.52979826927185: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 0. Validation. Loss: 3.670 , time : 2.131817579269409: 100%|██████████| 475/475 [00:02<00:00, 218.52it/s] \n",
      "Epoch: 1. Train.      Loss: 2.037 , time : 38.49076199531555: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 1. Validation. Loss: 3.605 , time : 2.1866848468780518: 100%|██████████| 475/475 [00:02<00:00, 213.14it/s]\n",
      "Epoch: 2. Train.      Loss: 1.998 , time : 38.859232902526855: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s]\n",
      "Epoch: 2. Validation. Loss: 3.625 , time : 2.2195611000061035: 100%|██████████| 475/475 [00:02<00:00, 208.59it/s]\n",
      "Epoch: 3. Train.      Loss: 1.970 , time : 38.55960965156555: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 3. Validation. Loss: 3.670 , time : 2.1412124633789062: 100%|██████████| 475/475 [00:02<00:00, 217.30it/s]\n",
      "Epoch: 4. Train.      Loss: 1.942 , time : 38.681490898132324: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 4. Validation. Loss: 3.640 , time : 2.2168853282928467: 100%|██████████| 475/475 [00:02<00:00, 209.14it/s]\n",
      "Epoch: 5. Train.      Loss: 1.910 , time : 38.69969940185547: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s] \n",
      "Epoch: 5. Validation. Loss: 3.669 , time : 2.1904823780059814: 100%|██████████| 475/475 [00:02<00:00, 212.66it/s]\n",
      "Epoch: 6. Train.      Loss: 1.885 , time : 38.963398456573486: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]\n",
      "Epoch: 6. Validation. Loss: 3.679 , time : 2.1333701610565186: 100%|██████████| 475/475 [00:02<00:00, 218.37it/s]\n",
      "Epoch: 7. Train.      Loss: 1.856 , time : 38.72098422050476: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 7. Validation. Loss: 3.740 , time : 2.2910163402557373: 100%|██████████| 475/475 [00:02<00:00, 203.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25823... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▇▁▃▇▄▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.88546</td></tr><tr><td>Min_Val_Loss</td><td>3.60526</td></tr><tr><td>Val_Loss</td><td>3.67926</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">young-sweep-82</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/101jou1b\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/101jou1b</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_055447-101jou1b/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ahsh43du with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ahsh43du\" target=\"_blank\">dainty-sweep-83</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.878 , time : 38.452325105667114: 100%|██████████| 1898/1898 [00:38<00:00, 49.31it/s]\n",
      "Epoch: 0. Validation. Loss: 3.708 , time : 2.19710636138916: 100%|██████████| 475/475 [00:02<00:00, 212.00it/s]  \n",
      "Epoch: 1. Train.      Loss: 1.809 , time : 38.94413948059082: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 1. Validation. Loss: 3.673 , time : 2.219282627105713: 100%|██████████| 475/475 [00:02<00:00, 210.07it/s] \n",
      "Epoch: 2. Train.      Loss: 1.785 , time : 38.26269817352295: 100%|██████████| 1898/1898 [00:38<00:00, 49.55it/s] \n",
      "Epoch: 2. Validation. Loss: 3.761 , time : 2.0937514305114746: 100%|██████████| 475/475 [00:02<00:00, 222.44it/s]\n",
      "Epoch: 3. Train.      Loss: 1.760 , time : 38.68774747848511: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 3. Validation. Loss: 3.759 , time : 2.150381088256836: 100%|██████████| 475/475 [00:02<00:00, 216.54it/s] \n",
      "Epoch: 4. Train.      Loss: 1.740 , time : 38.91620874404907: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 4. Validation. Loss: 3.805 , time : 2.118584632873535: 100%|██████████| 475/475 [00:02<00:00, 219.83it/s] \n",
      "Epoch: 5. Train.      Loss: 1.712 , time : 38.725579261779785: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s]\n",
      "Epoch: 5. Validation. Loss: 3.759 , time : 2.1409385204315186: 100%|██████████| 475/475 [00:02<00:00, 217.64it/s]\n",
      "Epoch: 6. Train.      Loss: 1.693 , time : 38.900965213775635: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s]\n",
      "Epoch: 6. Validation. Loss: 3.758 , time : 2.1578617095947266: 100%|██████████| 475/475 [00:02<00:00, 215.91it/s]\n",
      "Epoch: 7. Train.      Loss: 1.670 , time : 38.5238618850708: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.782 , time : 2.1201698780059814: 100%|██████████| 475/475 [00:02<00:00, 219.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27854... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▆▆█▆▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.6925</td></tr><tr><td>Min_Val_Loss</td><td>3.67341</td></tr><tr><td>Val_Loss</td><td>3.75806</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dainty-sweep-83</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ahsh43du\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ahsh43du</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_060027-ahsh43du/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2t2we6gy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2t2we6gy\" target=\"_blank\">dutiful-sweep-84</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.689 , time : 38.6395206451416: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.836 , time : 2.1609628200531006: 100%|██████████| 475/475 [00:02<00:00, 215.52it/s]\n",
      "Epoch: 1. Train.      Loss: 1.633 , time : 38.848246812820435: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s]\n",
      "Epoch: 1. Validation. Loss: 3.837 , time : 2.254962921142578: 100%|██████████| 475/475 [00:02<00:00, 206.85it/s] \n",
      "Epoch: 2. Train.      Loss: 1.615 , time : 38.80075764656067: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 2. Validation. Loss: 3.791 , time : 2.1921842098236084: 100%|██████████| 475/475 [00:02<00:00, 212.67it/s]\n",
      "Epoch: 3. Train.      Loss: 1.598 , time : 38.53397297859192: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 3. Validation. Loss: 3.793 , time : 2.12363600730896: 100%|██████████| 475/475 [00:02<00:00, 219.16it/s]  \n",
      "Epoch: 4. Train.      Loss: 1.575 , time : 38.499504804611206: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s]\n",
      "Epoch: 4. Validation. Loss: 3.855 , time : 2.1872975826263428: 100%|██████████| 475/475 [00:02<00:00, 212.93it/s]\n",
      "Epoch: 5. Train.      Loss: 1.555 , time : 38.913684606552124: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 5. Validation. Loss: 3.922 , time : 2.1835296154022217: 100%|██████████| 475/475 [00:02<00:00, 213.25it/s]\n",
      "Epoch: 6. Train.      Loss: 1.539 , time : 38.72064018249512: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 6. Validation. Loss: 3.862 , time : 2.153433084487915: 100%|██████████| 475/475 [00:02<00:00, 216.27it/s] \n",
      "Epoch: 7. Train.      Loss: 1.521 , time : 38.685691356658936: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 7. Validation. Loss: 3.926 , time : 2.1881754398345947: 100%|██████████| 475/475 [00:02<00:00, 213.01it/s]\n",
      "Epoch: 8. Train.      Loss: 1.500 , time : 38.84136176109314: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s] \n",
      "Epoch: 8. Validation. Loss: 3.998 , time : 2.128420352935791: 100%|██████████| 475/475 [00:02<00:00, 218.79it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29907... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃▁▁▄█▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.52102</td></tr><tr><td>Min_Val_Loss</td><td>3.79055</td></tr><tr><td>Val_Loss</td><td>3.9265</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dutiful-sweep-84</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2t2we6gy\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2t2we6gy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_060606-2t2we6gy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lcmnl63t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/lcmnl63t\" target=\"_blank\">ethereal-sweep-85</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.405 , time : 23.563164472579956: 100%|██████████| 1898/1898 [00:23<00:00, 80.40it/s]\n",
      "Epoch: 0. Validation. Loss: 3.941 , time : 2.1746416091918945: 100%|██████████| 475/475 [00:02<00:00, 214.30it/s]\n",
      "Epoch: 1. Train.      Loss: 1.388 , time : 23.71867275238037: 100%|██████████| 1898/1898 [00:23<00:00, 79.88it/s] \n",
      "Epoch: 1. Validation. Loss: 3.938 , time : 2.141462564468384: 100%|██████████| 475/475 [00:02<00:00, 217.56it/s] \n",
      "Epoch: 2. Train.      Loss: 1.378 , time : 23.669984579086304: 100%|██████████| 1898/1898 [00:23<00:00, 80.04it/s]\n",
      "Epoch: 2. Validation. Loss: 3.932 , time : 2.1647355556488037: 100%|██████████| 475/475 [00:02<00:00, 213.13it/s]\n",
      "Epoch: 3. Train.      Loss: 1.371 , time : 23.66010594367981: 100%|██████████| 1898/1898 [00:23<00:00, 80.06it/s] \n",
      "Epoch: 3. Validation. Loss: 3.923 , time : 2.131542921066284: 100%|██████████| 475/475 [00:02<00:00, 218.50it/s] \n",
      "Epoch: 4. Train.      Loss: 1.366 , time : 24.327311277389526: 100%|██████████| 1898/1898 [00:24<00:00, 77.88it/s]\n",
      "Epoch: 4. Validation. Loss: 3.942 , time : 2.185486078262329: 100%|██████████| 475/475 [00:02<00:00, 213.23it/s] \n",
      "Epoch: 5. Train.      Loss: 1.363 , time : 23.759787559509277: 100%|██████████| 1898/1898 [00:23<00:00, 79.74it/s]\n",
      "Epoch: 5. Validation. Loss: 3.930 , time : 2.170912504196167: 100%|██████████| 475/475 [00:02<00:00, 214.67it/s] \n",
      "Epoch: 6. Train.      Loss: 1.358 , time : 23.82880163192749: 100%|██████████| 1898/1898 [00:23<00:00, 79.50it/s] \n",
      "Epoch: 6. Validation. Loss: 3.941 , time : 2.223482608795166: 100%|██████████| 475/475 [00:02<00:00, 209.70it/s] \n",
      "Epoch: 7. Train.      Loss: 1.354 , time : 23.9667649269104: 100%|██████████| 1898/1898 [00:24<00:00, 79.05it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.946 , time : 2.114936351776123: 100%|██████████| 475/475 [00:02<00:00, 220.24it/s] \n",
      "Epoch: 8. Train.      Loss: 1.352 , time : 23.892837524414062: 100%|██████████| 1898/1898 [00:23<00:00, 79.30it/s]\n",
      "Epoch: 8. Validation. Loss: 3.936 , time : 2.237319231033325: 100%|██████████| 475/475 [00:02<00:00, 208.37it/s] \n",
      "Epoch: 9. Train.      Loss: 1.351 , time : 23.79118537902832: 100%|██████████| 1898/1898 [00:23<00:00, 79.64it/s] \n",
      "Epoch: 9. Validation. Loss: 3.939 , time : 2.1176908016204834: 100%|██████████| 475/475 [00:02<00:00, 219.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32142... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▃▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▆▄▁▇▃▇█▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.35211</td></tr><tr><td>Min_Val_Loss</td><td>3.92291</td></tr><tr><td>Val_Loss</td><td>3.93566</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-85</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/lcmnl63t\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/lcmnl63t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_061227-lcmnl63t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8nkrxmd9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8nkrxmd9\" target=\"_blank\">atomic-sweep-86</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.349 , time : 23.725948095321655: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s]\n",
      "Epoch: 0. Validation. Loss: 3.940 , time : 2.1323587894439697: 100%|██████████| 475/475 [00:02<00:00, 218.42it/s]\n",
      "Epoch: 1. Train.      Loss: 1.346 , time : 23.766684532165527: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s]\n",
      "Epoch: 1. Validation. Loss: 3.946 , time : 2.180284261703491: 100%|██████████| 475/475 [00:02<00:00, 213.71it/s] \n",
      "Epoch: 2. Train.      Loss: 1.345 , time : 23.93614912033081: 100%|██████████| 1898/1898 [00:23<00:00, 79.15it/s] \n",
      "Epoch: 2. Validation. Loss: 3.951 , time : 2.19934344291687: 100%|██████████| 475/475 [00:02<00:00, 211.96it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.345 , time : 23.81597352027893: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s] \n",
      "Epoch: 3. Validation. Loss: 3.967 , time : 2.1942245960235596: 100%|██████████| 475/475 [00:02<00:00, 212.46it/s]\n",
      "Epoch: 4. Train.      Loss: 1.345 , time : 24.142794132232666: 100%|██████████| 1898/1898 [00:24<00:00, 78.47it/s]\n",
      "Epoch: 4. Validation. Loss: 3.960 , time : 2.152449131011963: 100%|██████████| 475/475 [00:02<00:00, 216.45it/s] \n",
      "Epoch: 5. Train.      Loss: 1.341 , time : 23.692224264144897: 100%|██████████| 1898/1898 [00:23<00:00, 79.90it/s]\n",
      "Epoch: 5. Validation. Loss: 3.954 , time : 2.1632320880889893: 100%|██████████| 475/475 [00:02<00:00, 215.37it/s]\n",
      "Epoch: 6. Train.      Loss: 1.341 , time : 23.772916316986084: 100%|██████████| 1898/1898 [00:23<00:00, 79.63it/s]\n",
      "Epoch: 6. Validation. Loss: 3.966 , time : 2.2322006225585938: 100%|██████████| 475/475 [00:02<00:00, 208.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2316... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▄▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▄█▆▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.34101</td></tr><tr><td>Min_Val_Loss</td><td>3.94002</td></tr><tr><td>Val_Loss</td><td>3.95352</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">atomic-sweep-86</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8nkrxmd9\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8nkrxmd9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_061658-8nkrxmd9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dpx3hsva with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dpx3hsva\" target=\"_blank\">fine-sweep-87</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.339 , time : 23.726166486740112: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s]\n",
      "Epoch: 0. Validation. Loss: 3.963 , time : 2.1475000381469727: 100%|██████████| 475/475 [00:02<00:00, 216.95it/s]\n",
      "Epoch: 1. Train.      Loss: 1.339 , time : 23.968772649765015: 100%|██████████| 1898/1898 [00:24<00:00, 79.00it/s]\n",
      "Epoch: 1. Validation. Loss: 3.956 , time : 2.2007291316986084: 100%|██████████| 475/475 [00:02<00:00, 211.51it/s]\n",
      "Epoch: 2. Train.      Loss: 1.338 , time : 24.02332592010498: 100%|██████████| 1898/1898 [00:24<00:00, 78.87it/s] \n",
      "Epoch: 2. Validation. Loss: 3.967 , time : 2.184465169906616: 100%|██████████| 475/475 [00:02<00:00, 213.36it/s] \n",
      "Epoch: 3. Train.      Loss: 1.338 , time : 23.976618766784668: 100%|██████████| 1898/1898 [00:24<00:00, 79.02it/s]\n",
      "Epoch: 3. Validation. Loss: 3.976 , time : 2.114501714706421: 100%|██████████| 475/475 [00:02<00:00, 218.27it/s] \n",
      "Epoch: 4. Train.      Loss: 1.336 , time : 23.889832258224487: 100%|██████████| 1898/1898 [00:23<00:00, 79.31it/s]\n",
      "Epoch: 4. Validation. Loss: 3.978 , time : 2.203460454940796: 100%|██████████| 475/475 [00:02<00:00, 211.53it/s] \n",
      "Epoch: 5. Train.      Loss: 1.335 , time : 23.931878566741943: 100%|██████████| 1898/1898 [00:23<00:00, 79.17it/s]\n",
      "Epoch: 5. Validation. Loss: 3.991 , time : 2.269106149673462: 100%|██████████| 475/475 [00:02<00:00, 203.59it/s] \n",
      "Epoch: 6. Train.      Loss: 1.334 , time : 23.962161540985107: 100%|██████████| 1898/1898 [00:24<00:00, 79.07it/s]\n",
      "Epoch: 6. Validation. Loss: 3.989 , time : 2.15967059135437: 100%|██████████| 475/475 [00:02<00:00, 215.69it/s]  \n",
      "Epoch: 7. Train.      Loss: 1.333 , time : 24.004050731658936: 100%|██████████| 1898/1898 [00:24<00:00, 78.93it/s]\n",
      "Epoch: 7. Validation. Loss: 3.994 , time : 2.218951463699341: 100%|██████████| 475/475 [00:02<00:00, 210.04it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3497... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▆▃▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▁▃▅▅██</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.3345</td></tr><tr><td>Min_Val_Loss</td><td>3.9557</td></tr><tr><td>Val_Loss</td><td>3.98927</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fine-sweep-87</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dpx3hsva\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/dpx3hsva</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_062011-dpx3hsva/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: al4rifbu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/al4rifbu\" target=\"_blank\">spring-sweep-88</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.333 , time : 23.85288953781128: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s] \n",
      "Epoch: 0. Validation. Loss: 3.991 , time : 2.187847852706909: 100%|██████████| 475/475 [00:02<00:00, 213.03it/s] \n",
      "Epoch: 1. Train.      Loss: 1.332 , time : 23.858155012130737: 100%|██████████| 1898/1898 [00:23<00:00, 79.41it/s]\n",
      "Epoch: 1. Validation. Loss: 3.999 , time : 2.1994376182556152: 100%|██████████| 475/475 [00:02<00:00, 211.89it/s]\n",
      "Epoch: 2. Train.      Loss: 1.332 , time : 23.85829496383667: 100%|██████████| 1898/1898 [00:23<00:00, 79.41it/s] \n",
      "Epoch: 2. Validation. Loss: 4.002 , time : 2.14774751663208: 100%|██████████| 475/475 [00:02<00:00, 215.52it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.331 , time : 23.825642824172974: 100%|██████████| 1898/1898 [00:23<00:00, 79.52it/s]\n",
      "Epoch: 3. Validation. Loss: 3.998 , time : 2.1930058002471924: 100%|██████████| 475/475 [00:02<00:00, 212.46it/s]\n",
      "Epoch: 4. Train.      Loss: 1.330 , time : 24.017003536224365: 100%|██████████| 1898/1898 [00:24<00:00, 78.89it/s]\n",
      "Epoch: 4. Validation. Loss: 4.002 , time : 2.2353384494781494: 100%|██████████| 475/475 [00:02<00:00, 208.55it/s]\n",
      "Epoch: 5. Train.      Loss: 1.330 , time : 24.48876428604126: 100%|██████████| 1898/1898 [00:24<00:00, 77.34it/s] \n",
      "Epoch: 5. Validation. Loss: 3.995 , time : 2.2744274139404297: 100%|██████████| 475/475 [00:02<00:00, 204.94it/s]\n",
      "Epoch: 6. Train.      Loss: 1.329 , time : 24.105512857437134: 100%|██████████| 1898/1898 [00:24<00:00, 78.60it/s]\n",
      "Epoch: 6. Validation. Loss: 4.004 , time : 2.233595371246338: 100%|██████████| 475/475 [00:02<00:00, 208.68it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4878... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▃▁▂</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▆█▅█▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.33001</td></tr><tr><td>Min_Val_Loss</td><td>3.99098</td></tr><tr><td>Val_Loss</td><td>3.99488</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-88</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/al4rifbu\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/al4rifbu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_062351-al4rifbu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8a0qxnet with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8a0qxnet\" target=\"_blank\">peachy-sweep-89</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.103 , time : 39.24342465400696: 100%|██████████| 1898/1898 [00:39<00:00, 48.29it/s] \n",
      "Epoch: 0. Validation. Loss: 6.099 , time : 2.149087905883789: 100%|██████████| 475/475 [00:02<00:00, 216.79it/s] \n",
      "Epoch: 1. Train.      Loss: 5.716 , time : 38.80962896347046: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 1. Validation. Loss: 5.868 , time : 2.1698415279388428: 100%|██████████| 475/475 [00:02<00:00, 214.55it/s]\n",
      "Epoch: 2. Train.      Loss: 5.382 , time : 38.32314133644104: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s] \n",
      "Epoch: 2. Validation. Loss: 5.588 , time : 2.148916721343994: 100%|██████████| 475/475 [00:02<00:00, 216.80it/s] \n",
      "Epoch: 3. Train.      Loss: 5.023 , time : 38.97573900222778: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s] \n",
      "Epoch: 3. Validation. Loss: 5.268 , time : 2.143207550048828: 100%|██████████| 475/475 [00:02<00:00, 214.96it/s] \n",
      "Epoch: 4. Train.      Loss: 4.694 , time : 38.786338329315186: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]\n",
      "Epoch: 4. Validation. Loss: 4.989 , time : 2.21429443359375: 100%|██████████| 475/475 [00:02<00:00, 210.34it/s]  \n",
      "Epoch: 5. Train.      Loss: 4.425 , time : 38.86768698692322: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s] \n",
      "Epoch: 5. Validation. Loss: 4.771 , time : 2.1668522357940674: 100%|██████████| 475/475 [00:02<00:00, 215.00it/s]\n",
      "Epoch: 6. Train.      Loss: 4.207 , time : 38.791858434677124: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s]\n",
      "Epoch: 6. Validation. Loss: 4.625 , time : 2.1877946853637695: 100%|██████████| 475/475 [00:02<00:00, 213.48it/s]\n",
      "Epoch: 7. Train.      Loss: 4.021 , time : 38.4805691242218: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]  \n",
      "Epoch: 7. Validation. Loss: 4.501 , time : 2.188237190246582: 100%|██████████| 475/475 [00:02<00:00, 212.91it/s] \n",
      "Epoch: 8. Train.      Loss: 3.861 , time : 38.692577838897705: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 8. Validation. Loss: 4.361 , time : 2.2532918453216553: 100%|██████████| 475/475 [00:02<00:00, 206.90it/s]\n",
      "Epoch: 9. Train.      Loss: 3.721 , time : 38.703336000442505: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 9. Validation. Loss: 4.284 , time : 2.114997625350952: 100%|██████████| 475/475 [00:02<00:00, 219.95it/s] \n",
      "Epoch: 10. Train.      Loss: 3.600 , time : 38.66190147399902: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 10. Validation. Loss: 4.201 , time : 2.158824920654297: 100%|██████████| 475/475 [00:02<00:00, 215.83it/s] \n",
      "Epoch: 11. Train.      Loss: 3.488 , time : 39.21548056602478: 100%|██████████| 1898/1898 [00:39<00:00, 48.35it/s] \n",
      "Epoch: 11. Validation. Loss: 4.152 , time : 2.20013165473938: 100%|██████████| 475/475 [00:02<00:00, 211.64it/s]  \n",
      "Epoch: 12. Train.      Loss: 3.386 , time : 38.992666482925415: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s]\n",
      "Epoch: 12. Validation. Loss: 4.073 , time : 2.1502466201782227: 100%|██████████| 475/475 [00:02<00:00, 216.49it/s]\n",
      "Epoch: 13. Train.      Loss: 3.291 , time : 38.96474504470825: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 13. Validation. Loss: 4.010 , time : 2.2144393920898438: 100%|██████████| 475/475 [00:02<00:00, 210.48it/s]\n",
      "Epoch: 14. Train.      Loss: 3.204 , time : 39.34937000274658: 100%|██████████| 1898/1898 [00:39<00:00, 48.18it/s] \n",
      "Epoch: 14. Validation. Loss: 3.951 , time : 2.363273859024048: 100%|██████████| 475/475 [00:02<00:00, 197.32it/s] \n",
      "Epoch: 15. Train.      Loss: 3.128 , time : 42.71528434753418: 100%|██████████| 1898/1898 [00:42<00:00, 44.37it/s] \n",
      "Epoch: 15. Validation. Loss: 3.925 , time : 3.0928609371185303: 100%|██████████| 475/475 [00:03<00:00, 150.84it/s]\n",
      "Epoch: 16. Train.      Loss: 3.053 , time : 52.43030858039856: 100%|██████████| 1898/1898 [00:52<00:00, 36.16it/s] \n",
      "Epoch: 16. Validation. Loss: 3.883 , time : 2.90197491645813: 100%|██████████| 475/475 [00:02<00:00, 160.53it/s]  \n",
      "Epoch: 17. Train.      Loss: 2.982 , time : 52.47055506706238: 100%|██████████| 1898/1898 [00:52<00:00, 36.13it/s] \n",
      "Epoch: 17. Validation. Loss: 3.858 , time : 2.939314842224121: 100%|██████████| 475/475 [00:03<00:00, 158.08it/s] \n",
      "Epoch: 18. Train.      Loss: 2.911 , time : 51.47512674331665: 100%|██████████| 1898/1898 [00:51<00:00, 36.83it/s] \n",
      "Epoch: 18. Validation. Loss: 3.812 , time : 3.0276572704315186: 100%|██████████| 475/475 [00:03<00:00, 153.99it/s]\n",
      "Epoch: 19. Train.      Loss: 2.848 , time : 52.05937194824219: 100%|██████████| 1898/1898 [00:52<00:00, 36.41it/s] \n",
      "Epoch: 19. Validation. Loss: 3.780 , time : 2.851684331893921: 100%|██████████| 475/475 [00:02<00:00, 163.32it/s] \n",
      "Epoch: 20. Train.      Loss: 2.787 , time : 51.86224007606506: 100%|██████████| 1898/1898 [00:51<00:00, 36.56it/s] \n",
      "Epoch: 20. Validation. Loss: 3.731 , time : 2.9184014797210693: 100%|██████████| 475/475 [00:02<00:00, 159.60it/s]\n",
      "Epoch: 21. Train.      Loss: 2.729 , time : 52.771106481552124: 100%|██████████| 1898/1898 [00:52<00:00, 35.93it/s]\n",
      "Epoch: 21. Validation. Loss: 3.757 , time : 2.9958343505859375: 100%|██████████| 475/475 [00:03<00:00, 155.58it/s]\n",
      "Epoch: 22. Train.      Loss: 2.680 , time : 51.74334716796875: 100%|██████████| 1898/1898 [00:51<00:00, 36.64it/s] \n",
      "Epoch: 22. Validation. Loss: 3.677 , time : 2.980919599533081: 100%|██████████| 475/475 [00:03<00:00, 156.37it/s] \n",
      "Epoch: 23. Train.      Loss: 2.626 , time : 51.79729628562927: 100%|██████████| 1898/1898 [00:51<00:00, 36.60it/s] \n",
      "Epoch: 23. Validation. Loss: 3.699 , time : 2.952976703643799: 100%|██████████| 475/475 [00:03<00:00, 157.81it/s] \n",
      "Epoch: 24. Train.      Loss: 2.578 , time : 51.859856843948364: 100%|██████████| 1898/1898 [00:51<00:00, 36.55it/s]\n",
      "Epoch: 24. Validation. Loss: 3.656 , time : 3.022644281387329: 100%|██████████| 475/475 [00:03<00:00, 154.28it/s] \n",
      "Epoch: 25. Train.      Loss: 2.528 , time : 51.56606578826904: 100%|██████████| 1898/1898 [00:51<00:00, 36.77it/s] \n",
      "Epoch: 25. Validation. Loss: 3.643 , time : 2.860175371170044: 100%|██████████| 475/475 [00:02<00:00, 161.37it/s] \n",
      "Epoch: 26. Train.      Loss: 2.485 , time : 51.660916328430176: 100%|██████████| 1898/1898 [00:51<00:00, 36.70it/s]\n",
      "Epoch: 26. Validation. Loss: 3.634 , time : 3.0024161338806152: 100%|██████████| 475/475 [00:03<00:00, 155.27it/s]\n",
      "Epoch: 27. Train.      Loss: 2.441 , time : 50.79859161376953: 100%|██████████| 1898/1898 [00:50<00:00, 37.32it/s] \n",
      "Epoch: 27. Validation. Loss: 3.598 , time : 2.9980309009552: 100%|██████████| 475/475 [00:03<00:00, 154.99it/s]   \n",
      "Epoch: 28. Train.      Loss: 2.401 , time : 51.06814527511597: 100%|██████████| 1898/1898 [00:51<00:00, 37.11it/s] \n",
      "Epoch: 28. Validation. Loss: 3.620 , time : 3.062131404876709: 100%|██████████| 475/475 [00:03<00:00, 152.30it/s] \n",
      "Epoch: 29. Train.      Loss: 2.361 , time : 52.60594940185547: 100%|██████████| 1898/1898 [00:52<00:00, 36.04it/s] \n",
      "Epoch: 29. Validation. Loss: 3.585 , time : 3.9017176628112793: 100%|██████████| 475/475 [00:04<00:00, 118.67it/s]\n",
      "Epoch: 30. Train.      Loss: 2.321 , time : 66.91763925552368: 100%|██████████| 1898/1898 [01:07<00:00, 28.32it/s] \n",
      "Epoch: 30. Validation. Loss: 3.601 , time : 4.297012090682983: 100%|██████████| 475/475 [00:04<00:00, 108.61it/s] \n",
      "Epoch: 31. Train.      Loss: 2.287 , time : 65.23022675514221: 100%|██████████| 1898/1898 [01:05<00:00, 29.05it/s] \n",
      "Epoch: 31. Validation. Loss: 3.595 , time : 4.567502021789551: 100%|██████████| 475/475 [00:04<00:00, 101.48it/s] \n",
      "Epoch: 32. Train.      Loss: 2.252 , time : 58.72766423225403: 100%|██████████| 1898/1898 [00:58<00:00, 32.26it/s] \n",
      "Epoch: 32. Validation. Loss: 3.606 , time : 4.451528310775757: 100%|██████████| 475/475 [00:04<00:00, 103.72it/s] \n",
      "Epoch: 33. Train.      Loss: 2.215 , time : 67.85280990600586: 100%|██████████| 1898/1898 [01:07<00:00, 27.93it/s] \n",
      "Epoch: 33. Validation. Loss: 3.588 , time : 4.454432487487793: 100%|██████████| 475/475 [00:04<00:00, 104.83it/s] \n",
      "Epoch: 34. Train.      Loss: 2.184 , time : 56.399354219436646: 100%|██████████| 1898/1898 [00:56<00:00, 33.63it/s]\n",
      "Epoch: 34. Validation. Loss: 3.583 , time : 2.580779790878296: 100%|██████████| 475/475 [00:02<00:00, 180.11it/s] \n",
      "Epoch: 35. Train.      Loss: 2.152 , time : 52.406001806259155: 100%|██████████| 1898/1898 [00:52<00:00, 36.18it/s]\n",
      "Epoch: 35. Validation. Loss: 3.575 , time : 3.1597907543182373: 100%|██████████| 475/475 [00:03<00:00, 147.64it/s]\n",
      "Epoch: 36. Train.      Loss: 2.122 , time : 52.94640588760376: 100%|██████████| 1898/1898 [00:53<00:00, 35.81it/s] \n",
      "Epoch: 36. Validation. Loss: 3.572 , time : 3.3071506023406982: 100%|██████████| 475/475 [00:03<00:00, 141.19it/s]\n",
      "Epoch: 37. Train.      Loss: 2.088 , time : 48.93404698371887: 100%|██████████| 1898/1898 [00:48<00:00, 38.75it/s] \n",
      "Epoch: 37. Validation. Loss: 3.620 , time : 2.3539531230926514: 100%|██████████| 475/475 [00:02<00:00, 197.65it/s]\n",
      "Epoch: 38. Train.      Loss: 2.059 , time : 51.432987213134766: 100%|██████████| 1898/1898 [00:51<00:00, 36.86it/s]\n",
      "Epoch: 38. Validation. Loss: 3.595 , time : 3.298389196395874: 100%|██████████| 475/475 [00:03<00:00, 141.60it/s] \n",
      "Epoch: 39. Train.      Loss: 2.033 , time : 51.87666440010071: 100%|██████████| 1898/1898 [00:51<00:00, 36.55it/s] \n",
      "Epoch: 39. Validation. Loss: 3.556 , time : 3.1135904788970947: 100%|██████████| 475/475 [00:03<00:00, 149.81it/s]\n",
      "Epoch: 40. Train.      Loss: 2.000 , time : 50.52603220939636: 100%|██████████| 1898/1898 [00:50<00:00, 37.53it/s] \n",
      "Epoch: 40. Validation. Loss: 3.579 , time : 2.1635477542877197: 100%|██████████| 475/475 [00:02<00:00, 215.15it/s]\n",
      "Epoch: 41. Train.      Loss: 1.974 , time : 38.89522099494934: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 41. Validation. Loss: 3.563 , time : 2.1408886909484863: 100%|██████████| 475/475 [00:02<00:00, 217.56it/s]\n",
      "Epoch: 42. Train.      Loss: 1.949 , time : 38.92326784133911: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 42. Validation. Loss: 3.580 , time : 2.179488182067871: 100%|██████████| 475/475 [00:02<00:00, 213.65it/s] \n",
      "Epoch: 43. Train.      Loss: 1.922 , time : 38.77752375602722: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 43. Validation. Loss: 3.590 , time : 2.1295316219329834: 100%|██████████| 475/475 [00:02<00:00, 218.70it/s]\n",
      "Epoch: 44. Train.      Loss: 1.894 , time : 39.031075954437256: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s]\n",
      "Epoch: 44. Validation. Loss: 3.567 , time : 2.1466805934906006: 100%|██████████| 475/475 [00:02<00:00, 216.96it/s]\n",
      "Epoch: 45. Train.      Loss: 1.869 , time : 38.439566135406494: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s]\n",
      "Epoch: 45. Validation. Loss: 3.595 , time : 2.162388324737549: 100%|██████████| 475/475 [00:02<00:00, 215.45it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6832... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.89353</td></tr><tr><td>Min_Val_Loss</td><td>3.55604</td></tr><tr><td>Val_Loss</td><td>3.56698</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">peachy-sweep-89</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8a0qxnet\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8a0qxnet</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_062709-8a0qxnet/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rv9hval5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv9hval5\" target=\"_blank\">vague-sweep-90</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.890 , time : 38.47153353691101: 100%|██████████| 1898/1898 [00:38<00:00, 49.28it/s] \n",
      "Epoch: 0. Validation. Loss: 3.593 , time : 2.146397590637207: 100%|██████████| 475/475 [00:02<00:00, 217.15it/s] \n",
      "Epoch: 1. Train.      Loss: 1.822 , time : 38.62608075141907: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 1. Validation. Loss: 3.589 , time : 2.2072808742523193: 100%|██████████| 475/475 [00:02<00:00, 211.20it/s]\n",
      "Epoch: 2. Train.      Loss: 1.798 , time : 38.4191358089447: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.596 , time : 2.1941845417022705: 100%|██████████| 475/475 [00:02<00:00, 212.49it/s]\n",
      "Epoch: 3. Train.      Loss: 1.776 , time : 38.62076234817505: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 3. Validation. Loss: 3.592 , time : 2.1374728679656982: 100%|██████████| 475/475 [00:02<00:00, 218.06it/s]\n",
      "Epoch: 4. Train.      Loss: 1.755 , time : 38.8087522983551: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s]  \n",
      "Epoch: 4. Validation. Loss: 3.607 , time : 2.1624624729156494: 100%|██████████| 475/475 [00:02<00:00, 215.44it/s]\n",
      "Epoch: 5. Train.      Loss: 1.727 , time : 38.999208211898804: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s]\n",
      "Epoch: 5. Validation. Loss: 3.599 , time : 2.1781530380249023: 100%|██████████| 475/475 [00:02<00:00, 213.84it/s]\n",
      "Epoch: 6. Train.      Loss: 1.711 , time : 39.02036237716675: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 6. Validation. Loss: 3.638 , time : 2.1574995517730713: 100%|██████████| 475/475 [00:02<00:00, 214.53it/s]\n",
      "Epoch: 7. Train.      Loss: 1.687 , time : 38.65526509284973: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 7. Validation. Loss: 3.635 , time : 2.2041091918945312: 100%|██████████| 475/475 [00:02<00:00, 211.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24028... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▂▁▄▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.71149</td></tr><tr><td>Min_Val_Loss</td><td>3.58934</td></tr><tr><td>Val_Loss</td><td>3.63763</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vague-sweep-90</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv9hval5\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/rv9hval5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_070754-rv9hval5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v5py2hxz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v5py2hxz\" target=\"_blank\">fanciful-sweep-91</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.706 , time : 38.695794105529785: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 0. Validation. Loss: 3.632 , time : 2.105491876602173: 100%|██████████| 475/475 [00:02<00:00, 221.25it/s] \n",
      "Epoch: 1. Train.      Loss: 1.652 , time : 38.319947481155396: 100%|██████████| 1898/1898 [00:38<00:00, 49.47it/s]\n",
      "Epoch: 1. Validation. Loss: 3.657 , time : 2.131094455718994: 100%|██████████| 475/475 [00:02<00:00, 218.62it/s] \n",
      "Epoch: 2. Train.      Loss: 1.634 , time : 38.65588116645813: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 2. Validation. Loss: 3.634 , time : 2.1455752849578857: 100%|██████████| 475/475 [00:02<00:00, 217.15it/s]\n",
      "Epoch: 3. Train.      Loss: 1.610 , time : 38.70738387107849: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 3. Validation. Loss: 3.653 , time : 2.170781135559082: 100%|██████████| 475/475 [00:02<00:00, 214.73it/s] \n",
      "Epoch: 4. Train.      Loss: 1.592 , time : 38.8695809841156: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]  \n",
      "Epoch: 4. Validation. Loss: 3.685 , time : 2.1606943607330322: 100%|██████████| 475/475 [00:02<00:00, 215.68it/s]\n",
      "Epoch: 5. Train.      Loss: 1.572 , time : 38.59296226501465: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 5. Validation. Loss: 3.682 , time : 2.1994214057922363: 100%|██████████| 475/475 [00:02<00:00, 211.89it/s]\n",
      "Epoch: 6. Train.      Loss: 1.561 , time : 39.02524375915527: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s] \n",
      "Epoch: 6. Validation. Loss: 3.662 , time : 2.1931679248809814: 100%|██████████| 475/475 [00:02<00:00, 212.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26066... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄▁▄██</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.57199</td></tr><tr><td>Min_Val_Loss</td><td>3.63173</td></tr><tr><td>Val_Loss</td><td>3.68178</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fanciful-sweep-91</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v5py2hxz\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v5py2hxz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_071338-v5py2hxz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0pzccjhk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pzccjhk\" target=\"_blank\">trim-sweep-92</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.578 , time : 39.14264178276062: 100%|██████████| 1898/1898 [00:39<00:00, 48.44it/s] \n",
      "Epoch: 0. Validation. Loss: 3.648 , time : 2.180666446685791: 100%|██████████| 475/475 [00:02<00:00, 213.73it/s] \n",
      "Epoch: 1. Train.      Loss: 1.529 , time : 38.74750065803528: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 1. Validation. Loss: 3.653 , time : 2.215425729751587: 100%|██████████| 475/475 [00:02<00:00, 210.32it/s] \n",
      "Epoch: 2. Train.      Loss: 1.516 , time : 38.45451879501343: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 2. Validation. Loss: 3.666 , time : 2.180400848388672: 100%|██████████| 475/475 [00:02<00:00, 213.72it/s] \n",
      "Epoch: 3. Train.      Loss: 1.496 , time : 39.0986590385437: 100%|██████████| 1898/1898 [00:39<00:00, 48.49it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.660 , time : 2.263099193572998: 100%|██████████| 475/475 [00:02<00:00, 206.10it/s] \n",
      "Epoch: 4. Train.      Loss: 1.486 , time : 38.57270646095276: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 4. Validation. Loss: 3.654 , time : 2.159108877182007: 100%|██████████| 475/475 [00:02<00:00, 215.87it/s] \n",
      "Epoch: 5. Train.      Loss: 1.467 , time : 38.634814977645874: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s]\n",
      "Epoch: 5. Validation. Loss: 3.660 , time : 2.2332875728607178: 100%|██████████| 475/475 [00:02<00:00, 208.50it/s]\n",
      "Epoch: 6. Train.      Loss: 1.453 , time : 38.96806192398071: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 6. Validation. Loss: 3.705 , time : 2.2123515605926514: 100%|██████████| 475/475 [00:02<00:00, 210.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28564... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃█▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.46689</td></tr><tr><td>Min_Val_Loss</td><td>3.64775</td></tr><tr><td>Val_Loss</td><td>3.65971</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">trim-sweep-92</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pzccjhk\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0pzccjhk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_072045-0pzccjhk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pc77i59o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pc77i59o\" target=\"_blank\">ethereal-sweep-93</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.359 , time : 23.809349298477173: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s]\n",
      "Epoch: 0. Validation. Loss: 3.681 , time : 2.1489381790161133: 100%|██████████| 475/475 [00:02<00:00, 216.86it/s]\n",
      "Epoch: 1. Train.      Loss: 1.344 , time : 23.80863356590271: 100%|██████████| 1898/1898 [00:23<00:00, 79.58it/s] \n",
      "Epoch: 1. Validation. Loss: 3.683 , time : 2.2675788402557373: 100%|██████████| 475/475 [00:02<00:00, 205.50it/s]\n",
      "Epoch: 2. Train.      Loss: 1.336 , time : 23.70181155204773: 100%|██████████| 1898/1898 [00:23<00:00, 79.94it/s] \n",
      "Epoch: 2. Validation. Loss: 3.668 , time : 2.2156870365142822: 100%|██████████| 475/475 [00:02<00:00, 210.31it/s]\n",
      "Epoch: 3. Train.      Loss: 1.330 , time : 23.77189826965332: 100%|██████████| 1898/1898 [00:23<00:00, 79.70it/s] \n",
      "Epoch: 3. Validation. Loss: 3.659 , time : 2.190769672393799: 100%|██████████| 475/475 [00:02<00:00, 212.77it/s] \n",
      "Epoch: 4. Train.      Loss: 1.325 , time : 23.738390684127808: 100%|██████████| 1898/1898 [00:23<00:00, 79.81it/s]\n",
      "Epoch: 4. Validation. Loss: 3.661 , time : 2.144678831100464: 100%|██████████| 475/475 [00:02<00:00, 217.27it/s] \n",
      "Epoch: 5. Train.      Loss: 1.321 , time : 23.818823099136353: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s]\n",
      "Epoch: 5. Validation. Loss: 3.654 , time : 2.1344001293182373: 100%|██████████| 475/475 [00:02<00:00, 218.32it/s]\n",
      "Epoch: 6. Train.      Loss: 1.318 , time : 23.729426622390747: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s]\n",
      "Epoch: 6. Validation. Loss: 3.654 , time : 2.1256027221679688: 100%|██████████| 475/475 [00:02<00:00, 219.06it/s]\n",
      "Epoch: 7. Train.      Loss: 1.314 , time : 23.749213695526123: 100%|██████████| 1898/1898 [00:23<00:00, 79.72it/s]\n",
      "Epoch: 7. Validation. Loss: 3.660 , time : 2.2439653873443604: 100%|██████████| 475/475 [00:02<00:00, 207.84it/s]\n",
      "Epoch: 8. Train.      Loss: 1.312 , time : 23.77896237373352: 100%|██████████| 1898/1898 [00:23<00:00, 79.57it/s] \n",
      "Epoch: 8. Validation. Loss: 3.661 , time : 2.1835410594940186: 100%|██████████| 475/475 [00:02<00:00, 213.47it/s]\n",
      "Epoch: 9. Train.      Loss: 1.310 , time : 23.966712713241577: 100%|██████████| 1898/1898 [00:24<00:00, 79.05it/s]\n",
      "Epoch: 9. Validation. Loss: 3.657 , time : 2.1853816509246826: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s]\n",
      "Epoch: 10. Train.      Loss: 1.308 , time : 23.731441497802734: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s]\n",
      "Epoch: 10. Validation. Loss: 3.658 , time : 2.1492409706115723: 100%|██████████| 475/475 [00:02<00:00, 216.83it/s]\n",
      "Epoch: 11. Train.      Loss: 1.307 , time : 24.09109854698181: 100%|██████████| 1898/1898 [00:24<00:00, 78.64it/s] \n",
      "Epoch: 11. Validation. Loss: 3.665 , time : 2.2057249546051025: 100%|██████████| 475/475 [00:02<00:00, 211.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31110... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▅▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▇█▄▂▃▁▁▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.30795</td></tr><tr><td>Min_Val_Loss</td><td>3.6535</td></tr><tr><td>Val_Loss</td><td>3.65801</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-93</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pc77i59o\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/pc77i59o</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_072753-pc77i59o/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h3f5zliw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/h3f5zliw\" target=\"_blank\">wobbly-sweep-94</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.305 , time : 23.80349564552307: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s] \n",
      "Epoch: 0. Validation. Loss: 3.659 , time : 2.157344102859497: 100%|██████████| 475/475 [00:02<00:00, 213.84it/s] \n",
      "Epoch: 1. Train.      Loss: 1.303 , time : 23.659464120864868: 100%|██████████| 1898/1898 [00:23<00:00, 80.08it/s]\n",
      "Epoch: 1. Validation. Loss: 3.653 , time : 2.1467247009277344: 100%|██████████| 475/475 [00:02<00:00, 217.18it/s]\n",
      "Epoch: 2. Train.      Loss: 1.302 , time : 23.643389463424683: 100%|██████████| 1898/1898 [00:23<00:00, 80.13it/s]\n",
      "Epoch: 2. Validation. Loss: 3.660 , time : 2.150094747543335: 100%|██████████| 475/475 [00:02<00:00, 216.74it/s] \n",
      "Epoch: 3. Train.      Loss: 1.301 , time : 23.51451086997986: 100%|██████████| 1898/1898 [00:23<00:00, 80.57it/s] \n",
      "Epoch: 3. Validation. Loss: 3.661 , time : 2.194082736968994: 100%|██████████| 475/475 [00:02<00:00, 212.31it/s] \n",
      "Epoch: 4. Train.      Loss: 1.300 , time : 23.820175886154175: 100%|██████████| 1898/1898 [00:23<00:00, 79.54it/s]\n",
      "Epoch: 4. Validation. Loss: 3.657 , time : 2.141798973083496: 100%|██████████| 475/475 [00:02<00:00, 217.60it/s] \n",
      "Epoch: 5. Train.      Loss: 1.299 , time : 23.765745401382446: 100%|██████████| 1898/1898 [00:23<00:00, 79.72it/s]\n",
      "Epoch: 5. Validation. Loss: 3.670 , time : 2.1342384815216064: 100%|██████████| 475/475 [00:02<00:00, 218.18it/s]\n",
      "Epoch: 6. Train.      Loss: 1.298 , time : 23.87138557434082: 100%|██████████| 1898/1898 [00:23<00:00, 79.37it/s] \n",
      "Epoch: 6. Validation. Loss: 3.657 , time : 2.1242992877960205: 100%|██████████| 475/475 [00:02<00:00, 219.22it/s]\n",
      "Epoch: 7. Train.      Loss: 1.297 , time : 23.865014791488647: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s]\n",
      "Epoch: 7. Validation. Loss: 3.661 , time : 2.1229922771453857: 100%|██████████| 475/475 [00:02<00:00, 219.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 649... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▄▅▃█▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.2978</td></tr><tr><td>Min_Val_Loss</td><td>3.6532</td></tr><tr><td>Val_Loss</td><td>3.65688</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wobbly-sweep-94</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/h3f5zliw\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/h3f5zliw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_073317-h3f5zliw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fb1jy2v2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fb1jy2v2\" target=\"_blank\">jolly-sweep-95</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.297 , time : 23.74755883216858: 100%|██████████| 1898/1898 [00:23<00:00, 79.78it/s] \n",
      "Epoch: 0. Validation. Loss: 3.660 , time : 2.133877992630005: 100%|██████████| 475/475 [00:02<00:00, 216.50it/s] \n",
      "Epoch: 1. Train.      Loss: 1.297 , time : 23.516706705093384: 100%|██████████| 1898/1898 [00:23<00:00, 80.57it/s]\n",
      "Epoch: 1. Validation. Loss: 3.667 , time : 2.1296863555908203: 100%|██████████| 475/475 [00:02<00:00, 218.81it/s]\n",
      "Epoch: 2. Train.      Loss: 1.295 , time : 23.822786808013916: 100%|██████████| 1898/1898 [00:23<00:00, 79.53it/s]\n",
      "Epoch: 2. Validation. Loss: 3.664 , time : 2.1800713539123535: 100%|██████████| 475/475 [00:02<00:00, 211.84it/s]\n",
      "Epoch: 3. Train.      Loss: 1.294 , time : 23.7145357131958: 100%|██████████| 1898/1898 [00:23<00:00, 79.89it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.671 , time : 2.1452107429504395: 100%|██████████| 475/475 [00:02<00:00, 217.24it/s]\n",
      "Epoch: 4. Train.      Loss: 1.293 , time : 23.902061700820923: 100%|██████████| 1898/1898 [00:23<00:00, 79.27it/s]\n",
      "Epoch: 4. Validation. Loss: 3.665 , time : 2.121668815612793: 100%|██████████| 475/475 [00:02<00:00, 219.55it/s] \n",
      "Epoch: 5. Train.      Loss: 1.292 , time : 23.84356117248535: 100%|██████████| 1898/1898 [00:23<00:00, 79.46it/s] \n",
      "Epoch: 5. Validation. Loss: 3.665 , time : 2.1211774349212646: 100%|██████████| 475/475 [00:02<00:00, 219.48it/s]\n",
      "Epoch: 6. Train.      Loss: 1.292 , time : 23.693268060684204: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s]\n",
      "Epoch: 6. Validation. Loss: 3.668 , time : 2.1849474906921387: 100%|██████████| 475/475 [00:02<00:00, 213.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2852... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▇█▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▃█▄▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.29232</td></tr><tr><td>Min_Val_Loss</td><td>3.65996</td></tr><tr><td>Val_Loss</td><td>3.66509</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">jolly-sweep-95</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fb1jy2v2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/fb1jy2v2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_073906-fb1jy2v2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1nwx7emf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1nwx7emf\" target=\"_blank\">dark-sweep-96</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.292 , time : 23.54761791229248: 100%|██████████| 1898/1898 [00:23<00:00, 80.46it/s] \n",
      "Epoch: 0. Validation. Loss: 3.684 , time : 2.2061376571655273: 100%|██████████| 475/475 [00:02<00:00, 211.32it/s]\n",
      "Epoch: 1. Train.      Loss: 1.291 , time : 23.682299375534058: 100%|██████████| 1898/1898 [00:23<00:00, 80.00it/s]\n",
      "Epoch: 1. Validation. Loss: 3.680 , time : 2.0961663722991943: 100%|██████████| 475/475 [00:02<00:00, 222.24it/s]\n",
      "Epoch: 2. Train.      Loss: 1.291 , time : 23.762698650360107: 100%|██████████| 1898/1898 [00:23<00:00, 79.73it/s]\n",
      "Epoch: 2. Validation. Loss: 3.669 , time : 2.1243083477020264: 100%|██████████| 475/475 [00:02<00:00, 219.28it/s]\n",
      "Epoch: 3. Train.      Loss: 1.291 , time : 23.852436065673828: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s]\n",
      "Epoch: 3. Validation. Loss: 3.673 , time : 2.155409812927246: 100%|██████████| 475/475 [00:02<00:00, 216.25it/s] \n",
      "Epoch: 4. Train.      Loss: 1.290 , time : 23.68901777267456: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s] \n",
      "Epoch: 4. Validation. Loss: 3.673 , time : 2.146758794784546: 100%|██████████| 475/475 [00:02<00:00, 217.00it/s] \n",
      "Epoch: 5. Train.      Loss: 1.289 , time : 23.910685300827026: 100%|██████████| 1898/1898 [00:23<00:00, 79.24it/s]\n",
      "Epoch: 5. Validation. Loss: 3.674 , time : 2.1933412551879883: 100%|██████████| 475/475 [00:02<00:00, 212.57it/s]\n",
      "Epoch: 6. Train.      Loss: 1.288 , time : 23.785736560821533: 100%|██████████| 1898/1898 [00:23<00:00, 79.65it/s]\n",
      "Epoch: 6. Validation. Loss: 3.673 , time : 2.168985605239868: 100%|██████████| 475/475 [00:02<00:00, 214.87it/s] \n",
      "Epoch: 7. Train.      Loss: 1.288 , time : 23.639760732650757: 100%|██████████| 1898/1898 [00:23<00:00, 80.14it/s]\n",
      "Epoch: 7. Validation. Loss: 3.675 , time : 2.1745097637176514: 100%|██████████| 475/475 [00:02<00:00, 214.44it/s]\n",
      "Epoch: 8. Train.      Loss: 1.287 , time : 23.967237949371338: 100%|██████████| 1898/1898 [00:24<00:00, 79.05it/s]\n",
      "Epoch: 8. Validation. Loss: 3.684 , time : 2.183176279067993: 100%|██████████| 475/475 [00:02<00:00, 213.47it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4757... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆█▆▅▃▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▆▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▆▁▃▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.28751</td></tr><tr><td>Min_Val_Loss</td><td>3.6692</td></tr><tr><td>Val_Loss</td><td>3.67473</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dark-sweep-96</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1nwx7emf\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/1nwx7emf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_074429-1nwx7emf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mnkylfhr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mnkylfhr\" target=\"_blank\">charmed-sweep-97</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.095 , time : 38.555413484573364: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s]\n",
      "Epoch: 0. Validation. Loss: 6.076 , time : 2.124415874481201: 100%|██████████| 475/475 [00:02<00:00, 219.31it/s] \n",
      "Epoch: 1. Train.      Loss: 5.695 , time : 38.67442059516907: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 1. Validation. Loss: 5.861 , time : 2.163987636566162: 100%|██████████| 475/475 [00:02<00:00, 215.29it/s] \n",
      "Epoch: 2. Train.      Loss: 5.363 , time : 38.51490092277527: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 2. Validation. Loss: 5.582 , time : 2.1762185096740723: 100%|██████████| 475/475 [00:02<00:00, 214.19it/s]\n",
      "Epoch: 3. Train.      Loss: 5.013 , time : 38.73699736595154: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 3. Validation. Loss: 5.276 , time : 2.1662416458129883: 100%|██████████| 475/475 [00:02<00:00, 215.15it/s]\n",
      "Epoch: 4. Train.      Loss: 4.689 , time : 39.09800672531128: 100%|██████████| 1898/1898 [00:39<00:00, 48.46it/s] \n",
      "Epoch: 4. Validation. Loss: 4.985 , time : 2.1692287921905518: 100%|██████████| 475/475 [00:02<00:00, 214.91it/s]\n",
      "Epoch: 5. Train.      Loss: 4.414 , time : 38.61323833465576: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 5. Validation. Loss: 4.776 , time : 2.1592063903808594: 100%|██████████| 475/475 [00:02<00:00, 215.82it/s]\n",
      "Epoch: 6. Train.      Loss: 4.184 , time : 38.85459518432617: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 6. Validation. Loss: 4.628 , time : 2.1577775478363037: 100%|██████████| 475/475 [00:02<00:00, 215.99it/s]\n",
      "Epoch: 7. Train.      Loss: 3.990 , time : 38.507059812545776: 100%|██████████| 1898/1898 [00:38<00:00, 49.23it/s]\n",
      "Epoch: 7. Validation. Loss: 4.479 , time : 2.182351589202881: 100%|██████████| 475/475 [00:02<00:00, 213.67it/s] \n",
      "Epoch: 8. Train.      Loss: 3.829 , time : 38.43082356452942: 100%|██████████| 1898/1898 [00:38<00:00, 49.33it/s] \n",
      "Epoch: 8. Validation. Loss: 4.346 , time : 2.11245059967041: 100%|██████████| 475/475 [00:02<00:00, 220.42it/s]  \n",
      "Epoch: 9. Train.      Loss: 3.681 , time : 38.73172974586487: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 9. Validation. Loss: 4.240 , time : 2.1472294330596924: 100%|██████████| 475/475 [00:02<00:00, 216.86it/s]\n",
      "Epoch: 10. Train.      Loss: 3.549 , time : 38.90044379234314: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 10. Validation. Loss: 4.194 , time : 2.1632373332977295: 100%|██████████| 475/475 [00:02<00:00, 215.46it/s]\n",
      "Epoch: 11. Train.      Loss: 3.432 , time : 38.20421266555786: 100%|██████████| 1898/1898 [00:38<00:00, 49.60it/s] \n",
      "Epoch: 11. Validation. Loss: 4.134 , time : 2.108672618865967: 100%|██████████| 475/475 [00:02<00:00, 220.94it/s] \n",
      "Epoch: 12. Train.      Loss: 3.324 , time : 38.50269079208374: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 12. Validation. Loss: 4.027 , time : 2.193544864654541: 100%|██████████| 475/475 [00:02<00:00, 212.38it/s] \n",
      "Epoch: 13. Train.      Loss: 3.221 , time : 38.51985192298889: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 13. Validation. Loss: 4.011 , time : 2.158604383468628: 100%|██████████| 475/475 [00:02<00:00, 215.92it/s] \n",
      "Epoch: 14. Train.      Loss: 3.128 , time : 38.68595290184021: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 14. Validation. Loss: 3.944 , time : 2.1490862369537354: 100%|██████████| 475/475 [00:02<00:00, 216.82it/s]\n",
      "Epoch: 15. Train.      Loss: 3.038 , time : 38.651387214660645: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]\n",
      "Epoch: 15. Validation. Loss: 3.896 , time : 2.1152522563934326: 100%|██████████| 475/475 [00:02<00:00, 220.23it/s]\n",
      "Epoch: 16. Train.      Loss: 2.952 , time : 38.88724207878113: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 16. Validation. Loss: 3.835 , time : 2.1662001609802246: 100%|██████████| 475/475 [00:02<00:00, 215.18it/s]\n",
      "Epoch: 17. Train.      Loss: 2.872 , time : 39.41514730453491: 100%|██████████| 1898/1898 [00:39<00:00, 48.10it/s] \n",
      "Epoch: 17. Validation. Loss: 3.831 , time : 2.149263858795166: 100%|██████████| 475/475 [00:02<00:00, 216.81it/s] \n",
      "Epoch: 18. Train.      Loss: 2.802 , time : 39.86314821243286: 100%|██████████| 1898/1898 [00:39<00:00, 47.56it/s] \n",
      "Epoch: 18. Validation. Loss: 3.731 , time : 2.251234292984009: 100%|██████████| 475/475 [00:02<00:00, 207.22it/s] \n",
      "Epoch: 19. Train.      Loss: 2.735 , time : 39.298397064208984: 100%|██████████| 1898/1898 [00:39<00:00, 48.24it/s]\n",
      "Epoch: 19. Validation. Loss: 3.736 , time : 2.146726608276367: 100%|██████████| 475/475 [00:02<00:00, 217.02it/s] \n",
      "Epoch: 20. Train.      Loss: 2.667 , time : 38.97662925720215: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 20. Validation. Loss: 3.704 , time : 2.163705825805664: 100%|██████████| 475/475 [00:02<00:00, 215.38it/s] \n",
      "Epoch: 21. Train.      Loss: 2.602 , time : 38.79983425140381: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 21. Validation. Loss: 3.693 , time : 2.166189193725586: 100%|██████████| 475/475 [00:02<00:00, 215.15it/s] \n",
      "Epoch: 22. Train.      Loss: 2.544 , time : 38.62332844734192: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s] \n",
      "Epoch: 22. Validation. Loss: 3.672 , time : 2.191990375518799: 100%|██████████| 475/475 [00:02<00:00, 212.72it/s] \n",
      "Epoch: 23. Train.      Loss: 2.491 , time : 38.53745198249817: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 23. Validation. Loss: 3.642 , time : 2.104625940322876: 100%|██████████| 475/475 [00:02<00:00, 221.35it/s] \n",
      "Epoch: 24. Train.      Loss: 2.437 , time : 38.74510645866394: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 24. Validation. Loss: 3.632 , time : 2.109786033630371: 100%|██████████| 475/475 [00:02<00:00, 220.75it/s] \n",
      "Epoch: 25. Train.      Loss: 2.388 , time : 38.91115927696228: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 25. Validation. Loss: 3.620 , time : 2.145338773727417: 100%|██████████| 475/475 [00:02<00:00, 215.27it/s] \n",
      "Epoch: 26. Train.      Loss: 2.333 , time : 38.80150485038757: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 26. Validation. Loss: 3.617 , time : 2.207732915878296: 100%|██████████| 475/475 [00:02<00:00, 210.98it/s] \n",
      "Epoch: 27. Train.      Loss: 2.289 , time : 38.81041955947876: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 27. Validation. Loss: 3.586 , time : 2.164320707321167: 100%|██████████| 475/475 [00:02<00:00, 215.34it/s] \n",
      "Epoch: 28. Train.      Loss: 2.242 , time : 38.742143869400024: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s]\n",
      "Epoch: 28. Validation. Loss: 3.582 , time : 2.1292099952697754: 100%|██████████| 475/475 [00:02<00:00, 218.66it/s]\n",
      "Epoch: 29. Train.      Loss: 2.200 , time : 38.73279023170471: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 29. Validation. Loss: 3.565 , time : 2.1624343395233154: 100%|██████████| 475/475 [00:02<00:00, 215.49it/s]\n",
      "Epoch: 30. Train.      Loss: 2.158 , time : 38.54560041427612: 100%|██████████| 1898/1898 [00:38<00:00, 49.18it/s] \n",
      "Epoch: 30. Validation. Loss: 3.591 , time : 2.106870174407959: 100%|██████████| 475/475 [00:02<00:00, 220.94it/s] \n",
      "Epoch: 31. Train.      Loss: 2.118 , time : 38.60701894760132: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s] \n",
      "Epoch: 31. Validation. Loss: 3.588 , time : 2.145266532897949: 100%|██████████| 475/475 [00:02<00:00, 217.25it/s] \n",
      "Epoch: 32. Train.      Loss: 2.081 , time : 38.68187379837036: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 32. Validation. Loss: 3.580 , time : 2.1704235076904297: 100%|██████████| 475/475 [00:02<00:00, 214.77it/s]\n",
      "Epoch: 33. Train.      Loss: 2.046 , time : 38.67480111122131: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 33. Validation. Loss: 3.566 , time : 2.138514518737793: 100%|██████████| 475/475 [00:02<00:00, 217.80it/s] \n",
      "Epoch: 34. Train.      Loss: 2.006 , time : 38.830833435058594: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s]\n",
      "Epoch: 34. Validation. Loss: 3.553 , time : 2.212972640991211: 100%|██████████| 475/475 [00:02<00:00, 210.56it/s] \n",
      "Epoch: 35. Train.      Loss: 1.970 , time : 38.97434115409851: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s] \n",
      "Epoch: 35. Validation. Loss: 3.549 , time : 2.1443941593170166: 100%|██████████| 475/475 [00:02<00:00, 217.30it/s]\n",
      "Epoch: 36. Train.      Loss: 1.937 , time : 38.417359590530396: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]\n",
      "Epoch: 36. Validation. Loss: 3.538 , time : 2.1823816299438477: 100%|██████████| 475/475 [00:02<00:00, 213.41it/s]\n",
      "Epoch: 37. Train.      Loss: 1.906 , time : 38.74351620674133: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 37. Validation. Loss: 3.590 , time : 2.1662960052490234: 100%|██████████| 475/475 [00:02<00:00, 213.28it/s]\n",
      "Epoch: 38. Train.      Loss: 1.872 , time : 38.72927379608154: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 38. Validation. Loss: 3.537 , time : 2.1586573123931885: 100%|██████████| 475/475 [00:02<00:00, 215.91it/s]\n",
      "Epoch: 39. Train.      Loss: 1.838 , time : 38.97803711891174: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 39. Validation. Loss: 3.538 , time : 2.180837392807007: 100%|██████████| 475/475 [00:02<00:00, 213.78it/s] \n",
      "Epoch: 40. Train.      Loss: 1.809 , time : 39.0239052772522: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s]  \n",
      "Epoch: 40. Validation. Loss: 3.567 , time : 2.103527545928955: 100%|██████████| 475/475 [00:02<00:00, 221.37it/s] \n",
      "Epoch: 41. Train.      Loss: 1.775 , time : 38.83084559440613: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 41. Validation. Loss: 3.578 , time : 2.156127691268921: 100%|██████████| 475/475 [00:02<00:00, 215.98it/s] \n",
      "Epoch: 42. Train.      Loss: 1.751 , time : 38.64255928993225: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s] \n",
      "Epoch: 42. Validation. Loss: 3.562 , time : 2.1670165061950684: 100%|██████████| 475/475 [00:02<00:00, 215.09it/s]\n",
      "Epoch: 43. Train.      Loss: 1.720 , time : 38.44217491149902: 100%|██████████| 1898/1898 [00:38<00:00, 49.32it/s] \n",
      "Epoch: 43. Validation. Loss: 3.584 , time : 2.174492359161377: 100%|██████████| 475/475 [00:02<00:00, 214.40it/s] \n",
      "Epoch: 44. Train.      Loss: 1.691 , time : 38.89510631561279: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s] \n",
      "Epoch: 44. Validation. Loss: 3.578 , time : 2.128309965133667: 100%|██████████| 475/475 [00:02<00:00, 218.95it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7013... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.71971</td></tr><tr><td>Min_Val_Loss</td><td>3.53692</td></tr><tr><td>Val_Loss</td><td>3.58354</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">charmed-sweep-97</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mnkylfhr\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mnkylfhr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_075045-mnkylfhr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0s2ehgf3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0s2ehgf3\" target=\"_blank\">solar-sweep-98</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.709 , time : 38.416250467300415: 100%|██████████| 1898/1898 [00:38<00:00, 49.35it/s]\n",
      "Epoch: 0. Validation. Loss: 3.577 , time : 2.194396734237671: 100%|██████████| 475/475 [00:02<00:00, 212.46it/s] \n",
      "Epoch: 1. Train.      Loss: 1.637 , time : 38.398844480514526: 100%|██████████| 1898/1898 [00:38<00:00, 49.36it/s]\n",
      "Epoch: 1. Validation. Loss: 3.601 , time : 2.1239664554595947: 100%|██████████| 475/475 [00:02<00:00, 219.19it/s]\n",
      "Epoch: 2. Train.      Loss: 1.614 , time : 39.10134983062744: 100%|██████████| 1898/1898 [00:39<00:00, 48.49it/s] \n",
      "Epoch: 2. Validation. Loss: 3.632 , time : 2.132054090499878: 100%|██████████| 475/475 [00:02<00:00, 218.48it/s] \n",
      "Epoch: 3. Train.      Loss: 1.584 , time : 38.586493492126465: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s]\n",
      "Epoch: 3. Validation. Loss: 3.584 , time : 2.1886308193206787: 100%|██████████| 475/475 [00:02<00:00, 212.99it/s]\n",
      "Epoch: 4. Train.      Loss: 1.561 , time : 38.74820899963379: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 4. Validation. Loss: 3.588 , time : 2.2144715785980225: 100%|██████████| 475/475 [00:02<00:00, 210.48it/s]\n",
      "Epoch: 5. Train.      Loss: 1.532 , time : 38.68733835220337: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 5. Validation. Loss: 3.623 , time : 2.1583261489868164: 100%|██████████| 475/475 [00:02<00:00, 215.91it/s]\n",
      "Epoch: 6. Train.      Loss: 1.510 , time : 38.85951566696167: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 6. Validation. Loss: 3.641 , time : 2.142622232437134: 100%|██████████| 475/475 [00:02<00:00, 216.74it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18787... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄█▂▂▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.53223</td></tr><tr><td>Min_Val_Loss</td><td>3.57657</td></tr><tr><td>Val_Loss</td><td>3.62293</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">solar-sweep-98</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0s2ehgf3\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/0s2ehgf3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_082350-0s2ehgf3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67vzivip with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/67vzivip\" target=\"_blank\">smart-sweep-99</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.527 , time : 38.67743134498596: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 0. Validation. Loss: 3.614 , time : 2.189789295196533: 100%|██████████| 475/475 [00:02<00:00, 212.84it/s] \n",
      "Epoch: 1. Train.      Loss: 1.467 , time : 38.93093276023865: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 1. Validation. Loss: 3.610 , time : 2.1631903648376465: 100%|██████████| 475/475 [00:02<00:00, 215.43it/s]\n",
      "Epoch: 2. Train.      Loss: 1.448 , time : 38.618857622146606: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s]\n",
      "Epoch: 2. Validation. Loss: 3.594 , time : 2.160168409347534: 100%|██████████| 475/475 [00:02<00:00, 213.77it/s] \n",
      "Epoch: 3. Train.      Loss: 1.421 , time : 38.7087299823761: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.641 , time : 2.2288527488708496: 100%|██████████| 475/475 [00:02<00:00, 209.17it/s]\n",
      "Epoch: 4. Train.      Loss: 1.401 , time : 38.58230543136597: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 4. Validation. Loss: 3.666 , time : 2.1780662536621094: 100%|██████████| 475/475 [00:02<00:00, 214.03it/s]\n",
      "Epoch: 5. Train.      Loss: 1.380 , time : 38.79637575149536: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 5. Validation. Loss: 3.670 , time : 2.1717681884765625: 100%|██████████| 475/475 [00:02<00:00, 214.49it/s]\n",
      "Epoch: 6. Train.      Loss: 1.360 , time : 38.93733310699463: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 6. Validation. Loss: 3.681 , time : 2.1702077388763428: 100%|██████████| 475/475 [00:02<00:00, 214.74it/s]\n",
      "Epoch: 7. Train.      Loss: 1.339 , time : 38.69818353652954: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s] \n",
      "Epoch: 7. Validation. Loss: 3.694 , time : 2.205411911010742: 100%|██████████| 475/475 [00:02<00:00, 211.40it/s] \n",
      "Epoch: 8. Train.      Loss: 1.322 , time : 38.53655242919922: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 8. Validation. Loss: 3.707 , time : 2.2058463096618652: 100%|██████████| 475/475 [00:02<00:00, 208.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21292... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▂▁▄▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.33937</td></tr><tr><td>Min_Val_Loss</td><td>3.59401</td></tr><tr><td>Val_Loss</td><td>3.69368</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">smart-sweep-99</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/67vzivip\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/67vzivip</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_083058-67vzivip/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9mydwyf2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mydwyf2\" target=\"_blank\">iconic-sweep-100</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.337 , time : 38.672388553619385: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s]\n",
      "Epoch: 0. Validation. Loss: 3.701 , time : 2.193952798843384: 100%|██████████| 475/475 [00:02<00:00, 212.46it/s] \n",
      "Epoch: 1. Train.      Loss: 1.290 , time : 38.65865159034729: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 1. Validation. Loss: 3.678 , time : 2.1168406009674072: 100%|██████████| 475/475 [00:02<00:00, 219.92it/s]\n",
      "Epoch: 2. Train.      Loss: 1.271 , time : 38.558247566223145: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s]\n",
      "Epoch: 2. Validation. Loss: 3.672 , time : 2.1786856651306152: 100%|██████████| 475/475 [00:02<00:00, 213.96it/s]\n",
      "Epoch: 3. Train.      Loss: 1.256 , time : 38.725383043289185: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s]\n",
      "Epoch: 3. Validation. Loss: 3.752 , time : 2.1789889335632324: 100%|██████████| 475/475 [00:02<00:00, 213.90it/s]\n",
      "Epoch: 4. Train.      Loss: 1.240 , time : 38.754090547561646: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s]\n",
      "Epoch: 4. Validation. Loss: 3.717 , time : 2.1001408100128174: 100%|██████████| 475/475 [00:02<00:00, 221.80it/s]\n",
      "Epoch: 5. Train.      Loss: 1.221 , time : 38.84516191482544: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 5. Validation. Loss: 3.744 , time : 2.2178561687469482: 100%|██████████| 475/475 [00:02<00:00, 210.25it/s]\n",
      "Epoch: 6. Train.      Loss: 1.208 , time : 38.81114935874939: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 6. Validation. Loss: 3.730 , time : 2.1659469604492188: 100%|██████████| 475/475 [00:02<00:00, 215.03it/s]\n",
      "Epoch: 7. Train.      Loss: 1.189 , time : 38.8051118850708: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s]  \n",
      "Epoch: 7. Validation. Loss: 3.747 , time : 2.1848480701446533: 100%|██████████| 475/475 [00:02<00:00, 213.33it/s]\n",
      "Epoch: 8. Train.      Loss: 1.174 , time : 38.649822473526: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]   \n",
      "Epoch: 8. Validation. Loss: 3.715 , time : 2.1948206424713135: 100%|██████████| 475/475 [00:02<00:00, 212.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24274... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▁█▅▇▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.18905</td></tr><tr><td>Min_Val_Loss</td><td>3.67213</td></tr><tr><td>Val_Loss</td><td>3.74711</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">iconic-sweep-100</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mydwyf2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9mydwyf2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_083931-9mydwyf2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ijz44r3p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ijz44r3p\" target=\"_blank\">wild-sweep-101</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.082 , time : 23.767226934432983: 100%|██████████| 1898/1898 [00:23<00:00, 79.71it/s]\n",
      "Epoch: 0. Validation. Loss: 3.701 , time : 2.1488819122314453: 100%|██████████| 475/475 [00:02<00:00, 216.73it/s]\n",
      "Epoch: 1. Train.      Loss: 1.065 , time : 23.84678077697754: 100%|██████████| 1898/1898 [00:23<00:00, 79.45it/s] \n",
      "Epoch: 1. Validation. Loss: 3.700 , time : 2.148144006729126: 100%|██████████| 475/475 [00:02<00:00, 216.91it/s] \n",
      "Epoch: 2. Train.      Loss: 1.056 , time : 23.82178521156311: 100%|██████████| 1898/1898 [00:23<00:00, 79.53it/s] \n",
      "Epoch: 2. Validation. Loss: 3.697 , time : 2.205366849899292: 100%|██████████| 475/475 [00:02<00:00, 211.38it/s] \n",
      "Epoch: 3. Train.      Loss: 1.050 , time : 23.69691276550293: 100%|██████████| 1898/1898 [00:23<00:00, 79.95it/s] \n",
      "Epoch: 3. Validation. Loss: 3.700 , time : 2.1618781089782715: 100%|██████████| 475/475 [00:02<00:00, 215.51it/s]\n",
      "Epoch: 4. Train.      Loss: 1.045 , time : 23.72750735282898: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s] \n",
      "Epoch: 4. Validation. Loss: 3.699 , time : 2.142033338546753: 100%|██████████| 475/475 [00:02<00:00, 217.44it/s] \n",
      "Epoch: 5. Train.      Loss: 1.041 , time : 23.67090654373169: 100%|██████████| 1898/1898 [00:23<00:00, 80.04it/s] \n",
      "Epoch: 5. Validation. Loss: 3.705 , time : 2.1005022525787354: 100%|██████████| 475/475 [00:02<00:00, 220.15it/s]\n",
      "Epoch: 6. Train.      Loss: 1.037 , time : 23.982515573501587: 100%|██████████| 1898/1898 [00:24<00:00, 79.00it/s]\n",
      "Epoch: 6. Validation. Loss: 3.694 , time : 2.1628706455230713: 100%|██████████| 475/475 [00:02<00:00, 215.47it/s]\n",
      "Epoch: 7. Train.      Loss: 1.034 , time : 23.659891605377197: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]\n",
      "Epoch: 7. Validation. Loss: 3.691 , time : 2.1649959087371826: 100%|██████████| 475/475 [00:02<00:00, 215.11it/s]\n",
      "Epoch: 8. Train.      Loss: 1.032 , time : 23.94658851623535: 100%|██████████| 1898/1898 [00:23<00:00, 79.12it/s] \n",
      "Epoch: 8. Validation. Loss: 3.732 , time : 2.1634652614593506: 100%|██████████| 475/475 [00:02<00:00, 215.39it/s]\n",
      "Epoch: 9. Train.      Loss: 1.030 , time : 23.794927835464478: 100%|██████████| 1898/1898 [00:23<00:00, 79.62it/s]\n",
      "Epoch: 9. Validation. Loss: 3.697 , time : 2.1775293350219727: 100%|██████████| 475/475 [00:02<00:00, 211.94it/s]\n",
      "Epoch: 10. Train.      Loss: 1.029 , time : 23.80931067466736: 100%|██████████| 1898/1898 [00:23<00:00, 79.57it/s] \n",
      "Epoch: 10. Validation. Loss: 3.699 , time : 2.2043721675872803: 100%|██████████| 475/475 [00:02<00:00, 211.50it/s]\n",
      "Epoch: 11. Train.      Loss: 1.027 , time : 24.015745878219604: 100%|██████████| 1898/1898 [00:24<00:00, 78.89it/s]\n",
      "Epoch: 11. Validation. Loss: 3.703 , time : 2.0914065837860107: 100%|██████████| 475/475 [00:02<00:00, 222.62it/s]\n",
      "Epoch: 12. Train.      Loss: 1.026 , time : 23.58237361907959: 100%|██████████| 1898/1898 [00:23<00:00, 80.34it/s] \n",
      "Epoch: 12. Validation. Loss: 3.705 , time : 2.135878086090088: 100%|██████████| 475/475 [00:02<00:00, 218.20it/s] \n",
      "Epoch: 13. Train.      Loss: 1.024 , time : 23.664475679397583: 100%|██████████| 1898/1898 [00:23<00:00, 80.06it/s]\n",
      "Epoch: 13. Validation. Loss: 3.699 , time : 2.0955617427825928: 100%|██████████| 475/475 [00:02<00:00, 221.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27224... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▅▅▅▅▃▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▂▂▃▂▃▁▁█▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.02577</td></tr><tr><td>Min_Val_Loss</td><td>3.69125</td></tr><tr><td>Val_Loss</td><td>3.70474</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wild-sweep-101</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ijz44r3p\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/ijz44r3p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_084801-ijz44r3p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mj6zqu0p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mj6zqu0p\" target=\"_blank\">feasible-sweep-102</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.023 , time : 23.54084300994873: 100%|██████████| 1898/1898 [00:23<00:00, 80.40it/s] \n",
      "Epoch: 0. Validation. Loss: 3.705 , time : 2.1663897037506104: 100%|██████████| 475/475 [00:02<00:00, 215.06it/s]\n",
      "Epoch: 1. Train.      Loss: 1.022 , time : 23.783358573913574: 100%|██████████| 1898/1898 [00:23<00:00, 79.66it/s]\n",
      "Epoch: 1. Validation. Loss: 3.708 , time : 2.1361734867095947: 100%|██████████| 475/475 [00:02<00:00, 217.06it/s]\n",
      "Epoch: 2. Train.      Loss: 1.020 , time : 23.703600645065308: 100%|██████████| 1898/1898 [00:23<00:00, 79.93it/s]\n",
      "Epoch: 2. Validation. Loss: 3.713 , time : 2.1736738681793213: 100%|██████████| 475/475 [00:02<00:00, 214.40it/s]\n",
      "Epoch: 3. Train.      Loss: 1.020 , time : 23.69461965560913: 100%|██████████| 1898/1898 [00:23<00:00, 79.96it/s] \n",
      "Epoch: 3. Validation. Loss: 3.710 , time : 2.1750292778015137: 100%|██████████| 475/475 [00:02<00:00, 214.26it/s]\n",
      "Epoch: 4. Train.      Loss: 1.019 , time : 23.625020027160645: 100%|██████████| 1898/1898 [00:23<00:00, 80.20it/s]\n",
      "Epoch: 4. Validation. Loss: 3.715 , time : 2.126131057739258: 100%|██████████| 475/475 [00:02<00:00, 219.04it/s] \n",
      "Epoch: 5. Train.      Loss: 1.018 , time : 23.712701559066772: 100%|██████████| 1898/1898 [00:23<00:00, 79.90it/s]\n",
      "Epoch: 5. Validation. Loss: 3.714 , time : 2.1178853511810303: 100%|██████████| 475/475 [00:02<00:00, 219.76it/s]\n",
      "Epoch: 6. Train.      Loss: 1.018 , time : 23.584591388702393: 100%|██████████| 1898/1898 [00:23<00:00, 80.32it/s]\n",
      "Epoch: 6. Validation. Loss: 3.716 , time : 2.1917850971221924: 100%|██████████| 475/475 [00:02<00:00, 212.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30189... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▇▄█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.01828</td></tr><tr><td>Min_Val_Loss</td><td>3.70481</td></tr><tr><td>Val_Loss</td><td>3.71353</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">feasible-sweep-102</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mj6zqu0p\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/mj6zqu0p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_085626-mj6zqu0p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: azfqitq6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/azfqitq6\" target=\"_blank\">upbeat-sweep-103</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.016 , time : 23.739136934280396: 100%|██████████| 1898/1898 [00:23<00:00, 79.81it/s]\n",
      "Epoch: 0. Validation. Loss: 3.720 , time : 2.294191837310791: 100%|██████████| 475/475 [00:02<00:00, 203.37it/s] \n",
      "Epoch: 1. Train.      Loss: 1.016 , time : 23.55256223678589: 100%|██████████| 1898/1898 [00:23<00:00, 80.44it/s] \n",
      "Epoch: 1. Validation. Loss: 3.725 , time : 2.0985426902770996: 100%|██████████| 475/475 [00:02<00:00, 221.97it/s]\n",
      "Epoch: 2. Train.      Loss: 1.015 , time : 23.398678302764893: 100%|██████████| 1898/1898 [00:23<00:00, 80.96it/s]\n",
      "Epoch: 2. Validation. Loss: 3.725 , time : 2.1051185131073: 100%|██████████| 475/475 [00:02<00:00, 221.32it/s]   \n",
      "Epoch: 3. Train.      Loss: 1.015 , time : 23.585561752319336: 100%|██████████| 1898/1898 [00:23<00:00, 80.33it/s]\n",
      "Epoch: 3. Validation. Loss: 3.722 , time : 2.1736435890197754: 100%|██████████| 475/475 [00:02<00:00, 214.47it/s]\n",
      "Epoch: 4. Train.      Loss: 1.014 , time : 23.598085641860962: 100%|██████████| 1898/1898 [00:23<00:00, 80.28it/s]\n",
      "Epoch: 4. Validation. Loss: 3.729 , time : 2.2706730365753174: 100%|██████████| 475/475 [00:02<00:00, 205.43it/s]\n",
      "Epoch: 5. Train.      Loss: 1.013 , time : 23.517056226730347: 100%|██████████| 1898/1898 [00:23<00:00, 80.56it/s]\n",
      "Epoch: 5. Validation. Loss: 3.728 , time : 2.0929629802703857: 100%|██████████| 475/475 [00:02<00:00, 222.53it/s]\n",
      "Epoch: 6. Train.      Loss: 1.012 , time : 23.79715657234192: 100%|██████████| 1898/1898 [00:23<00:00, 79.62it/s] \n",
      "Epoch: 6. Validation. Loss: 3.731 , time : 2.122086524963379: 100%|██████████| 475/475 [00:02<00:00, 219.59it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31357... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▄▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▄▂█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.01316</td></tr><tr><td>Min_Val_Loss</td><td>3.72</td></tr><tr><td>Val_Loss</td><td>3.72769</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">upbeat-sweep-103</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/azfqitq6\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/azfqitq6</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_085939-azfqitq6/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wsm1cgll with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wsm1cgll\" target=\"_blank\">olive-sweep-104</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.011 , time : 23.742745876312256: 100%|██████████| 1898/1898 [00:23<00:00, 79.80it/s]\n",
      "Epoch: 0. Validation. Loss: 3.734 , time : 2.1828739643096924: 100%|██████████| 475/475 [00:02<00:00, 213.51it/s]\n",
      "Epoch: 1. Train.      Loss: 1.011 , time : 23.59035873413086: 100%|██████████| 1898/1898 [00:23<00:00, 80.31it/s] \n",
      "Epoch: 1. Validation. Loss: 3.745 , time : 2.1709060668945312: 100%|██████████| 475/475 [00:02<00:00, 214.45it/s]\n",
      "Epoch: 2. Train.      Loss: 1.010 , time : 23.85854935646057: 100%|██████████| 1898/1898 [00:23<00:00, 79.40it/s] \n",
      "Epoch: 2. Validation. Loss: 3.742 , time : 2.144655227661133: 100%|██████████| 475/475 [00:02<00:00, 217.24it/s] \n",
      "Epoch: 3. Train.      Loss: 1.010 , time : 23.78265380859375: 100%|██████████| 1898/1898 [00:23<00:00, 79.66it/s] \n",
      "Epoch: 3. Validation. Loss: 3.735 , time : 2.150597333908081: 100%|██████████| 475/475 [00:02<00:00, 216.66it/s] \n",
      "Epoch: 4. Train.      Loss: 1.009 , time : 23.85445761680603: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s] \n",
      "Epoch: 4. Validation. Loss: 3.736 , time : 2.139758348464966: 100%|██████████| 475/475 [00:02<00:00, 217.65it/s] \n",
      "Epoch: 5. Train.      Loss: 1.008 , time : 23.815468072891235: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s]\n",
      "Epoch: 5. Validation. Loss: 3.746 , time : 2.160069465637207: 100%|██████████| 475/475 [00:02<00:00, 215.74it/s] \n",
      "Epoch: 6. Train.      Loss: 1.008 , time : 23.79971694946289: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s] \n",
      "Epoch: 6. Validation. Loss: 3.743 , time : 2.122490644454956: 100%|██████████| 475/475 [00:02<00:00, 219.49it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32555... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▄▃▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▇▅▁▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.00844</td></tr><tr><td>Min_Val_Loss</td><td>3.73399</td></tr><tr><td>Val_Loss</td><td>3.74618</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-104</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wsm1cgll\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/wsm1cgll</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_090253-wsm1cgll/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kxxq2s9b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kxxq2s9b\" target=\"_blank\">bright-sweep-105</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.097 , time : 38.79010987281799: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s] \n",
      "Epoch: 0. Validation. Loss: 6.068 , time : 2.1950008869171143: 100%|██████████| 475/475 [00:02<00:00, 212.24it/s]\n",
      "Epoch: 1. Train.      Loss: 5.673 , time : 38.48210287094116: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s] \n",
      "Epoch: 1. Validation. Loss: 5.814 , time : 2.1731951236724854: 100%|██████████| 475/475 [00:02<00:00, 214.45it/s]\n",
      "Epoch: 2. Train.      Loss: 5.287 , time : 38.80629372596741: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 2. Validation. Loss: 5.477 , time : 2.210893392562866: 100%|██████████| 475/475 [00:02<00:00, 210.75it/s] \n",
      "Epoch: 3. Train.      Loss: 4.897 , time : 39.07899498939514: 100%|██████████| 1898/1898 [00:39<00:00, 48.51it/s] \n",
      "Epoch: 3. Validation. Loss: 5.142 , time : 2.2022464275360107: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s]\n",
      "Epoch: 4. Train.      Loss: 4.576 , time : 38.85546350479126: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 4. Validation. Loss: 4.888 , time : 2.164877414703369: 100%|██████████| 475/475 [00:02<00:00, 212.97it/s] \n",
      "Epoch: 5. Train.      Loss: 4.336 , time : 38.99059343338013: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 5. Validation. Loss: 4.708 , time : 2.312825918197632: 100%|██████████| 475/475 [00:02<00:00, 201.72it/s] \n",
      "Epoch: 6. Train.      Loss: 4.138 , time : 39.03861379623413: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s] \n",
      "Epoch: 6. Validation. Loss: 4.558 , time : 2.20680832862854: 100%|██████████| 475/475 [00:02<00:00, 211.23it/s]  \n",
      "Epoch: 7. Train.      Loss: 3.968 , time : 38.74134016036987: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 7. Validation. Loss: 4.456 , time : 2.1547443866729736: 100%|██████████| 475/475 [00:02<00:00, 216.26it/s]\n",
      "Epoch: 8. Train.      Loss: 3.820 , time : 39.06225943565369: 100%|██████████| 1898/1898 [00:39<00:00, 48.54it/s] \n",
      "Epoch: 8. Validation. Loss: 4.337 , time : 2.1457159519195557: 100%|██████████| 475/475 [00:02<00:00, 217.18it/s]\n",
      "Epoch: 9. Train.      Loss: 3.688 , time : 38.570513010025024: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 9. Validation. Loss: 4.253 , time : 2.139887809753418: 100%|██████████| 475/475 [00:02<00:00, 217.72it/s] \n",
      "Epoch: 10. Train.      Loss: 3.565 , time : 38.704946517944336: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s]\n",
      "Epoch: 10. Validation. Loss: 4.189 , time : 2.167595386505127: 100%|██████████| 475/475 [00:02<00:00, 212.47it/s] \n",
      "Epoch: 11. Train.      Loss: 3.456 , time : 39.07446074485779: 100%|██████████| 1898/1898 [00:39<00:00, 48.52it/s] \n",
      "Epoch: 11. Validation. Loss: 4.120 , time : 2.2118568420410156: 100%|██████████| 475/475 [00:02<00:00, 210.58it/s]\n",
      "Epoch: 12. Train.      Loss: 3.358 , time : 38.94004487991333: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 12. Validation. Loss: 4.072 , time : 2.1551260948181152: 100%|██████████| 475/475 [00:02<00:00, 216.21it/s]\n",
      "Epoch: 13. Train.      Loss: 3.266 , time : 38.645851850509644: 100%|██████████| 1898/1898 [00:38<00:00, 49.06it/s]\n",
      "Epoch: 13. Validation. Loss: 3.978 , time : 2.1113388538360596: 100%|██████████| 475/475 [00:02<00:00, 220.54it/s]\n",
      "Epoch: 14. Train.      Loss: 3.177 , time : 38.897292137145996: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s]\n",
      "Epoch: 14. Validation. Loss: 3.957 , time : 2.2410154342651367: 100%|██████████| 475/475 [00:02<00:00, 207.99it/s]\n",
      "Epoch: 15. Train.      Loss: 3.095 , time : 38.99981927871704: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s] \n",
      "Epoch: 15. Validation. Loss: 3.898 , time : 2.2029097080230713: 100%|██████████| 475/475 [00:02<00:00, 211.48it/s]\n",
      "Epoch: 16. Train.      Loss: 3.019 , time : 38.82058644294739: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 16. Validation. Loss: 3.864 , time : 2.1643996238708496: 100%|██████████| 475/475 [00:02<00:00, 215.24it/s]\n",
      "Epoch: 17. Train.      Loss: 2.945 , time : 39.23034715652466: 100%|██████████| 1898/1898 [00:39<00:00, 48.33it/s] \n",
      "Epoch: 17. Validation. Loss: 3.787 , time : 2.172257661819458: 100%|██████████| 475/475 [00:02<00:00, 214.34it/s] \n",
      "Epoch: 18. Train.      Loss: 2.876 , time : 38.81349849700928: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 18. Validation. Loss: 3.767 , time : 2.137913465499878: 100%|██████████| 475/475 [00:02<00:00, 217.91it/s] \n",
      "Epoch: 19. Train.      Loss: 2.813 , time : 39.14224982261658: 100%|██████████| 1898/1898 [00:39<00:00, 48.44it/s] \n",
      "Epoch: 19. Validation. Loss: 3.734 , time : 2.107905626296997: 100%|██████████| 475/475 [00:02<00:00, 220.75it/s] \n",
      "Epoch: 20. Train.      Loss: 2.752 , time : 39.01879954338074: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 20. Validation. Loss: 3.722 , time : 2.1534881591796875: 100%|██████████| 475/475 [00:02<00:00, 216.04it/s]\n",
      "Epoch: 21. Train.      Loss: 2.691 , time : 38.856926918029785: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s]\n",
      "Epoch: 21. Validation. Loss: 3.676 , time : 2.1415722370147705: 100%|██████████| 475/475 [00:02<00:00, 217.60it/s]\n",
      "Epoch: 22. Train.      Loss: 2.636 , time : 38.90587615966797: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 22. Validation. Loss: 3.687 , time : 2.1550748348236084: 100%|██████████| 475/475 [00:02<00:00, 216.25it/s]\n",
      "Epoch: 23. Train.      Loss: 2.582 , time : 38.763952016830444: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]\n",
      "Epoch: 23. Validation. Loss: 3.651 , time : 2.1369173526763916: 100%|██████████| 475/475 [00:02<00:00, 215.95it/s]\n",
      "Epoch: 24. Train.      Loss: 2.531 , time : 39.611589670181274: 100%|██████████| 1898/1898 [00:39<00:00, 47.86it/s]\n",
      "Epoch: 24. Validation. Loss: 3.654 , time : 2.260284423828125: 100%|██████████| 475/475 [00:02<00:00, 206.31it/s] \n",
      "Epoch: 25. Train.      Loss: 2.483 , time : 39.309351205825806: 100%|██████████| 1898/1898 [00:39<00:00, 48.23it/s]\n",
      "Epoch: 25. Validation. Loss: 3.596 , time : 2.1933305263519287: 100%|██████████| 475/475 [00:02<00:00, 212.48it/s]\n",
      "Epoch: 26. Train.      Loss: 2.433 , time : 38.87552309036255: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 26. Validation. Loss: 3.574 , time : 2.148117780685425: 100%|██████████| 475/475 [00:02<00:00, 216.92it/s] \n",
      "Epoch: 27. Train.      Loss: 2.390 , time : 38.91685247421265: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 27. Validation. Loss: 3.599 , time : 2.199298143386841: 100%|██████████| 475/475 [00:02<00:00, 211.93it/s] \n",
      "Epoch: 28. Train.      Loss: 2.345 , time : 39.216646671295166: 100%|██████████| 1898/1898 [00:39<00:00, 48.35it/s]\n",
      "Epoch: 28. Validation. Loss: 3.599 , time : 2.1335880756378174: 100%|██████████| 475/475 [00:02<00:00, 218.39it/s]\n",
      "Epoch: 29. Train.      Loss: 2.302 , time : 38.581881046295166: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s]\n",
      "Epoch: 29. Validation. Loss: 3.562 , time : 2.146080255508423: 100%|██████████| 475/475 [00:02<00:00, 216.97it/s] \n",
      "Epoch: 30. Train.      Loss: 2.262 , time : 38.8962779045105: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s]  \n",
      "Epoch: 30. Validation. Loss: 3.551 , time : 2.2505991458892822: 100%|██████████| 475/475 [00:02<00:00, 207.24it/s]\n",
      "Epoch: 31. Train.      Loss: 2.219 , time : 39.03808617591858: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s] \n",
      "Epoch: 31. Validation. Loss: 3.538 , time : 2.1698079109191895: 100%|██████████| 475/475 [00:02<00:00, 214.79it/s]\n",
      "Epoch: 32. Train.      Loss: 2.183 , time : 38.954691886901855: 100%|██████████| 1898/1898 [00:38<00:00, 48.67it/s]\n",
      "Epoch: 32. Validation. Loss: 3.549 , time : 2.134813070297241: 100%|██████████| 475/475 [00:02<00:00, 218.22it/s] \n",
      "Epoch: 33. Train.      Loss: 2.141 , time : 38.78176999092102: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 33. Validation. Loss: 3.527 , time : 2.14068341255188: 100%|██████████| 475/475 [00:02<00:00, 217.64it/s]  \n",
      "Epoch: 34. Train.      Loss: 2.106 , time : 38.79334807395935: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 34. Validation. Loss: 3.536 , time : 2.1873080730438232: 100%|██████████| 475/475 [00:02<00:00, 213.10it/s]\n",
      "Epoch: 35. Train.      Loss: 2.070 , time : 39.3442280292511: 100%|██████████| 1898/1898 [00:39<00:00, 48.19it/s]  \n",
      "Epoch: 35. Validation. Loss: 3.532 , time : 2.159193277359009: 100%|██████████| 475/475 [00:02<00:00, 215.45it/s] \n",
      "Epoch: 36. Train.      Loss: 2.034 , time : 38.961445808410645: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]\n",
      "Epoch: 36. Validation. Loss: 3.516 , time : 2.131923198699951: 100%|██████████| 475/475 [00:02<00:00, 218.35it/s] \n",
      "Epoch: 37. Train.      Loss: 2.002 , time : 39.33245229721069: 100%|██████████| 1898/1898 [00:39<00:00, 48.20it/s] \n",
      "Epoch: 37. Validation. Loss: 3.489 , time : 2.1855804920196533: 100%|██████████| 475/475 [00:02<00:00, 213.31it/s]\n",
      "Epoch: 38. Train.      Loss: 1.969 , time : 38.71422553062439: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 38. Validation. Loss: 3.520 , time : 2.152484655380249: 100%|██████████| 475/475 [00:02<00:00, 216.48it/s] \n",
      "Epoch: 39. Train.      Loss: 1.935 , time : 38.866379499435425: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]\n",
      "Epoch: 39. Validation. Loss: 3.470 , time : 2.24127459526062: 100%|██████████| 475/475 [00:02<00:00, 208.06it/s]  \n",
      "Epoch: 40. Train.      Loss: 1.906 , time : 39.07272481918335: 100%|██████████| 1898/1898 [00:39<00:00, 48.52it/s] \n",
      "Epoch: 40. Validation. Loss: 3.528 , time : 2.1594042778015137: 100%|██████████| 475/475 [00:02<00:00, 215.81it/s]\n",
      "Epoch: 41. Train.      Loss: 1.877 , time : 38.939441204071045: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s]\n",
      "Epoch: 41. Validation. Loss: 3.518 , time : 2.2097291946411133: 100%|██████████| 475/475 [00:02<00:00, 210.80it/s]\n",
      "Epoch: 42. Train.      Loss: 1.841 , time : 38.695268630981445: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 42. Validation. Loss: 3.478 , time : 2.2030539512634277: 100%|██████████| 475/475 [00:02<00:00, 211.62it/s]\n",
      "Epoch: 43. Train.      Loss: 1.812 , time : 38.90089249610901: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 43. Validation. Loss: 3.517 , time : 2.215656042098999: 100%|██████████| 475/475 [00:02<00:00, 210.39it/s] \n",
      "Epoch: 44. Train.      Loss: 1.783 , time : 39.456785678863525: 100%|██████████| 1898/1898 [00:39<00:00, 48.05it/s]\n",
      "Epoch: 44. Validation. Loss: 3.489 , time : 2.184390068054199: 100%|██████████| 475/475 [00:02<00:00, 213.37it/s] \n",
      "Epoch: 45. Train.      Loss: 1.753 , time : 39.05049109458923: 100%|██████████| 1898/1898 [00:39<00:00, 48.55it/s] \n",
      "Epoch: 45. Validation. Loss: 3.541 , time : 2.1332848072052: 100%|██████████| 475/475 [00:02<00:00, 217.74it/s]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1343... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.78311</td></tr><tr><td>Min_Val_Loss</td><td>3.47039</td></tr><tr><td>Val_Loss</td><td>3.48942</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">bright-sweep-105</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kxxq2s9b\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/kxxq2s9b</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_090606-kxxq2s9b/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i7mlm3ia with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i7mlm3ia\" target=\"_blank\">honest-sweep-106</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.776 , time : 38.50587248802185: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 0. Validation. Loss: 3.501 , time : 2.1453003883361816: 100%|██████████| 475/475 [00:02<00:00, 217.13it/s]\n",
      "Epoch: 1. Train.      Loss: 1.706 , time : 38.670482873916626: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s]\n",
      "Epoch: 1. Validation. Loss: 3.541 , time : 2.2570536136627197: 100%|██████████| 475/475 [00:02<00:00, 206.50it/s]\n",
      "Epoch: 2. Train.      Loss: 1.669 , time : 38.787680864334106: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]\n",
      "Epoch: 2. Validation. Loss: 3.502 , time : 2.1766393184661865: 100%|██████████| 475/475 [00:02<00:00, 214.09it/s]\n",
      "Epoch: 3. Train.      Loss: 1.651 , time : 38.42431092262268: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 3. Validation. Loss: 3.520 , time : 2.131458044052124: 100%|██████████| 475/475 [00:02<00:00, 218.50it/s] \n",
      "Epoch: 4. Train.      Loss: 1.619 , time : 38.68913722038269: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 4. Validation. Loss: 3.539 , time : 2.1705477237701416: 100%|██████████| 475/475 [00:02<00:00, 214.52it/s]\n",
      "Epoch: 5. Train.      Loss: 1.597 , time : 39.05571627616882: 100%|██████████| 1898/1898 [00:39<00:00, 48.54it/s] \n",
      "Epoch: 5. Validation. Loss: 3.549 , time : 2.178560972213745: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s] \n",
      "Epoch: 6. Train.      Loss: 1.568 , time : 38.682003021240234: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 6. Validation. Loss: 3.603 , time : 2.1858012676239014: 100%|██████████| 475/475 [00:02<00:00, 213.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12462... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▇▁▄▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.59683</td></tr><tr><td>Min_Val_Loss</td><td>3.50073</td></tr><tr><td>Val_Loss</td><td>3.54908</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">honest-sweep-106</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i7mlm3ia\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i7mlm3ia</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_093754-i7mlm3ia/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9ys43vs8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9ys43vs8\" target=\"_blank\">dainty-sweep-107</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.595 , time : 38.73509359359741: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 0. Validation. Loss: 3.526 , time : 2.1676700115203857: 100%|██████████| 475/475 [00:02<00:00, 213.53it/s]\n",
      "Epoch: 1. Train.      Loss: 1.530 , time : 38.8942813873291: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]  \n",
      "Epoch: 1. Validation. Loss: 3.564 , time : 2.1402101516723633: 100%|██████████| 475/475 [00:02<00:00, 217.66it/s]\n",
      "Epoch: 2. Train.      Loss: 1.508 , time : 39.801624059677124: 100%|██████████| 1898/1898 [00:39<00:00, 47.64it/s]\n",
      "Epoch: 2. Validation. Loss: 3.553 , time : 2.2252421379089355: 100%|██████████| 475/475 [00:02<00:00, 209.48it/s]\n",
      "Epoch: 3. Train.      Loss: 1.483 , time : 38.712411403656006: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 3. Validation. Loss: 3.560 , time : 2.1672542095184326: 100%|██████████| 475/475 [00:02<00:00, 214.94it/s]\n",
      "Epoch: 4. Train.      Loss: 1.465 , time : 38.971195220947266: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s]\n",
      "Epoch: 4. Validation. Loss: 3.606 , time : 2.1864891052246094: 100%|██████████| 475/475 [00:02<00:00, 213.10it/s]\n",
      "Epoch: 5. Train.      Loss: 1.441 , time : 38.944562911987305: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s]\n",
      "Epoch: 5. Validation. Loss: 3.564 , time : 2.2020888328552246: 100%|██████████| 475/475 [00:02<00:00, 211.48it/s]\n",
      "Epoch: 6. Train.      Loss: 1.421 , time : 38.93168377876282: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 6. Validation. Loss: 3.569 , time : 2.1290576457977295: 100%|██████████| 475/475 [00:02<00:00, 218.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14206... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▄▃▄█▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.44114</td></tr><tr><td>Min_Val_Loss</td><td>3.52561</td></tr><tr><td>Val_Loss</td><td>3.56386</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dainty-sweep-107</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9ys43vs8\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/9ys43vs8</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_094252-9ys43vs8/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d0lsx2zz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d0lsx2zz\" target=\"_blank\">royal-sweep-108</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.441 , time : 38.75829267501831: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 0. Validation. Loss: 3.582 , time : 2.2154107093811035: 100%|██████████| 475/475 [00:02<00:00, 210.14it/s]\n",
      "Epoch: 1. Train.      Loss: 1.388 , time : 38.88175988197327: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 1. Validation. Loss: 3.563 , time : 2.170208215713501: 100%|██████████| 475/475 [00:02<00:00, 214.68it/s] \n",
      "Epoch: 2. Train.      Loss: 1.373 , time : 38.6463725566864: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s]  \n",
      "Epoch: 2. Validation. Loss: 3.596 , time : 2.161783218383789: 100%|██████████| 475/475 [00:02<00:00, 215.28it/s] \n",
      "Epoch: 3. Train.      Loss: 1.354 , time : 38.851638078689575: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s]\n",
      "Epoch: 3. Validation. Loss: 3.581 , time : 2.1418323516845703: 100%|██████████| 475/475 [00:02<00:00, 217.51it/s]\n",
      "Epoch: 4. Train.      Loss: 1.341 , time : 38.75458812713623: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s] \n",
      "Epoch: 4. Validation. Loss: 3.576 , time : 2.1983187198638916: 100%|██████████| 475/475 [00:02<00:00, 211.96it/s]\n",
      "Epoch: 5. Train.      Loss: 1.319 , time : 38.717103242874146: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 5. Validation. Loss: 3.598 , time : 2.1843597888946533: 100%|██████████| 475/475 [00:02<00:00, 211.38it/s]\n",
      "Epoch: 6. Train.      Loss: 1.302 , time : 38.63222360610962: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 6. Validation. Loss: 3.604 , time : 2.137101411819458: 100%|██████████| 475/475 [00:02<00:00, 217.94it/s] \n",
      "Epoch: 7. Train.      Loss: 1.282 , time : 38.876338720321655: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s]\n",
      "Epoch: 7. Validation. Loss: 3.656 , time : 2.1863765716552734: 100%|██████████| 475/475 [00:02<00:00, 213.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15968... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▄▁▇▄▃▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.3017</td></tr><tr><td>Min_Val_Loss</td><td>3.56298</td></tr><tr><td>Val_Loss</td><td>3.60366</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">royal-sweep-108</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d0lsx2zz\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/d0lsx2zz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_094755-d0lsx2zz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2k6mi0uk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2k6mi0uk\" target=\"_blank\">stilted-sweep-109</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.185 , time : 23.787790298461914: 100%|██████████| 1898/1898 [00:23<00:00, 79.64it/s]\n",
      "Epoch: 0. Validation. Loss: 3.624 , time : 2.12722110748291: 100%|██████████| 475/475 [00:02<00:00, 218.83it/s]  \n",
      "Epoch: 1. Train.      Loss: 1.172 , time : 23.659820318222046: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]\n",
      "Epoch: 1. Validation. Loss: 3.607 , time : 2.116729259490967: 100%|██████████| 475/475 [00:02<00:00, 219.95it/s] \n",
      "Epoch: 2. Train.      Loss: 1.164 , time : 23.737085103988647: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s]\n",
      "Epoch: 2. Validation. Loss: 3.606 , time : 2.099085569381714: 100%|██████████| 475/475 [00:02<00:00, 221.72it/s] \n",
      "Epoch: 3. Train.      Loss: 1.157 , time : 24.05028223991394: 100%|██████████| 1898/1898 [00:24<00:00, 78.78it/s] \n",
      "Epoch: 3. Validation. Loss: 3.599 , time : 2.196200132369995: 100%|██████████| 475/475 [00:02<00:00, 212.07it/s] \n",
      "Epoch: 4. Train.      Loss: 1.152 , time : 23.83547830581665: 100%|██████████| 1898/1898 [00:23<00:00, 79.49it/s] \n",
      "Epoch: 4. Validation. Loss: 3.594 , time : 2.208381414413452: 100%|██████████| 475/475 [00:02<00:00, 210.96it/s] \n",
      "Epoch: 5. Train.      Loss: 1.148 , time : 23.833300828933716: 100%|██████████| 1898/1898 [00:23<00:00, 79.49it/s]\n",
      "Epoch: 5. Validation. Loss: 3.591 , time : 2.1766462326049805: 100%|██████████| 475/475 [00:02<00:00, 214.01it/s]\n",
      "Epoch: 6. Train.      Loss: 1.146 , time : 23.82013487815857: 100%|██████████| 1898/1898 [00:23<00:00, 79.54it/s] \n",
      "Epoch: 6. Validation. Loss: 3.606 , time : 2.197730779647827: 100%|██████████| 475/475 [00:02<00:00, 212.01it/s] \n",
      "Epoch: 7. Train.      Loss: 1.142 , time : 23.585317611694336: 100%|██████████| 1898/1898 [00:23<00:00, 80.33it/s]\n",
      "Epoch: 7. Validation. Loss: 3.592 , time : 2.112551212310791: 100%|██████████| 475/475 [00:02<00:00, 220.25it/s] \n",
      "Epoch: 8. Train.      Loss: 1.141 , time : 23.928573846817017: 100%|██████████| 1898/1898 [00:23<00:00, 79.17it/s]\n",
      "Epoch: 8. Validation. Loss: 3.588 , time : 2.153834819793701: 100%|██████████| 475/475 [00:02<00:00, 216.16it/s] \n",
      "Epoch: 9. Train.      Loss: 1.137 , time : 23.832847833633423: 100%|██████████| 1898/1898 [00:23<00:00, 79.49it/s]\n",
      "Epoch: 9. Validation. Loss: 3.593 , time : 2.13869571685791: 100%|██████████| 475/475 [00:02<00:00, 217.71it/s]  \n",
      "Epoch: 10. Train.      Loss: 1.136 , time : 23.80357265472412: 100%|██████████| 1898/1898 [00:23<00:00, 79.59it/s] \n",
      "Epoch: 10. Validation. Loss: 3.590 , time : 2.1542298793792725: 100%|██████████| 475/475 [00:02<00:00, 216.18it/s]\n",
      "Epoch: 11. Train.      Loss: 1.134 , time : 23.952990531921387: 100%|██████████| 1898/1898 [00:23<00:00, 79.09it/s]\n",
      "Epoch: 11. Validation. Loss: 3.590 , time : 2.1816084384918213: 100%|██████████| 475/475 [00:02<00:00, 212.94it/s]\n",
      "Epoch: 12. Train.      Loss: 1.133 , time : 23.98202395439148: 100%|██████████| 1898/1898 [00:24<00:00, 79.04it/s] \n",
      "Epoch: 12. Validation. Loss: 3.589 , time : 2.1460132598876953: 100%|██████████| 475/475 [00:02<00:00, 216.95it/s]\n",
      "Epoch: 13. Train.      Loss: 1.131 , time : 23.910229682922363: 100%|██████████| 1898/1898 [00:23<00:00, 79.24it/s]\n",
      "Epoch: 13. Validation. Loss: 3.601 , time : 2.2454495429992676: 100%|██████████| 475/475 [00:02<00:00, 207.43it/s]\n",
      "Epoch: 14. Train.      Loss: 1.129 , time : 23.75979208946228: 100%|██████████| 1898/1898 [00:23<00:00, 79.73it/s] \n",
      "Epoch: 14. Validation. Loss: 3.597 , time : 2.1526081562042236: 100%|██████████| 475/475 [00:02<00:00, 216.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17988... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▅▄▃▂▂▅▂▁▂▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.1306</td></tr><tr><td>Min_Val_Loss</td><td>3.58791</td></tr><tr><td>Val_Loss</td><td>3.60068</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stilted-sweep-109</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2k6mi0uk\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2k6mi0uk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_095335-2k6mi0uk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k9hdgkn1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/k9hdgkn1\" target=\"_blank\">genial-sweep-110</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.129 , time : 23.855830907821655: 100%|██████████| 1898/1898 [00:23<00:00, 79.42it/s]\n",
      "Epoch: 0. Validation. Loss: 3.597 , time : 2.1677322387695312: 100%|██████████| 475/475 [00:02<00:00, 214.85it/s]\n",
      "Epoch: 1. Train.      Loss: 1.127 , time : 23.959181547164917: 100%|██████████| 1898/1898 [00:24<00:00, 79.07it/s]\n",
      "Epoch: 1. Validation. Loss: 3.628 , time : 2.162931203842163: 100%|██████████| 475/475 [00:02<00:00, 215.28it/s] \n",
      "Epoch: 2. Train.      Loss: 1.126 , time : 24.023951053619385: 100%|██████████| 1898/1898 [00:24<00:00, 78.86it/s]\n",
      "Epoch: 2. Validation. Loss: 3.592 , time : 2.1675288677215576: 100%|██████████| 475/475 [00:02<00:00, 214.79it/s]\n",
      "Epoch: 3. Train.      Loss: 1.125 , time : 23.6189284324646: 100%|██████████| 1898/1898 [00:23<00:00, 80.21it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.600 , time : 2.151784896850586: 100%|██████████| 475/475 [00:02<00:00, 216.44it/s] \n",
      "Epoch: 4. Train.      Loss: 1.124 , time : 23.85047459602356: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s] \n",
      "Epoch: 4. Validation. Loss: 3.601 , time : 2.1218974590301514: 100%|██████████| 475/475 [00:02<00:00, 219.41it/s]\n",
      "Epoch: 5. Train.      Loss: 1.123 , time : 23.823891639709473: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s]\n",
      "Epoch: 5. Validation. Loss: 3.597 , time : 2.19777512550354: 100%|██████████| 475/475 [00:02<00:00, 211.91it/s]  \n",
      "Epoch: 6. Train.      Loss: 1.122 , time : 23.841254949569702: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s]\n",
      "Epoch: 6. Validation. Loss: 3.610 , time : 2.2182235717773438: 100%|██████████| 475/475 [00:02<00:00, 209.86it/s]\n",
      "Epoch: 7. Train.      Loss: 1.121 , time : 23.83161234855652: 100%|██████████| 1898/1898 [00:23<00:00, 79.50it/s] \n",
      "Epoch: 7. Validation. Loss: 3.601 , time : 2.1652798652648926: 100%|██████████| 475/475 [00:02<00:00, 215.08it/s]\n",
      "Epoch: 8. Train.      Loss: 1.120 , time : 23.720250129699707: 100%|██████████| 1898/1898 [00:23<00:00, 79.87it/s]\n",
      "Epoch: 8. Validation. Loss: 3.610 , time : 2.1802055835723877: 100%|██████████| 475/475 [00:02<00:00, 213.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20533... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂█▁▃▃▂▅▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.12103</td></tr><tr><td>Min_Val_Loss</td><td>3.59182</td></tr><tr><td>Val_Loss</td><td>3.60084</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-110</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/k9hdgkn1\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/k9hdgkn1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_100026-k9hdgkn1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 14sfi8e2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/14sfi8e2\" target=\"_blank\">whole-sweep-111</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.120 , time : 23.741300344467163: 100%|██████████| 1898/1898 [00:23<00:00, 79.80it/s]\n",
      "Epoch: 0. Validation. Loss: 3.602 , time : 2.1426243782043457: 100%|██████████| 475/475 [00:02<00:00, 217.32it/s]\n",
      "Epoch: 1. Train.      Loss: 1.119 , time : 23.807913780212402: 100%|██████████| 1898/1898 [00:23<00:00, 79.57it/s]\n",
      "Epoch: 1. Validation. Loss: 3.603 , time : 2.175067901611328: 100%|██████████| 475/475 [00:02<00:00, 213.96it/s] \n",
      "Epoch: 2. Train.      Loss: 1.119 , time : 23.779273748397827: 100%|██████████| 1898/1898 [00:23<00:00, 79.67it/s]\n",
      "Epoch: 2. Validation. Loss: 3.613 , time : 2.18170428276062: 100%|██████████| 475/475 [00:02<00:00, 213.47it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.120 , time : 23.82772421836853: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s] \n",
      "Epoch: 3. Validation. Loss: 3.604 , time : 2.154928207397461: 100%|██████████| 475/475 [00:02<00:00, 216.10it/s] \n",
      "Epoch: 4. Train.      Loss: 1.117 , time : 23.788813829421997: 100%|██████████| 1898/1898 [00:23<00:00, 79.63it/s]\n",
      "Epoch: 4. Validation. Loss: 3.618 , time : 2.150634288787842: 100%|██████████| 475/475 [00:02<00:00, 216.50it/s] \n",
      "Epoch: 5. Train.      Loss: 1.116 , time : 23.901893377304077: 100%|██████████| 1898/1898 [00:23<00:00, 79.26it/s]\n",
      "Epoch: 5. Validation. Loss: 3.614 , time : 2.1653761863708496: 100%|██████████| 475/475 [00:02<00:00, 215.06it/s]\n",
      "Epoch: 6. Train.      Loss: 1.116 , time : 23.743170738220215: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 6. Validation. Loss: 3.616 , time : 2.166613817214966: 100%|██████████| 475/475 [00:02<00:00, 214.92it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22059... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▇█▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▆▂█▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.11598</td></tr><tr><td>Min_Val_Loss</td><td>3.60212</td></tr><tr><td>Val_Loss</td><td>3.61352</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">whole-sweep-111</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/14sfi8e2\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/14sfi8e2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_100432-14sfi8e2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vrsa00jd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/vrsa00jd\" target=\"_blank\">vibrant-sweep-112</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.115 , time : 23.64026188850403: 100%|██████████| 1898/1898 [00:23<00:00, 80.13it/s] \n",
      "Epoch: 0. Validation. Loss: 3.623 , time : 2.2368834018707275: 100%|██████████| 475/475 [00:02<00:00, 208.30it/s]\n",
      "Epoch: 1. Train.      Loss: 1.115 , time : 23.86288619041443: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s] \n",
      "Epoch: 1. Validation. Loss: 3.615 , time : 2.2016804218292236: 100%|██████████| 475/475 [00:02<00:00, 211.56it/s]\n",
      "Epoch: 2. Train.      Loss: 1.113 , time : 24.07419180870056: 100%|██████████| 1898/1898 [00:24<00:00, 78.69it/s] \n",
      "Epoch: 2. Validation. Loss: 3.625 , time : 2.1188011169433594: 100%|██████████| 475/475 [00:02<00:00, 217.17it/s]\n",
      "Epoch: 3. Train.      Loss: 1.113 , time : 23.956725120544434: 100%|██████████| 1898/1898 [00:24<00:00, 79.08it/s]\n",
      "Epoch: 3. Validation. Loss: 3.616 , time : 2.2233469486236572: 100%|██████████| 475/475 [00:02<00:00, 209.49it/s]\n",
      "Epoch: 4. Train.      Loss: 1.113 , time : 23.842779397964478: 100%|██████████| 1898/1898 [00:23<00:00, 79.46it/s]\n",
      "Epoch: 4. Validation. Loss: 3.621 , time : 2.20123028755188: 100%|██████████| 475/475 [00:02<00:00, 211.53it/s]  \n",
      "Epoch: 5. Train.      Loss: 1.112 , time : 23.794151306152344: 100%|██████████| 1898/1898 [00:23<00:00, 79.61it/s]\n",
      "Epoch: 5. Validation. Loss: 3.614 , time : 2.12446665763855: 100%|██████████| 475/475 [00:02<00:00, 219.02it/s]  \n",
      "Epoch: 6. Train.      Loss: 1.112 , time : 23.73205804824829: 100%|██████████| 1898/1898 [00:23<00:00, 79.83it/s] \n",
      "Epoch: 6. Validation. Loss: 3.624 , time : 2.1597838401794434: 100%|██████████| 475/475 [00:02<00:00, 215.58it/s]\n",
      "Epoch: 7. Train.      Loss: 1.111 , time : 24.008949279785156: 100%|██████████| 1898/1898 [00:24<00:00, 78.91it/s]\n",
      "Epoch: 7. Validation. Loss: 3.623 , time : 2.125809669494629: 100%|██████████| 475/475 [00:02<00:00, 218.95it/s] \n",
      "Epoch: 8. Train.      Loss: 1.110 , time : 23.83996057510376: 100%|██████████| 1898/1898 [00:23<00:00, 79.46it/s] \n",
      "Epoch: 8. Validation. Loss: 3.621 , time : 2.1870925426483154: 100%|██████████| 475/475 [00:02<00:00, 212.92it/s]\n",
      "Epoch: 9. Train.      Loss: 1.110 , time : 23.91015386581421: 100%|██████████| 1898/1898 [00:23<00:00, 79.23it/s] \n",
      "Epoch: 9. Validation. Loss: 3.616 , time : 2.0823068618774414: 100%|██████████| 475/475 [00:02<00:00, 223.41it/s]\n",
      "Epoch: 10. Train.      Loss: 1.109 , time : 23.905858516693115: 100%|██████████| 1898/1898 [00:23<00:00, 79.25it/s]\n",
      "Epoch: 10. Validation. Loss: 3.629 , time : 2.1989805698394775: 100%|██████████| 475/475 [00:02<00:00, 211.62it/s]\n",
      "Epoch: 11. Train.      Loss: 1.109 , time : 23.843440055847168: 100%|██████████| 1898/1898 [00:23<00:00, 79.45it/s]\n",
      "Epoch: 11. Validation. Loss: 3.623 , time : 2.2001521587371826: 100%|██████████| 475/475 [00:02<00:00, 211.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23237... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▆▆▅▄▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▁▆▂▄▁▆▅▄▂█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.10916</td></tr><tr><td>Min_Val_Loss</td><td>3.61439</td></tr><tr><td>Val_Loss</td><td>3.62893</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vibrant-sweep-112</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/vrsa00jd\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/vrsa00jd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_100745-vrsa00jd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v9p6iqhe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v9p6iqhe\" target=\"_blank\">firm-sweep-113</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.086 , time : 38.738195180892944: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s]\n",
      "Epoch: 0. Validation. Loss: 6.059 , time : 2.1603446006774902: 100%|██████████| 475/475 [00:02<00:00, 215.33it/s]\n",
      "Epoch: 1. Train.      Loss: 5.633 , time : 38.42412853240967: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 1. Validation. Loss: 5.789 , time : 2.1655473709106445: 100%|██████████| 475/475 [00:02<00:00, 214.88it/s]\n",
      "Epoch: 2. Train.      Loss: 5.250 , time : 38.56679725646973: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 2. Validation. Loss: 5.463 , time : 2.1977148056030273: 100%|██████████| 475/475 [00:02<00:00, 211.72it/s]\n",
      "Epoch: 3. Train.      Loss: 4.883 , time : 38.50864768028259: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 3. Validation. Loss: 5.159 , time : 2.1875510215759277: 100%|██████████| 475/475 [00:02<00:00, 212.77it/s]\n",
      "Epoch: 4. Train.      Loss: 4.566 , time : 38.83113074302673: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 4. Validation. Loss: 4.890 , time : 2.156597375869751: 100%|██████████| 475/475 [00:02<00:00, 215.62it/s] \n",
      "Epoch: 5. Train.      Loss: 4.304 , time : 38.61382865905762: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 5. Validation. Loss: 4.679 , time : 2.173112630844116: 100%|██████████| 475/475 [00:02<00:00, 214.17it/s] \n",
      "Epoch: 6. Train.      Loss: 4.078 , time : 38.69960927963257: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s] \n",
      "Epoch: 6. Validation. Loss: 4.527 , time : 2.2173759937286377: 100%|██████████| 475/475 [00:02<00:00, 209.93it/s]\n",
      "Epoch: 7. Train.      Loss: 3.886 , time : 38.49700951576233: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 7. Validation. Loss: 4.396 , time : 2.219454050064087: 100%|██████████| 475/475 [00:02<00:00, 209.87it/s] \n",
      "Epoch: 8. Train.      Loss: 3.716 , time : 38.99506855010986: 100%|██████████| 1898/1898 [00:39<00:00, 48.61it/s] \n",
      "Epoch: 8. Validation. Loss: 4.301 , time : 2.145040273666382: 100%|██████████| 475/475 [00:02<00:00, 216.91it/s] \n",
      "Epoch: 9. Train.      Loss: 3.570 , time : 38.76238393783569: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 9. Validation. Loss: 4.195 , time : 2.248236894607544: 100%|██████████| 475/475 [00:02<00:00, 207.09it/s] \n",
      "Epoch: 10. Train.      Loss: 3.437 , time : 38.792540311813354: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s]\n",
      "Epoch: 10. Validation. Loss: 4.109 , time : 2.171339511871338: 100%|██████████| 475/475 [00:02<00:00, 214.28it/s] \n",
      "Epoch: 11. Train.      Loss: 3.315 , time : 39.01600360870361: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 11. Validation. Loss: 4.021 , time : 2.1972670555114746: 100%|██████████| 475/475 [00:02<00:00, 211.94it/s]\n",
      "Epoch: 12. Train.      Loss: 3.209 , time : 38.72751045227051: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 12. Validation. Loss: 4.005 , time : 2.1213274002075195: 100%|██████████| 475/475 [00:02<00:00, 219.18it/s]\n",
      "Epoch: 13. Train.      Loss: 3.111 , time : 38.8165717124939: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]  \n",
      "Epoch: 13. Validation. Loss: 3.915 , time : 2.1937496662139893: 100%|██████████| 475/475 [00:02<00:00, 212.26it/s]\n",
      "Epoch: 14. Train.      Loss: 3.021 , time : 38.84007382392883: 100%|██████████| 1898/1898 [00:38<00:00, 48.81it/s] \n",
      "Epoch: 14. Validation. Loss: 3.894 , time : 2.2523229122161865: 100%|██████████| 475/475 [00:02<00:00, 206.89it/s]\n",
      "Epoch: 15. Train.      Loss: 2.939 , time : 38.59362196922302: 100%|██████████| 1898/1898 [00:38<00:00, 49.12it/s] \n",
      "Epoch: 15. Validation. Loss: 3.817 , time : 2.2059338092803955: 100%|██████████| 475/475 [00:02<00:00, 211.16it/s]\n",
      "Epoch: 16. Train.      Loss: 2.866 , time : 38.89889311790466: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 16. Validation. Loss: 3.803 , time : 2.1649794578552246: 100%|██████████| 475/475 [00:02<00:00, 215.06it/s]\n",
      "Epoch: 17. Train.      Loss: 2.794 , time : 39.49807167053223: 100%|██████████| 1898/1898 [00:39<00:00, 48.00it/s] \n",
      "Epoch: 17. Validation. Loss: 3.763 , time : 2.178673505783081: 100%|██████████| 475/475 [00:02<00:00, 213.73it/s] \n",
      "Epoch: 18. Train.      Loss: 2.729 , time : 38.78070688247681: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s] \n",
      "Epoch: 18. Validation. Loss: 3.733 , time : 2.118074893951416: 100%|██████████| 475/475 [00:02<00:00, 219.65it/s] \n",
      "Epoch: 19. Train.      Loss: 2.667 , time : 38.51876664161682: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 19. Validation. Loss: 3.696 , time : 2.155552625656128: 100%|██████████| 475/475 [00:02<00:00, 215.57it/s] \n",
      "Epoch: 20. Train.      Loss: 2.614 , time : 38.478909969329834: 100%|██████████| 1898/1898 [00:38<00:00, 49.27it/s]\n",
      "Epoch: 20. Validation. Loss: 3.722 , time : 2.130383014678955: 100%|██████████| 475/475 [00:02<00:00, 218.32it/s] \n",
      "Epoch: 21. Train.      Loss: 2.553 , time : 39.35224485397339: 100%|██████████| 1898/1898 [00:39<00:00, 48.18it/s] \n",
      "Epoch: 21. Validation. Loss: 3.678 , time : 2.160179615020752: 100%|██████████| 475/475 [00:02<00:00, 215.47it/s] \n",
      "Epoch: 22. Train.      Loss: 2.508 , time : 38.809513092041016: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s]\n",
      "Epoch: 22. Validation. Loss: 3.628 , time : 2.2113447189331055: 100%|██████████| 475/475 [00:02<00:00, 210.63it/s]\n",
      "Epoch: 23. Train.      Loss: 2.459 , time : 38.90088510513306: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 23. Validation. Loss: 3.640 , time : 2.14697003364563: 100%|██████████| 475/475 [00:02<00:00, 216.75it/s]  \n",
      "Epoch: 24. Train.      Loss: 2.414 , time : 38.71118998527527: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s] \n",
      "Epoch: 24. Validation. Loss: 3.626 , time : 2.1839709281921387: 100%|██████████| 475/475 [00:02<00:00, 213.12it/s]\n",
      "Epoch: 25. Train.      Loss: 2.372 , time : 38.86356520652771: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s] \n",
      "Epoch: 25. Validation. Loss: 3.629 , time : 2.205047607421875: 100%|██████████| 475/475 [00:02<00:00, 211.07it/s] \n",
      "Epoch: 26. Train.      Loss: 2.326 , time : 38.74551486968994: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 26. Validation. Loss: 3.653 , time : 2.1633119583129883: 100%|██████████| 475/475 [00:02<00:00, 212.74it/s]\n",
      "Epoch: 27. Train.      Loss: 2.289 , time : 38.738940954208374: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]\n",
      "Epoch: 27. Validation. Loss: 3.619 , time : 2.175344944000244: 100%|██████████| 475/475 [00:02<00:00, 213.98it/s] \n",
      "Epoch: 28. Train.      Loss: 2.246 , time : 38.830411434173584: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s]\n",
      "Epoch: 28. Validation. Loss: 3.623 , time : 2.213501214981079: 100%|██████████| 475/475 [00:02<00:00, 208.61it/s] \n",
      "Epoch: 29. Train.      Loss: 2.214 , time : 39.57233119010925: 100%|██████████| 1898/1898 [00:39<00:00, 47.91it/s] \n",
      "Epoch: 29. Validation. Loss: 3.576 , time : 2.2260730266571045: 100%|██████████| 475/475 [00:02<00:00, 209.25it/s]\n",
      "Epoch: 30. Train.      Loss: 2.175 , time : 38.659992933273315: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]\n",
      "Epoch: 30. Validation. Loss: 3.578 , time : 2.213452100753784: 100%|██████████| 475/475 [00:02<00:00, 210.40it/s] \n",
      "Epoch: 31. Train.      Loss: 2.140 , time : 38.79001545906067: 100%|██████████| 1898/1898 [00:38<00:00, 48.87it/s] \n",
      "Epoch: 31. Validation. Loss: 3.575 , time : 2.2178966999053955: 100%|██████████| 475/475 [00:02<00:00, 208.78it/s]\n",
      "Epoch: 32. Train.      Loss: 2.104 , time : 38.62672662734985: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 32. Validation. Loss: 3.595 , time : 2.219484329223633: 100%|██████████| 475/475 [00:02<00:00, 209.90it/s] \n",
      "Epoch: 33. Train.      Loss: 2.076 , time : 38.779473543167114: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 33. Validation. Loss: 3.571 , time : 2.190983533859253: 100%|██████████| 475/475 [00:02<00:00, 212.54it/s] \n",
      "Epoch: 34. Train.      Loss: 2.040 , time : 39.94411754608154: 100%|██████████| 1898/1898 [00:39<00:00, 47.46it/s] \n",
      "Epoch: 34. Validation. Loss: 3.585 , time : 2.2399144172668457: 100%|██████████| 475/475 [00:02<00:00, 207.95it/s]\n",
      "Epoch: 35. Train.      Loss: 2.007 , time : 38.92102670669556: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 35. Validation. Loss: 3.610 , time : 2.2160089015960693: 100%|██████████| 475/475 [00:02<00:00, 210.09it/s]\n",
      "Epoch: 36. Train.      Loss: 1.973 , time : 38.68014121055603: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s] \n",
      "Epoch: 36. Validation. Loss: 3.596 , time : 2.2157278060913086: 100%|██████████| 475/475 [00:02<00:00, 210.16it/s]\n",
      "Epoch: 37. Train.      Loss: 1.947 , time : 38.30549693107605: 100%|██████████| 1898/1898 [00:38<00:00, 49.49it/s] \n",
      "Epoch: 37. Validation. Loss: 3.597 , time : 2.1754231452941895: 100%|██████████| 475/475 [00:02<00:00, 214.03it/s]\n",
      "Epoch: 38. Train.      Loss: 1.911 , time : 38.68710684776306: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 38. Validation. Loss: 3.575 , time : 2.251569986343384: 100%|██████████| 475/475 [00:02<00:00, 206.88it/s] \n",
      "Epoch: 39. Train.      Loss: 1.883 , time : 40.22650361061096: 100%|██████████| 1898/1898 [00:40<00:00, 47.13it/s] \n",
      "Epoch: 39. Validation. Loss: 3.599 , time : 2.2131729125976562: 100%|██████████| 475/475 [00:02<00:00, 210.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25272... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.91127</td></tr><tr><td>Min_Val_Loss</td><td>3.57104</td></tr><tr><td>Val_Loss</td><td>3.57516</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">firm-sweep-113</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v9p6iqhe\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/v9p6iqhe</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_101314-v9p6iqhe/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: emm0bv40 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/emm0bv40\" target=\"_blank\">spring-sweep-114</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.911 , time : 38.42625975608826: 100%|██████████| 1898/1898 [00:38<00:00, 49.34it/s] \n",
      "Epoch: 0. Validation. Loss: 3.622 , time : 2.1523280143737793: 100%|██████████| 475/475 [00:02<00:00, 216.27it/s]\n",
      "Epoch: 1. Train.      Loss: 1.831 , time : 38.86475706100464: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s] \n",
      "Epoch: 1. Validation. Loss: 3.642 , time : 2.1719672679901123: 100%|██████████| 475/475 [00:02<00:00, 214.20it/s]\n",
      "Epoch: 2. Train.      Loss: 1.803 , time : 39.31647777557373: 100%|██████████| 1898/1898 [00:39<00:00, 48.22it/s] \n",
      "Epoch: 2. Validation. Loss: 3.642 , time : 2.1927225589752197: 100%|██████████| 475/475 [00:02<00:00, 212.33it/s]\n",
      "Epoch: 3. Train.      Loss: 1.774 , time : 38.890507221221924: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 3. Validation. Loss: 3.600 , time : 2.213430881500244: 100%|██████████| 475/475 [00:02<00:00, 210.11it/s] \n",
      "Epoch: 4. Train.      Loss: 1.748 , time : 38.783355951309204: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]\n",
      "Epoch: 4. Validation. Loss: 3.585 , time : 2.1337404251098633: 100%|██████████| 475/475 [00:02<00:00, 218.12it/s]\n",
      "Epoch: 5. Train.      Loss: 1.723 , time : 39.04796051979065: 100%|██████████| 1898/1898 [00:39<00:00, 48.55it/s] \n",
      "Epoch: 5. Validation. Loss: 3.627 , time : 2.204312562942505: 100%|██████████| 475/475 [00:02<00:00, 211.28it/s] \n",
      "Epoch: 6. Train.      Loss: 1.695 , time : 39.13181400299072: 100%|██████████| 1898/1898 [00:39<00:00, 48.44it/s] \n",
      "Epoch: 6. Validation. Loss: 3.640 , time : 2.1327085494995117: 100%|██████████| 475/475 [00:02<00:00, 217.98it/s]\n",
      "Epoch: 7. Train.      Loss: 1.668 , time : 38.48005771636963: 100%|██████████| 1898/1898 [00:38<00:00, 49.26it/s] \n",
      "Epoch: 7. Validation. Loss: 3.656 , time : 2.206606864929199: 100%|██████████| 475/475 [00:02<00:00, 211.06it/s] \n",
      "Epoch: 8. Train.      Loss: 1.644 , time : 38.85474371910095: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 8. Validation. Loss: 3.631 , time : 2.150550365447998: 100%|██████████| 475/475 [00:02<00:00, 216.44it/s] \n",
      "Epoch: 9. Train.      Loss: 1.623 , time : 38.87630844116211: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s] \n",
      "Epoch: 9. Validation. Loss: 3.648 , time : 2.1310689449310303: 100%|██████████| 475/475 [00:02<00:00, 218.23it/s]\n",
      "Epoch: 10. Train.      Loss: 1.596 , time : 38.81457734107971: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 10. Validation. Loss: 3.666 , time : 2.2101306915283203: 100%|██████████| 475/475 [00:02<00:00, 210.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2573... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▅▇▇▂▁▅▆█▆▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.62268</td></tr><tr><td>Min_Val_Loss</td><td>3.58545</td></tr><tr><td>Val_Loss</td><td>3.64806</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-114</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/emm0bv40\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/emm0bv40</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_104053-emm0bv40/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l01ur0xc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l01ur0xc\" target=\"_blank\">efficient-sweep-115</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.621 , time : 38.86038398742676: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 0. Validation. Loss: 3.656 , time : 2.182062864303589: 100%|██████████| 475/475 [00:02<00:00, 213.45it/s] \n",
      "Epoch: 1. Train.      Loss: 1.561 , time : 38.885525703430176: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 1. Validation. Loss: 3.674 , time : 2.160508632659912: 100%|██████████| 475/475 [00:02<00:00, 215.48it/s] \n",
      "Epoch: 2. Train.      Loss: 1.533 , time : 39.48613429069519: 100%|██████████| 1898/1898 [00:39<00:00, 48.01it/s] \n",
      "Epoch: 2. Validation. Loss: 3.690 , time : 2.2137343883514404: 100%|██████████| 475/475 [00:02<00:00, 210.37it/s]\n",
      "Epoch: 3. Train.      Loss: 1.517 , time : 39.561607122421265: 100%|██████████| 1898/1898 [00:39<00:00, 47.92it/s]\n",
      "Epoch: 3. Validation. Loss: 3.640 , time : 2.149492025375366: 100%|██████████| 475/475 [00:02<00:00, 216.44it/s] \n",
      "Epoch: 4. Train.      Loss: 1.493 , time : 38.50438356399536: 100%|██████████| 1898/1898 [00:38<00:00, 49.24it/s] \n",
      "Epoch: 4. Validation. Loss: 3.653 , time : 2.1710128784179688: 100%|██████████| 475/475 [00:02<00:00, 214.50it/s]\n",
      "Epoch: 5. Train.      Loss: 1.475 , time : 38.91766285896301: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 5. Validation. Loss: 3.660 , time : 2.1879916191101074: 100%|██████████| 475/475 [00:02<00:00, 212.88it/s]\n",
      "Epoch: 6. Train.      Loss: 1.453 , time : 38.99587440490723: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s] \n",
      "Epoch: 6. Validation. Loss: 3.692 , time : 2.175386905670166: 100%|██████████| 475/475 [00:02<00:00, 213.91it/s] \n",
      "Epoch: 7. Train.      Loss: 1.433 , time : 38.96442413330078: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s] \n",
      "Epoch: 7. Validation. Loss: 3.672 , time : 2.20974063873291: 100%|██████████| 475/475 [00:02<00:00, 210.64it/s]  \n",
      "Epoch: 8. Train.      Loss: 1.410 , time : 38.74669361114502: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 8. Validation. Loss: 3.689 , time : 2.1888012886047363: 100%|██████████| 475/475 [00:02<00:00, 212.75it/s]\n",
      "Epoch: 9. Train.      Loss: 1.395 , time : 38.82209920883179: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 9. Validation. Loss: 3.683 , time : 2.193582773208618: 100%|██████████| 475/475 [00:02<00:00, 212.35it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5305... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▅▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>███▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▆█▁▃▄█▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.40954</td></tr><tr><td>Min_Val_Loss</td><td>3.6402</td></tr><tr><td>Val_Loss</td><td>3.68915</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">efficient-sweep-115</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l01ur0xc\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l01ur0xc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_104839-l01ur0xc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hs4mfmpt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/hs4mfmpt\" target=\"_blank\">cerulean-sweep-116</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.415 , time : 38.73787808418274: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s] \n",
      "Epoch: 0. Validation. Loss: 3.722 , time : 2.1494743824005127: 100%|██████████| 475/475 [00:02<00:00, 216.48it/s]\n",
      "Epoch: 1. Train.      Loss: 1.363 , time : 38.49245285987854: 100%|██████████| 1898/1898 [00:38<00:00, 49.25it/s] \n",
      "Epoch: 1. Validation. Loss: 3.712 , time : 2.153553009033203: 100%|██████████| 475/475 [00:02<00:00, 216.20it/s] \n",
      "Epoch: 2. Train.      Loss: 1.350 , time : 38.70483374595642: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s] \n",
      "Epoch: 2. Validation. Loss: 3.718 , time : 2.1079578399658203: 100%|██████████| 475/475 [00:02<00:00, 220.77it/s]\n",
      "Epoch: 3. Train.      Loss: 1.335 , time : 38.72156882286072: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 3. Validation. Loss: 3.708 , time : 2.1772878170013428: 100%|██████████| 475/475 [00:02<00:00, 213.92it/s]\n",
      "Epoch: 4. Train.      Loss: 1.316 , time : 38.64760065078735: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 4. Validation. Loss: 3.709 , time : 2.1317129135131836: 100%|██████████| 475/475 [00:02<00:00, 218.35it/s]\n",
      "Epoch: 5. Train.      Loss: 1.302 , time : 39.237541913986206: 100%|██████████| 1898/1898 [00:39<00:00, 48.32it/s]\n",
      "Epoch: 5. Validation. Loss: 3.711 , time : 2.2027952671051025: 100%|██████████| 475/475 [00:02<00:00, 211.47it/s]\n",
      "Epoch: 6. Train.      Loss: 1.283 , time : 38.62911009788513: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 6. Validation. Loss: 3.720 , time : 2.096479654312134: 100%|██████████| 475/475 [00:02<00:00, 221.83it/s] \n",
      "Epoch: 7. Train.      Loss: 1.271 , time : 38.63542675971985: 100%|██████████| 1898/1898 [00:38<00:00, 49.07it/s] \n",
      "Epoch: 7. Validation. Loss: 3.727 , time : 2.175291061401367: 100%|██████████| 475/475 [00:02<00:00, 213.95it/s] \n",
      "Epoch: 8. Train.      Loss: 1.254 , time : 38.83520197868347: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 8. Validation. Loss: 3.710 , time : 2.134690523147583: 100%|██████████| 475/475 [00:02<00:00, 217.90it/s] \n",
      "Epoch: 9. Train.      Loss: 1.240 , time : 38.61517953872681: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 9. Validation. Loss: 3.704 , time : 2.1145849227905273: 100%|██████████| 475/475 [00:02<00:00, 220.09it/s]\n",
      "Epoch: 10. Train.      Loss: 1.224 , time : 38.708919048309326: 100%|██████████| 1898/1898 [00:38<00:00, 48.98it/s]\n",
      "Epoch: 10. Validation. Loss: 3.764 , time : 2.196916341781616: 100%|██████████| 475/475 [00:02<00:00, 211.97it/s] \n",
      "Epoch: 11. Train.      Loss: 1.212 , time : 38.682928800582886: 100%|██████████| 1898/1898 [00:38<00:00, 49.01it/s]\n",
      "Epoch: 11. Validation. Loss: 3.777 , time : 2.1263744831085205: 100%|██████████| 475/475 [00:02<00:00, 218.93it/s]\n",
      "Epoch: 12. Train.      Loss: 1.193 , time : 38.54017400741577: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 12. Validation. Loss: 3.759 , time : 2.1359357833862305: 100%|██████████| 475/475 [00:02<00:00, 217.97it/s]\n",
      "Epoch: 13. Train.      Loss: 1.184 , time : 38.64829087257385: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 13. Validation. Loss: 3.783 , time : 2.1629855632781982: 100%|██████████| 475/475 [00:02<00:00, 215.10it/s]\n",
      "Epoch: 14. Train.      Loss: 1.167 , time : 38.90747356414795: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 14. Validation. Loss: 3.791 , time : 2.238205671310425: 100%|██████████| 475/475 [00:02<00:00, 208.19it/s] \n",
      "Epoch: 15. Train.      Loss: 1.153 , time : 39.15731596946716: 100%|██████████| 1898/1898 [00:39<00:00, 48.41it/s] \n",
      "Epoch: 15. Validation. Loss: 3.794 , time : 2.209822177886963: 100%|██████████| 475/475 [00:02<00:00, 210.72it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7773... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▆▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▄▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▂▂▂▁▁▁▂▃▁▁▆▇▅▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.16695</td></tr><tr><td>Min_Val_Loss</td><td>3.70448</td></tr><tr><td>Val_Loss</td><td>3.79115</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cerulean-sweep-116</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/hs4mfmpt\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/hs4mfmpt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_105546-hs4mfmpt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i42fjlhn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i42fjlhn\" target=\"_blank\">frosty-sweep-117</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.055 , time : 23.87696385383606: 100%|██████████| 1898/1898 [00:23<00:00, 79.35it/s] \n",
      "Epoch: 0. Validation. Loss: 3.771 , time : 2.1656675338745117: 100%|██████████| 475/475 [00:02<00:00, 214.99it/s]\n",
      "Epoch: 1. Train.      Loss: 1.040 , time : 23.9970486164093: 100%|██████████| 1898/1898 [00:24<00:00, 78.94it/s]  \n",
      "Epoch: 1. Validation. Loss: 3.765 , time : 2.171480178833008: 100%|██████████| 475/475 [00:02<00:00, 214.47it/s] \n",
      "Epoch: 2. Train.      Loss: 1.030 , time : 24.035664319992065: 100%|██████████| 1898/1898 [00:24<00:00, 78.82it/s]\n",
      "Epoch: 2. Validation. Loss: 3.760 , time : 2.2129170894622803: 100%|██████████| 475/475 [00:02<00:00, 210.44it/s]\n",
      "Epoch: 3. Train.      Loss: 1.024 , time : 24.108829259872437: 100%|██████████| 1898/1898 [00:24<00:00, 78.58it/s]\n",
      "Epoch: 3. Validation. Loss: 3.762 , time : 2.194222927093506: 100%|██████████| 475/475 [00:02<00:00, 212.16it/s] \n",
      "Epoch: 4. Train.      Loss: 1.019 , time : 23.873433589935303: 100%|██████████| 1898/1898 [00:23<00:00, 79.35it/s]\n",
      "Epoch: 4. Validation. Loss: 3.766 , time : 2.149470329284668: 100%|██████████| 475/475 [00:02<00:00, 216.58it/s] \n",
      "Epoch: 5. Train.      Loss: 1.016 , time : 23.841612339019775: 100%|██████████| 1898/1898 [00:23<00:00, 79.45it/s]\n",
      "Epoch: 5. Validation. Loss: 3.774 , time : 2.1314005851745605: 100%|██████████| 475/475 [00:02<00:00, 218.46it/s]\n",
      "Epoch: 6. Train.      Loss: 1.014 , time : 23.827493906021118: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s]\n",
      "Epoch: 6. Validation. Loss: 3.768 , time : 2.129265308380127: 100%|██████████| 475/475 [00:02<00:00, 218.61it/s] \n",
      "Epoch: 7. Train.      Loss: 1.010 , time : 23.914687871932983: 100%|██████████| 1898/1898 [00:23<00:00, 79.21it/s]\n",
      "Epoch: 7. Validation. Loss: 3.761 , time : 2.1854805946350098: 100%|██████████| 475/475 [00:02<00:00, 213.01it/s]\n",
      "Epoch: 8. Train.      Loss: 1.007 , time : 23.99278163909912: 100%|██████████| 1898/1898 [00:24<00:00, 78.95it/s] \n",
      "Epoch: 8. Validation. Loss: 3.768 , time : 2.1565327644348145: 100%|██████████| 475/475 [00:02<00:00, 215.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11673... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▃▂▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▄▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▃▁▂▄█▅▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.0098</td></tr><tr><td>Min_Val_Loss</td><td>3.7605</td></tr><tr><td>Val_Loss</td><td>3.76143</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frosty-sweep-117</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i42fjlhn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/i42fjlhn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_110654-i42fjlhn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ce9mv6j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ce9mv6j\" target=\"_blank\">effortless-sweep-118</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.005 , time : 23.882399082183838: 100%|██████████| 1898/1898 [00:23<00:00, 79.33it/s]\n",
      "Epoch: 0. Validation. Loss: 3.768 , time : 2.1857922077178955: 100%|██████████| 475/475 [00:02<00:00, 213.00it/s]\n",
      "Epoch: 1. Train.      Loss: 1.004 , time : 23.75192165374756: 100%|██████████| 1898/1898 [00:23<00:00, 79.76it/s] \n",
      "Epoch: 1. Validation. Loss: 3.770 , time : 2.194920301437378: 100%|██████████| 475/475 [00:02<00:00, 212.19it/s] \n",
      "Epoch: 2. Train.      Loss: 1.002 , time : 24.027281999588013: 100%|██████████| 1898/1898 [00:24<00:00, 78.85it/s]\n",
      "Epoch: 2. Validation. Loss: 3.771 , time : 2.213010311126709: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s] \n",
      "Epoch: 3. Train.      Loss: 1.001 , time : 23.64347815513611: 100%|██████████| 1898/1898 [00:23<00:00, 80.13it/s] \n",
      "Epoch: 3. Validation. Loss: 3.769 , time : 2.203758955001831: 100%|██████████| 475/475 [00:02<00:00, 211.42it/s] \n",
      "Epoch: 4. Train.      Loss: 0.999 , time : 23.600239038467407: 100%|██████████| 1898/1898 [00:23<00:00, 80.27it/s]\n",
      "Epoch: 4. Validation. Loss: 3.767 , time : 2.302523612976074: 100%|██████████| 475/475 [00:02<00:00, 202.35it/s] \n",
      "Epoch: 5. Train.      Loss: 0.998 , time : 24.162071704864502: 100%|██████████| 1898/1898 [00:24<00:00, 78.41it/s]\n",
      "Epoch: 5. Validation. Loss: 3.787 , time : 2.150624990463257: 100%|██████████| 475/475 [00:02<00:00, 216.51it/s] \n",
      "Epoch: 6. Train.      Loss: 0.997 , time : 24.06831979751587: 100%|██████████| 1898/1898 [00:24<00:00, 78.71it/s] \n",
      "Epoch: 6. Validation. Loss: 3.773 , time : 2.2384471893310547: 100%|██████████| 475/475 [00:02<00:00, 207.97it/s]\n",
      "Epoch: 7. Train.      Loss: 0.996 , time : 24.02210021018982: 100%|██████████| 1898/1898 [00:24<00:00, 78.87it/s] \n",
      "Epoch: 7. Validation. Loss: 3.778 , time : 2.2031912803649902: 100%|██████████| 475/475 [00:02<00:00, 211.25it/s]\n",
      "Epoch: 8. Train.      Loss: 0.996 , time : 23.8386971950531: 100%|██████████| 1898/1898 [00:23<00:00, 79.41it/s]  \n",
      "Epoch: 8. Validation. Loss: 3.779 , time : 2.180084705352783: 100%|██████████| 475/475 [00:02<00:00, 213.52it/s] \n",
      "Epoch: 9. Train.      Loss: 0.994 , time : 23.72561502456665: 100%|██████████| 1898/1898 [00:23<00:00, 79.85it/s] \n",
      "Epoch: 9. Validation. Loss: 3.790 , time : 2.1204514503479004: 100%|██████████| 475/475 [00:02<00:00, 217.13it/s]\n",
      "Epoch: 10. Train.      Loss: 0.993 , time : 23.979913234710693: 100%|██████████| 1898/1898 [00:24<00:00, 79.00it/s]\n",
      "Epoch: 10. Validation. Loss: 3.781 , time : 2.110804796218872: 100%|██████████| 475/475 [00:02<00:00, 220.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13843... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▅▄▃▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>████▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▂▂▁▇▃▄▅█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.99393</td></tr><tr><td>Min_Val_Loss</td><td>3.76683</td></tr><tr><td>Val_Loss</td><td>3.78962</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">effortless-sweep-118</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ce9mv6j\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2ce9mv6j</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_111309-2ce9mv6j/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: axhtv4al with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/axhtv4al\" target=\"_blank\">lunar-sweep-119</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 0.992 , time : 23.775795698165894: 100%|██████████| 1898/1898 [00:23<00:00, 79.67it/s]\n",
      "Epoch: 0. Validation. Loss: 3.793 , time : 2.1932456493377686: 100%|██████████| 475/475 [00:02<00:00, 212.21it/s]\n",
      "Epoch: 1. Train.      Loss: 0.991 , time : 24.21400022506714: 100%|██████████| 1898/1898 [00:24<00:00, 78.24it/s] \n",
      "Epoch: 1. Validation. Loss: 3.789 , time : 2.1627352237701416: 100%|██████████| 475/475 [00:02<00:00, 215.12it/s]\n",
      "Epoch: 2. Train.      Loss: 0.991 , time : 23.864069938659668: 100%|██████████| 1898/1898 [00:23<00:00, 79.39it/s]\n",
      "Epoch: 2. Validation. Loss: 3.808 , time : 2.1709513664245605: 100%|██████████| 475/475 [00:02<00:00, 214.54it/s]\n",
      "Epoch: 3. Train.      Loss: 0.990 , time : 23.93620777130127: 100%|██████████| 1898/1898 [00:23<00:00, 79.15it/s] \n",
      "Epoch: 3. Validation. Loss: 3.798 , time : 2.1887404918670654: 100%|██████████| 475/475 [00:02<00:00, 212.82it/s]\n",
      "Epoch: 4. Train.      Loss: 0.990 , time : 23.745665550231934: 100%|██████████| 1898/1898 [00:23<00:00, 79.78it/s]\n",
      "Epoch: 4. Validation. Loss: 3.786 , time : 2.1255316734313965: 100%|██████████| 475/475 [00:02<00:00, 219.00it/s]\n",
      "Epoch: 5. Train.      Loss: 0.989 , time : 23.67567276954651: 100%|██████████| 1898/1898 [00:23<00:00, 80.01it/s] \n",
      "Epoch: 5. Validation. Loss: 3.795 , time : 2.1813580989837646: 100%|██████████| 475/475 [00:02<00:00, 213.40it/s]\n",
      "Epoch: 6. Train.      Loss: 0.988 , time : 23.697579622268677: 100%|██████████| 1898/1898 [00:23<00:00, 79.91it/s]\n",
      "Epoch: 6. Validation. Loss: 3.797 , time : 2.243751287460327: 100%|██████████| 475/475 [00:02<00:00, 207.53it/s] \n",
      "Epoch: 7. Train.      Loss: 0.988 , time : 23.633402109146118: 100%|██████████| 1898/1898 [00:23<00:00, 80.16it/s]\n",
      "Epoch: 7. Validation. Loss: 3.790 , time : 2.139310836791992: 100%|██████████| 475/475 [00:02<00:00, 217.62it/s] \n",
      "Epoch: 8. Train.      Loss: 0.988 , time : 24.110832691192627: 100%|██████████| 1898/1898 [00:24<00:00, 78.57it/s]\n",
      "Epoch: 8. Validation. Loss: 3.801 , time : 2.1926801204681396: 100%|██████████| 475/475 [00:02<00:00, 212.39it/s]\n",
      "Epoch: 9. Train.      Loss: 0.986 , time : 23.913673400878906: 100%|██████████| 1898/1898 [00:23<00:00, 79.22it/s]\n",
      "Epoch: 9. Validation. Loss: 3.795 , time : 2.2158656120300293: 100%|██████████| 475/475 [00:02<00:00, 210.25it/s]\n",
      "Epoch: 10. Train.      Loss: 0.986 , time : 23.881218433380127: 100%|██████████| 1898/1898 [00:23<00:00, 79.33it/s]\n",
      "Epoch: 10. Validation. Loss: 3.801 , time : 2.1864407062530518: 100%|██████████| 475/475 [00:02<00:00, 213.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16332... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▅▅▄▃▃▃▁</td></tr><tr><td>Min_Val_Loss</td><td>█▃▃▃▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▂█▅▁▄▅▂▆▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.98622</td></tr><tr><td>Min_Val_Loss</td><td>3.78639</td></tr><tr><td>Val_Loss</td><td>3.79491</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">lunar-sweep-119</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/axhtv4al\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/axhtv4al</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_112017-axhtv4al/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8pubsvbc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8pubsvbc\" target=\"_blank\">fresh-sweep-120</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 0.985 , time : 23.814134120941162: 100%|██████████| 1898/1898 [00:23<00:00, 79.55it/s]\n",
      "Epoch: 0. Validation. Loss: 3.799 , time : 2.1470947265625: 100%|██████████| 475/475 [00:02<00:00, 216.69it/s]   \n",
      "Epoch: 1. Train.      Loss: 0.985 , time : 23.90115714073181: 100%|██████████| 1898/1898 [00:23<00:00, 79.26it/s] \n",
      "Epoch: 1. Validation. Loss: 3.801 , time : 2.191176414489746: 100%|██████████| 475/475 [00:02<00:00, 212.57it/s] \n",
      "Epoch: 2. Train.      Loss: 0.984 , time : 23.897409915924072: 100%|██████████| 1898/1898 [00:23<00:00, 79.28it/s]\n",
      "Epoch: 2. Validation. Loss: 3.801 , time : 2.1662495136260986: 100%|██████████| 475/475 [00:02<00:00, 214.94it/s]\n",
      "Epoch: 3. Train.      Loss: 0.984 , time : 24.025232553482056: 100%|██████████| 1898/1898 [00:24<00:00, 78.85it/s]\n",
      "Epoch: 3. Validation. Loss: 3.816 , time : 2.1552631855010986: 100%|██████████| 475/475 [00:02<00:00, 216.01it/s]\n",
      "Epoch: 4. Train.      Loss: 0.983 , time : 23.685428619384766: 100%|██████████| 1898/1898 [00:23<00:00, 79.98it/s]\n",
      "Epoch: 4. Validation. Loss: 3.812 , time : 2.175585985183716: 100%|██████████| 475/475 [00:02<00:00, 214.07it/s] \n",
      "Epoch: 5. Train.      Loss: 0.983 , time : 23.921459436416626: 100%|██████████| 1898/1898 [00:23<00:00, 79.19it/s]\n",
      "Epoch: 5. Validation. Loss: 3.818 , time : 2.2141637802124023: 100%|██████████| 475/475 [00:02<00:00, 209.08it/s]\n",
      "Epoch: 6. Train.      Loss: 0.982 , time : 23.800912618637085: 100%|██████████| 1898/1898 [00:23<00:00, 79.60it/s]\n",
      "Epoch: 6. Validation. Loss: 3.807 , time : 2.212888240814209: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18897... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▅▄▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▂▇▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.98252</td></tr><tr><td>Min_Val_Loss</td><td>3.79928</td></tr><tr><td>Val_Loss</td><td>3.81809</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fresh-sweep-120</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8pubsvbc\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/8pubsvbc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_112735-8pubsvbc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4x7uy2i6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4x7uy2i6\" target=\"_blank\">warm-sweep-121</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.077 , time : 38.614463329315186: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s]\n",
      "Epoch: 0. Validation. Loss: 6.051 , time : 2.3096282482147217: 100%|██████████| 475/475 [00:02<00:00, 202.72it/s]\n",
      "Epoch: 1. Train.      Loss: 5.585 , time : 39.153905391693115: 100%|██████████| 1898/1898 [00:39<00:00, 48.42it/s]\n",
      "Epoch: 1. Validation. Loss: 5.746 , time : 2.2688515186309814: 100%|██████████| 475/475 [00:02<00:00, 205.15it/s]\n",
      "Epoch: 2. Train.      Loss: 5.141 , time : 38.54836654663086: 100%|██████████| 1898/1898 [00:38<00:00, 49.16it/s] \n",
      "Epoch: 2. Validation. Loss: 5.351 , time : 2.2351973056793213: 100%|██████████| 475/475 [00:02<00:00, 208.43it/s]\n",
      "Epoch: 3. Train.      Loss: 4.736 , time : 38.45081353187561: 100%|██████████| 1898/1898 [00:38<00:00, 49.30it/s] \n",
      "Epoch: 3. Validation. Loss: 5.008 , time : 2.1680514812469482: 100%|██████████| 475/475 [00:02<00:00, 214.54it/s]\n",
      "Epoch: 4. Train.      Loss: 4.428 , time : 39.296420097351074: 100%|██████████| 1898/1898 [00:39<00:00, 48.24it/s]\n",
      "Epoch: 4. Validation. Loss: 4.771 , time : 2.2355668544769287: 100%|██████████| 475/475 [00:02<00:00, 208.31it/s]\n",
      "Epoch: 5. Train.      Loss: 4.190 , time : 39.945228099823: 100%|██████████| 1898/1898 [00:39<00:00, 47.46it/s]   \n",
      "Epoch: 5. Validation. Loss: 4.613 , time : 2.2354490756988525: 100%|██████████| 475/475 [00:02<00:00, 208.41it/s]\n",
      "Epoch: 6. Train.      Loss: 3.998 , time : 38.98839521408081: 100%|██████████| 1898/1898 [00:39<00:00, 48.62it/s] \n",
      "Epoch: 6. Validation. Loss: 4.476 , time : 2.128843069076538: 100%|██████████| 475/475 [00:02<00:00, 218.65it/s] \n",
      "Epoch: 7. Train.      Loss: 3.836 , time : 38.877074003219604: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s]\n",
      "Epoch: 7. Validation. Loss: 4.349 , time : 2.216195821762085: 100%|██████████| 475/475 [00:02<00:00, 209.29it/s] \n",
      "Epoch: 8. Train.      Loss: 3.692 , time : 38.659180879592896: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s]\n",
      "Epoch: 8. Validation. Loss: 4.256 , time : 2.2373664379119873: 100%|██████████| 475/475 [00:02<00:00, 208.26it/s]\n",
      "Epoch: 9. Train.      Loss: 3.567 , time : 38.93088245391846: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 9. Validation. Loss: 4.164 , time : 2.1304008960723877: 100%|██████████| 475/475 [00:02<00:00, 218.53it/s]\n",
      "Epoch: 10. Train.      Loss: 3.448 , time : 38.817710399627686: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]\n",
      "Epoch: 10. Validation. Loss: 4.106 , time : 2.2187886238098145: 100%|██████████| 475/475 [00:02<00:00, 209.98it/s]\n",
      "Epoch: 11. Train.      Loss: 3.348 , time : 38.65069937705994: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 11. Validation. Loss: 4.027 , time : 2.1658225059509277: 100%|██████████| 475/475 [00:02<00:00, 213.14it/s]\n",
      "Epoch: 12. Train.      Loss: 3.252 , time : 38.83689546585083: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 12. Validation. Loss: 4.000 , time : 2.2545182704925537: 100%|██████████| 475/475 [00:02<00:00, 206.73it/s]\n",
      "Epoch: 13. Train.      Loss: 3.163 , time : 38.85825204849243: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 13. Validation. Loss: 3.970 , time : 2.300189971923828: 100%|██████████| 475/475 [00:02<00:00, 202.67it/s] \n",
      "Epoch: 14. Train.      Loss: 3.080 , time : 38.8533501625061: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s]  \n",
      "Epoch: 14. Validation. Loss: 3.940 , time : 2.214602470397949: 100%|██████████| 475/475 [00:02<00:00, 207.26it/s] \n",
      "Epoch: 15. Train.      Loss: 3.007 , time : 38.85907530784607: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 15. Validation. Loss: 3.871 , time : 2.1415035724639893: 100%|██████████| 475/475 [00:02<00:00, 217.41it/s]\n",
      "Epoch: 16. Train.      Loss: 2.931 , time : 38.85255193710327: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s] \n",
      "Epoch: 16. Validation. Loss: 3.876 , time : 2.1731388568878174: 100%|██████████| 475/475 [00:02<00:00, 213.95it/s]\n",
      "Epoch: 17. Train.      Loss: 2.861 , time : 39.34724307060242: 100%|██████████| 1898/1898 [00:39<00:00, 48.15it/s] \n",
      "Epoch: 17. Validation. Loss: 3.784 , time : 2.2259631156921387: 100%|██████████| 475/475 [00:02<00:00, 209.29it/s]\n",
      "Epoch: 18. Train.      Loss: 2.791 , time : 38.751914262771606: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s]\n",
      "Epoch: 18. Validation. Loss: 3.791 , time : 2.244441270828247: 100%|██████████| 475/475 [00:02<00:00, 207.61it/s] \n",
      "Epoch: 19. Train.      Loss: 2.731 , time : 39.03326773643494: 100%|██████████| 1898/1898 [00:39<00:00, 48.57it/s] \n",
      "Epoch: 19. Validation. Loss: 3.739 , time : 2.126798629760742: 100%|██████████| 475/475 [00:02<00:00, 218.87it/s] \n",
      "Epoch: 20. Train.      Loss: 2.668 , time : 38.67183971405029: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 20. Validation. Loss: 3.723 , time : 2.2180392742156982: 100%|██████████| 475/475 [00:02<00:00, 210.04it/s]\n",
      "Epoch: 21. Train.      Loss: 2.612 , time : 38.571040868759155: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 21. Validation. Loss: 3.682 , time : 2.200596570968628: 100%|██████████| 475/475 [00:02<00:00, 211.69it/s] \n",
      "Epoch: 22. Train.      Loss: 2.558 , time : 38.775009870529175: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 22. Validation. Loss: 3.663 , time : 2.1971542835235596: 100%|██████████| 475/475 [00:02<00:00, 212.02it/s]\n",
      "Epoch: 23. Train.      Loss: 2.501 , time : 38.8154673576355: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s]  \n",
      "Epoch: 23. Validation. Loss: 3.677 , time : 2.187108039855957: 100%|██████████| 475/475 [00:02<00:00, 212.81it/s] \n",
      "Epoch: 24. Train.      Loss: 2.449 , time : 38.59038424491882: 100%|██████████| 1898/1898 [00:38<00:00, 49.13it/s] \n",
      "Epoch: 24. Validation. Loss: 3.687 , time : 2.2081804275512695: 100%|██████████| 475/475 [00:02<00:00, 210.95it/s]\n",
      "Epoch: 25. Train.      Loss: 2.397 , time : 38.54396390914917: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 25. Validation. Loss: 3.629 , time : 2.207343339920044: 100%|██████████| 475/475 [00:02<00:00, 211.02it/s] \n",
      "Epoch: 26. Train.      Loss: 2.347 , time : 38.598552227020264: 100%|██████████| 1898/1898 [00:38<00:00, 49.11it/s]\n",
      "Epoch: 26. Validation. Loss: 3.624 , time : 2.186182975769043: 100%|██████████| 475/475 [00:02<00:00, 212.97it/s] \n",
      "Epoch: 27. Train.      Loss: 2.298 , time : 38.777671337127686: 100%|██████████| 1898/1898 [00:38<00:00, 48.89it/s]\n",
      "Epoch: 27. Validation. Loss: 3.633 , time : 2.107210397720337: 100%|██████████| 475/475 [00:02<00:00, 219.90it/s] \n",
      "Epoch: 28. Train.      Loss: 2.257 , time : 38.756144523620605: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s]\n",
      "Epoch: 28. Validation. Loss: 3.596 , time : 2.154637336730957: 100%|██████████| 475/475 [00:02<00:00, 216.09it/s] \n",
      "Epoch: 29. Train.      Loss: 2.208 , time : 38.52526307106018: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s] \n",
      "Epoch: 29. Validation. Loss: 3.610 , time : 2.113121509552002: 100%|██████████| 475/475 [00:02<00:00, 220.23it/s] \n",
      "Epoch: 30. Train.      Loss: 2.169 , time : 38.84340953826904: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 30. Validation. Loss: 3.599 , time : 2.1650242805480957: 100%|██████████| 475/475 [00:02<00:00, 215.01it/s]\n",
      "Epoch: 31. Train.      Loss: 2.128 , time : 38.65702247619629: 100%|██████████| 1898/1898 [00:38<00:00, 49.04it/s] \n",
      "Epoch: 31. Validation. Loss: 3.600 , time : 2.13741135597229: 100%|██████████| 475/475 [00:02<00:00, 217.82it/s]  \n",
      "Epoch: 32. Train.      Loss: 2.083 , time : 38.81354355812073: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 32. Validation. Loss: 3.604 , time : 2.174166679382324: 100%|██████████| 475/475 [00:02<00:00, 214.19it/s] \n",
      "Epoch: 33. Train.      Loss: 2.048 , time : 39.07237458229065: 100%|██████████| 1898/1898 [00:39<00:00, 48.52it/s] \n",
      "Epoch: 33. Validation. Loss: 3.596 , time : 2.2398061752319336: 100%|██████████| 475/475 [00:02<00:00, 208.04it/s]\n",
      "Epoch: 34. Train.      Loss: 2.013 , time : 38.96687602996826: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s] \n",
      "Epoch: 34. Validation. Loss: 3.587 , time : 2.193498373031616: 100%|██████████| 475/475 [00:02<00:00, 212.30it/s] \n",
      "Epoch: 35. Train.      Loss: 1.975 , time : 38.928494453430176: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s]\n",
      "Epoch: 35. Validation. Loss: 3.589 , time : 2.221956253051758: 100%|██████████| 475/475 [00:02<00:00, 209.62it/s] \n",
      "Epoch: 36. Train.      Loss: 1.939 , time : 38.67313003540039: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 36. Validation. Loss: 3.598 , time : 2.1839616298675537: 100%|██████████| 475/475 [00:02<00:00, 213.26it/s]\n",
      "Epoch: 37. Train.      Loss: 1.902 , time : 38.57427954673767: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s] \n",
      "Epoch: 37. Validation. Loss: 3.583 , time : 2.1807284355163574: 100%|██████████| 475/475 [00:02<00:00, 213.54it/s]\n",
      "Epoch: 38. Train.      Loss: 1.872 , time : 38.91293668746948: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 38. Validation. Loss: 3.592 , time : 2.1410021781921387: 100%|██████████| 475/475 [00:02<00:00, 216.58it/s]\n",
      "Epoch: 39. Train.      Loss: 1.837 , time : 38.739458084106445: 100%|██████████| 1898/1898 [00:38<00:00, 48.94it/s]\n",
      "Epoch: 39. Validation. Loss: 3.601 , time : 2.160358428955078: 100%|██████████| 475/475 [00:02<00:00, 215.44it/s] \n",
      "Epoch: 40. Train.      Loss: 1.807 , time : 38.55892205238342: 100%|██████████| 1898/1898 [00:38<00:00, 49.14it/s] \n",
      "Epoch: 40. Validation. Loss: 3.590 , time : 2.1887569427490234: 100%|██████████| 475/475 [00:02<00:00, 212.81it/s]\n",
      "Epoch: 41. Train.      Loss: 1.775 , time : 38.85736155509949: 100%|██████████| 1898/1898 [00:38<00:00, 48.79it/s] \n",
      "Epoch: 41. Validation. Loss: 3.582 , time : 2.1684319972991943: 100%|██████████| 475/475 [00:02<00:00, 214.77it/s]\n",
      "Epoch: 42. Train.      Loss: 1.745 , time : 38.52565240859985: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s] \n",
      "Epoch: 42. Validation. Loss: 3.667 , time : 2.145465612411499: 100%|██████████| 475/475 [00:02<00:00, 217.03it/s] \n",
      "Epoch: 43. Train.      Loss: 1.718 , time : 38.73324799537659: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 43. Validation. Loss: 3.624 , time : 2.195146322250366: 100%|██████████| 475/475 [00:02<00:00, 212.14it/s] \n",
      "Epoch: 44. Train.      Loss: 1.689 , time : 38.99650311470032: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 44. Validation. Loss: 3.595 , time : 2.205449104309082: 100%|██████████| 475/475 [00:02<00:00, 211.15it/s] \n",
      "Epoch: 45. Train.      Loss: 1.658 , time : 38.80336785316467: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 45. Validation. Loss: 3.648 , time : 2.258331537246704: 100%|██████████| 475/475 [00:02<00:00, 206.27it/s] \n",
      "Epoch: 46. Train.      Loss: 1.628 , time : 38.5545871257782: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s]  \n",
      "Epoch: 46. Validation. Loss: 3.648 , time : 2.189314365386963: 100%|██████████| 475/475 [00:02<00:00, 212.71it/s] \n",
      "Epoch: 47. Train.      Loss: 1.606 , time : 38.96624040603638: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s] \n",
      "Epoch: 47. Validation. Loss: 3.629 , time : 2.2125303745269775: 100%|██████████| 475/475 [00:02<00:00, 210.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20809... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.6276</td></tr><tr><td>Min_Val_Loss</td><td>3.58231</td></tr><tr><td>Val_Loss</td><td>3.64768</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">warm-sweep-121</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4x7uy2i6\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/4x7uy2i6</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_113258-4x7uy2i6/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qovwendj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qovwendj\" target=\"_blank\">silver-sweep-122</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.621 , time : 38.699342012405396: 100%|██████████| 1898/1898 [00:38<00:00, 48.99it/s]\n",
      "Epoch: 0. Validation. Loss: 3.687 , time : 2.152235746383667: 100%|██████████| 475/475 [00:02<00:00, 216.35it/s] \n",
      "Epoch: 1. Train.      Loss: 1.556 , time : 38.682915687561035: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s]\n",
      "Epoch: 1. Validation. Loss: 3.703 , time : 2.1489102840423584: 100%|██████████| 475/475 [00:02<00:00, 216.03it/s]\n",
      "Epoch: 2. Train.      Loss: 1.527 , time : 39.00492453575134: 100%|██████████| 1898/1898 [00:39<00:00, 48.60it/s] \n",
      "Epoch: 2. Validation. Loss: 3.695 , time : 2.18690824508667: 100%|██████████| 475/475 [00:02<00:00, 212.99it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.503 , time : 39.20288348197937: 100%|██████████| 1898/1898 [00:39<00:00, 48.36it/s] \n",
      "Epoch: 3. Validation. Loss: 3.694 , time : 2.2362749576568604: 100%|██████████| 475/475 [00:02<00:00, 208.36it/s]\n",
      "Epoch: 4. Train.      Loss: 1.480 , time : 38.786858558654785: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]\n",
      "Epoch: 4. Validation. Loss: 3.754 , time : 2.2048463821411133: 100%|██████████| 475/475 [00:02<00:00, 211.30it/s]\n",
      "Epoch: 5. Train.      Loss: 1.456 , time : 38.832600831985474: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s]\n",
      "Epoch: 5. Validation. Loss: 3.725 , time : 2.180190086364746: 100%|██████████| 475/475 [00:02<00:00, 213.65it/s] \n",
      "Epoch: 6. Train.      Loss: 1.432 , time : 38.67703700065613: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 6. Validation. Loss: 3.774 , time : 2.2424252033233643: 100%|██████████| 475/475 [00:02<00:00, 207.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2219... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▂▂█▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.45642</td></tr><tr><td>Min_Val_Loss</td><td>3.68735</td></tr><tr><td>Val_Loss</td><td>3.72502</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">silver-sweep-122</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qovwendj\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/qovwendj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_120813-qovwendj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: chmdxtyl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/chmdxtyl\" target=\"_blank\">balmy-sweep-123</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.454 , time : 38.568957567214966: 100%|██████████| 1898/1898 [00:38<00:00, 49.15it/s]\n",
      "Epoch: 0. Validation. Loss: 3.730 , time : 2.3092904090881348: 100%|██████████| 475/475 [00:02<00:00, 201.12it/s]\n",
      "Epoch: 1. Train.      Loss: 1.394 , time : 38.529794454574585: 100%|██████████| 1898/1898 [00:38<00:00, 49.20it/s]\n",
      "Epoch: 1. Validation. Loss: 3.764 , time : 2.1269383430480957: 100%|██████████| 475/475 [00:02<00:00, 217.71it/s]\n",
      "Epoch: 2. Train.      Loss: 1.371 , time : 38.607426404953: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s]   \n",
      "Epoch: 2. Validation. Loss: 3.743 , time : 2.17824125289917: 100%|██████████| 475/475 [00:02<00:00, 213.74it/s]  \n",
      "Epoch: 3. Train.      Loss: 1.352 , time : 38.92969059944153: 100%|██████████| 1898/1898 [00:38<00:00, 48.70it/s] \n",
      "Epoch: 3. Validation. Loss: 3.750 , time : 2.203054666519165: 100%|██████████| 475/475 [00:02<00:00, 211.38it/s] \n",
      "Epoch: 4. Train.      Loss: 1.332 , time : 38.65257668495178: 100%|██████████| 1898/1898 [00:38<00:00, 49.05it/s] \n",
      "Epoch: 4. Validation. Loss: 3.788 , time : 2.1076934337615967: 100%|██████████| 475/475 [00:02<00:00, 220.64it/s]\n",
      "Epoch: 5. Train.      Loss: 1.309 , time : 39.007328271865845: 100%|██████████| 1898/1898 [00:39<00:00, 48.60it/s]\n",
      "Epoch: 5. Validation. Loss: 3.769 , time : 2.162508964538574: 100%|██████████| 475/475 [00:02<00:00, 215.31it/s] \n",
      "Epoch: 6. Train.      Loss: 1.292 , time : 39.08367872238159: 100%|██████████| 1898/1898 [00:39<00:00, 48.51it/s] \n",
      "Epoch: 6. Validation. Loss: 3.811 , time : 2.161583423614502: 100%|██████████| 475/475 [00:02<00:00, 215.42it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4721... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▅▃▃█▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.30945</td></tr><tr><td>Min_Val_Loss</td><td>3.72954</td></tr><tr><td>Val_Loss</td><td>3.76901</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">balmy-sweep-123</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/chmdxtyl\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/chmdxtyl</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_121530-chmdxtyl/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 22jfjygh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/22jfjygh\" target=\"_blank\">stoic-sweep-124</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.314 , time : 38.72245979309082: 100%|██████████| 1898/1898 [00:38<00:00, 48.96it/s] \n",
      "Epoch: 0. Validation. Loss: 3.775 , time : 2.1371114253997803: 100%|██████████| 475/475 [00:02<00:00, 217.88it/s]\n",
      "Epoch: 1. Train.      Loss: 1.263 , time : 38.60892868041992: 100%|██████████| 1898/1898 [00:38<00:00, 49.10it/s] \n",
      "Epoch: 1. Validation. Loss: 3.770 , time : 2.1607232093811035: 100%|██████████| 475/475 [00:02<00:00, 215.52it/s]\n",
      "Epoch: 2. Train.      Loss: 1.247 , time : 38.616129636764526: 100%|██████████| 1898/1898 [00:38<00:00, 49.09it/s]\n",
      "Epoch: 2. Validation. Loss: 3.788 , time : 2.1695754528045654: 100%|██████████| 475/475 [00:02<00:00, 214.53it/s]\n",
      "Epoch: 3. Train.      Loss: 1.233 , time : 39.30582284927368: 100%|██████████| 1898/1898 [00:39<00:00, 48.23it/s] \n",
      "Epoch: 3. Validation. Loss: 3.772 , time : 2.2315444946289062: 100%|██████████| 475/475 [00:02<00:00, 208.63it/s]\n",
      "Epoch: 4. Train.      Loss: 1.215 , time : 38.785720109939575: 100%|██████████| 1898/1898 [00:38<00:00, 48.88it/s]\n",
      "Epoch: 4. Validation. Loss: 3.854 , time : 2.1937177181243896: 100%|██████████| 475/475 [00:02<00:00, 212.30it/s]\n",
      "Epoch: 5. Train.      Loss: 1.196 , time : 39.318400859832764: 100%|██████████| 1898/1898 [00:39<00:00, 48.22it/s]\n",
      "Epoch: 5. Validation. Loss: 3.814 , time : 2.2189972400665283: 100%|██████████| 475/475 [00:02<00:00, 209.92it/s]\n",
      "Epoch: 6. Train.      Loss: 1.183 , time : 38.90832543373108: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 6. Validation. Loss: 3.828 , time : 2.1901581287384033: 100%|██████████| 475/475 [00:02<00:00, 212.66it/s]\n",
      "Epoch: 7. Train.      Loss: 1.164 , time : 39.306427001953125: 100%|██████████| 1898/1898 [00:39<00:00, 48.23it/s]\n",
      "Epoch: 7. Validation. Loss: 3.861 , time : 2.1249194145202637: 100%|██████████| 475/475 [00:02<00:00, 219.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7796... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▃▁█▅▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.18284</td></tr><tr><td>Min_Val_Loss</td><td>3.76967</td></tr><tr><td>Val_Loss</td><td>3.82832</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stoic-sweep-124</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/22jfjygh\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/22jfjygh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_122248-22jfjygh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2y9lxt1w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2y9lxt1w\" target=\"_blank\">playful-sweep-125</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.071 , time : 23.849931001663208: 100%|██████████| 1898/1898 [00:23<00:00, 79.43it/s]\n",
      "Epoch: 0. Validation. Loss: 3.827 , time : 2.2249765396118164: 100%|██████████| 475/475 [00:02<00:00, 209.25it/s]\n",
      "Epoch: 1. Train.      Loss: 1.054 , time : 23.661766529083252: 100%|██████████| 1898/1898 [00:23<00:00, 80.06it/s]\n",
      "Epoch: 1. Validation. Loss: 3.805 , time : 2.1992993354797363: 100%|██████████| 475/475 [00:02<00:00, 211.69it/s]\n",
      "Epoch: 2. Train.      Loss: 1.046 , time : 24.00240969657898: 100%|██████████| 1898/1898 [00:24<00:00, 78.93it/s] \n",
      "Epoch: 2. Validation. Loss: 3.818 , time : 2.2195773124694824: 100%|██████████| 475/475 [00:02<00:00, 209.94it/s]\n",
      "Epoch: 3. Train.      Loss: 1.040 , time : 24.063233852386475: 100%|██████████| 1898/1898 [00:24<00:00, 78.73it/s]\n",
      "Epoch: 3. Validation. Loss: 3.798 , time : 2.146252155303955: 100%|██████████| 475/475 [00:02<00:00, 216.83it/s] \n",
      "Epoch: 4. Train.      Loss: 1.035 , time : 23.78238868713379: 100%|██████████| 1898/1898 [00:23<00:00, 79.66it/s] \n",
      "Epoch: 4. Validation. Loss: 3.796 , time : 2.1699917316436768: 100%|██████████| 475/475 [00:02<00:00, 214.44it/s]\n",
      "Epoch: 5. Train.      Loss: 1.032 , time : 23.895695447921753: 100%|██████████| 1898/1898 [00:23<00:00, 79.28it/s]\n",
      "Epoch: 5. Validation. Loss: 3.793 , time : 2.233283758163452: 100%|██████████| 475/475 [00:02<00:00, 208.49it/s] \n",
      "Epoch: 6. Train.      Loss: 1.027 , time : 24.109323024749756: 100%|██████████| 1898/1898 [00:24<00:00, 78.58it/s]\n",
      "Epoch: 6. Validation. Loss: 3.809 , time : 2.163400650024414: 100%|██████████| 475/475 [00:02<00:00, 215.19it/s] \n",
      "Epoch: 7. Train.      Loss: 1.024 , time : 23.88810968399048: 100%|██████████| 1898/1898 [00:23<00:00, 79.31it/s] \n",
      "Epoch: 7. Validation. Loss: 3.799 , time : 2.187804698944092: 100%|██████████| 475/475 [00:02<00:00, 212.67it/s] \n",
      "Epoch: 8. Train.      Loss: 1.022 , time : 24.08815836906433: 100%|██████████| 1898/1898 [00:24<00:00, 78.65it/s] \n",
      "Epoch: 8. Validation. Loss: 3.797 , time : 2.1796743869781494: 100%|██████████| 475/475 [00:02<00:00, 213.64it/s]\n",
      "Epoch: 9. Train.      Loss: 1.019 , time : 23.743709564208984: 100%|██████████| 1898/1898 [00:23<00:00, 79.79it/s]\n",
      "Epoch: 9. Validation. Loss: 3.796 , time : 2.108640193939209: 100%|██████████| 475/475 [00:02<00:00, 220.60it/s] \n",
      "Epoch: 10. Train.      Loss: 1.018 , time : 24.32087278366089: 100%|██████████| 1898/1898 [00:24<00:00, 77.90it/s] \n",
      "Epoch: 10. Validation. Loss: 3.801 , time : 2.1949474811553955: 100%|██████████| 475/475 [00:02<00:00, 212.21it/s]\n",
      "Epoch: 11. Train.      Loss: 1.016 , time : 24.114171743392944: 100%|██████████| 1898/1898 [00:24<00:00, 78.57it/s]\n",
      "Epoch: 11. Validation. Loss: 3.795 , time : 2.1730737686157227: 100%|██████████| 475/475 [00:02<00:00, 214.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11189... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▃▃▂▂▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▃▆▂▂▁▄▂▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.01786</td></tr><tr><td>Min_Val_Loss</td><td>3.7935</td></tr><tr><td>Val_Loss</td><td>3.80105</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-125</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2y9lxt1w\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/2y9lxt1w</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_123039-2y9lxt1w/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l3cqmo05 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l3cqmo05\" target=\"_blank\">young-sweep-126</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.014 , time : 23.9616916179657: 100%|██████████| 1898/1898 [00:24<00:00, 79.06it/s]  \n",
      "Epoch: 0. Validation. Loss: 3.805 , time : 2.154381036758423: 100%|██████████| 475/475 [00:02<00:00, 216.15it/s] \n",
      "Epoch: 1. Train.      Loss: 1.013 , time : 23.7851140499115: 100%|██████████| 1898/1898 [00:23<00:00, 79.56it/s]  \n",
      "Epoch: 1. Validation. Loss: 3.807 , time : 2.1402993202209473: 100%|██████████| 475/475 [00:02<00:00, 217.39it/s]\n",
      "Epoch: 2. Train.      Loss: 1.012 , time : 23.88542342185974: 100%|██████████| 1898/1898 [00:23<00:00, 79.31it/s] \n",
      "Epoch: 2. Validation. Loss: 3.804 , time : 2.2369227409362793: 100%|██████████| 475/475 [00:02<00:00, 208.26it/s]\n",
      "Epoch: 3. Train.      Loss: 1.010 , time : 23.871105194091797: 100%|██████████| 1898/1898 [00:23<00:00, 79.34it/s]\n",
      "Epoch: 3. Validation. Loss: 3.801 , time : 2.162355422973633: 100%|██████████| 475/475 [00:02<00:00, 215.13it/s] \n",
      "Epoch: 4. Train.      Loss: 1.010 , time : 23.667260885238647: 100%|██████████| 1898/1898 [00:23<00:00, 80.05it/s]\n",
      "Epoch: 4. Validation. Loss: 3.801 , time : 2.2219221591949463: 100%|██████████| 475/475 [00:02<00:00, 209.65it/s]\n",
      "Epoch: 5. Train.      Loss: 1.008 , time : 23.839066982269287: 100%|██████████| 1898/1898 [00:23<00:00, 79.47it/s]\n",
      "Epoch: 5. Validation. Loss: 3.817 , time : 2.171238422393799: 100%|██████████| 475/475 [00:02<00:00, 214.49it/s] \n",
      "Epoch: 6. Train.      Loss: 1.007 , time : 23.908440828323364: 100%|██████████| 1898/1898 [00:23<00:00, 79.24it/s]\n",
      "Epoch: 6. Validation. Loss: 3.805 , time : 2.125741958618164: 100%|██████████| 475/475 [00:02<00:00, 219.02it/s] \n",
      "Epoch: 7. Train.      Loss: 1.006 , time : 23.709211587905884: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s]\n",
      "Epoch: 7. Validation. Loss: 3.811 , time : 2.1618669033050537: 100%|██████████| 475/475 [00:02<00:00, 215.26it/s]\n",
      "Epoch: 8. Train.      Loss: 1.006 , time : 23.986015796661377: 100%|██████████| 1898/1898 [00:24<00:00, 78.98it/s]\n",
      "Epoch: 8. Validation. Loss: 3.807 , time : 2.1619534492492676: 100%|██████████| 475/475 [00:02<00:00, 215.40it/s]\n",
      "Epoch: 9. Train.      Loss: 1.005 , time : 24.12611413002014: 100%|██████████| 1898/1898 [00:24<00:00, 78.53it/s] \n",
      "Epoch: 9. Validation. Loss: 3.815 , time : 2.237011432647705: 100%|██████████| 475/475 [00:02<00:00, 208.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14539... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▅▅▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>██▆▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▄▂▁▁█▃▆▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.00551</td></tr><tr><td>Min_Val_Loss</td><td>3.80069</td></tr><tr><td>Val_Loss</td><td>3.80677</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">young-sweep-126</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l3cqmo05\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/l3cqmo05</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_123817-l3cqmo05/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 72tx49s5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/72tx49s5\" target=\"_blank\">devout-sweep-127</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.004 , time : 23.68872570991516: 100%|██████████| 1898/1898 [00:23<00:00, 79.97it/s] \n",
      "Epoch: 0. Validation. Loss: 3.813 , time : 2.133129119873047: 100%|██████████| 475/475 [00:02<00:00, 217.77it/s] \n",
      "Epoch: 1. Train.      Loss: 1.004 , time : 23.748732805252075: 100%|██████████| 1898/1898 [00:23<00:00, 79.77it/s]\n",
      "Epoch: 1. Validation. Loss: 3.813 , time : 2.1911425590515137: 100%|██████████| 475/475 [00:02<00:00, 212.55it/s]\n",
      "Epoch: 2. Train.      Loss: 1.004 , time : 23.83631920814514: 100%|██████████| 1898/1898 [00:23<00:00, 79.48it/s] \n",
      "Epoch: 2. Validation. Loss: 3.820 , time : 2.183129072189331: 100%|██████████| 475/475 [00:02<00:00, 213.33it/s] \n",
      "Epoch: 3. Train.      Loss: 1.002 , time : 23.726802349090576: 100%|██████████| 1898/1898 [00:23<00:00, 79.84it/s]\n",
      "Epoch: 3. Validation. Loss: 3.816 , time : 2.1661038398742676: 100%|██████████| 475/475 [00:02<00:00, 214.99it/s]\n",
      "Epoch: 4. Train.      Loss: 1.001 , time : 23.6606228351593: 100%|██████████| 1898/1898 [00:23<00:00, 80.07it/s]  \n",
      "Epoch: 4. Validation. Loss: 3.823 , time : 2.1520023345947266: 100%|██████████| 475/475 [00:02<00:00, 215.41it/s]\n",
      "Epoch: 5. Train.      Loss: 1.001 , time : 23.887911558151245: 100%|██████████| 1898/1898 [00:23<00:00, 79.31it/s]\n",
      "Epoch: 5. Validation. Loss: 3.818 , time : 2.247417688369751: 100%|██████████| 475/475 [00:02<00:00, 207.24it/s] \n",
      "Epoch: 6. Train.      Loss: 1.000 , time : 24.260480403900146: 100%|██████████| 1898/1898 [00:24<00:00, 78.02it/s]\n",
      "Epoch: 6. Validation. Loss: 3.815 , time : 2.140967845916748: 100%|██████████| 475/475 [00:02<00:00, 217.39it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16950... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>██▇▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁▆▃█▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.00085</td></tr><tr><td>Min_Val_Loss</td><td>3.81282</td></tr><tr><td>Val_Loss</td><td>3.81752</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">devout-sweep-127</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/72tx49s5\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/72tx49s5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_124459-72tx49s5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b57yc4cs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/b57yc4cs\" target=\"_blank\">hardy-sweep-128</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 0.999 , time : 23.970598220825195: 100%|██████████| 1898/1898 [00:24<00:00, 79.03it/s]\n",
      "Epoch: 0. Validation. Loss: 3.819 , time : 2.1763477325439453: 100%|██████████| 475/475 [00:02<00:00, 214.01it/s]\n",
      "Epoch: 1. Train.      Loss: 0.998 , time : 23.899115085601807: 100%|██████████| 1898/1898 [00:23<00:00, 79.27it/s]\n",
      "Epoch: 1. Validation. Loss: 3.820 , time : 2.222996950149536: 100%|██████████| 475/475 [00:02<00:00, 209.50it/s] \n",
      "Epoch: 2. Train.      Loss: 0.998 , time : 23.86545157432556: 100%|██████████| 1898/1898 [00:23<00:00, 79.38it/s] \n",
      "Epoch: 2. Validation. Loss: 3.829 , time : 2.2178866863250732: 100%|██████████| 475/475 [00:02<00:00, 210.04it/s]\n",
      "Epoch: 3. Train.      Loss: 0.997 , time : 23.746790170669556: 100%|██████████| 1898/1898 [00:23<00:00, 79.78it/s]\n",
      "Epoch: 3. Validation. Loss: 3.821 , time : 2.180818796157837: 100%|██████████| 475/475 [00:02<00:00, 213.48it/s] \n",
      "Epoch: 4. Train.      Loss: 0.997 , time : 24.030938863754272: 100%|██████████| 1898/1898 [00:24<00:00, 78.84it/s]\n",
      "Epoch: 4. Validation. Loss: 3.820 , time : 2.120537757873535: 100%|██████████| 475/475 [00:02<00:00, 217.36it/s] \n",
      "Epoch: 5. Train.      Loss: 0.996 , time : 23.958016872406006: 100%|██████████| 1898/1898 [00:24<00:00, 79.08it/s]\n",
      "Epoch: 5. Validation. Loss: 3.828 , time : 2.2019600868225098: 100%|██████████| 475/475 [00:02<00:00, 211.49it/s]\n",
      "Epoch: 6. Train.      Loss: 0.996 , time : 23.74839735031128: 100%|██████████| 1898/1898 [00:23<00:00, 79.75it/s] \n",
      "Epoch: 6. Validation. Loss: 3.838 , time : 2.192774772644043: 100%|██████████| 475/475 [00:02<00:00, 212.39it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18950... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▄▄▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▁█▂▁▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.99636</td></tr><tr><td>Min_Val_Loss</td><td>3.81949</td></tr><tr><td>Val_Loss</td><td>3.8277</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hardy-sweep-128</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/b57yc4cs\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/b57yc4cs</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_125022-b57yc4cs/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f4nob7oq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f4nob7oq\" target=\"_blank\">vibrant-sweep-129</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 6.087 , time : 38.74789595603943: 100%|██████████| 1898/1898 [00:38<00:00, 48.93it/s] \n",
      "Epoch: 0. Validation. Loss: 6.054 , time : 2.179192543029785: 100%|██████████| 475/475 [00:02<00:00, 213.70it/s] \n",
      "Epoch: 1. Train.      Loss: 5.616 , time : 38.7567253112793: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s]  \n",
      "Epoch: 1. Validation. Loss: 5.756 , time : 2.142014980316162: 100%|██████████| 475/475 [00:02<00:00, 217.22it/s] \n",
      "Epoch: 2. Train.      Loss: 5.168 , time : 38.55508518218994: 100%|██████████| 1898/1898 [00:38<00:00, 49.17it/s] \n",
      "Epoch: 2. Validation. Loss: 5.370 , time : 2.187680721282959: 100%|██████████| 475/475 [00:02<00:00, 212.95it/s] \n",
      "Epoch: 3. Train.      Loss: 4.733 , time : 38.67860412597656: 100%|██████████| 1898/1898 [00:38<00:00, 49.02it/s] \n",
      "Epoch: 3. Validation. Loss: 4.995 , time : 2.206540584564209: 100%|██████████| 475/475 [00:02<00:00, 210.96it/s] \n",
      "Epoch: 4. Train.      Loss: 4.393 , time : 38.91623139381409: 100%|██████████| 1898/1898 [00:38<00:00, 48.71it/s] \n",
      "Epoch: 4. Validation. Loss: 4.741 , time : 2.214550495147705: 100%|██████████| 475/475 [00:02<00:00, 210.34it/s] \n",
      "Epoch: 5. Train.      Loss: 4.128 , time : 38.886290550231934: 100%|██████████| 1898/1898 [00:38<00:00, 48.75it/s]\n",
      "Epoch: 5. Validation. Loss: 4.556 , time : 2.220869779586792: 100%|██████████| 475/475 [00:02<00:00, 209.79it/s] \n",
      "Epoch: 6. Train.      Loss: 3.910 , time : 38.51305365562439: 100%|██████████| 1898/1898 [00:38<00:00, 49.22it/s] \n",
      "Epoch: 6. Validation. Loss: 4.410 , time : 2.1579806804656982: 100%|██████████| 475/475 [00:02<00:00, 215.80it/s]\n",
      "Epoch: 7. Train.      Loss: 3.724 , time : 38.72904419898987: 100%|██████████| 1898/1898 [00:38<00:00, 48.95it/s] \n",
      "Epoch: 7. Validation. Loss: 4.258 , time : 2.1427714824676514: 100%|██████████| 475/475 [00:02<00:00, 215.92it/s]\n",
      "Epoch: 8. Train.      Loss: 3.558 , time : 38.53889012336731: 100%|██████████| 1898/1898 [00:38<00:00, 49.19it/s] \n",
      "Epoch: 8. Validation. Loss: 4.179 , time : 2.1663222312927246: 100%|██████████| 475/475 [00:02<00:00, 214.75it/s]\n",
      "Epoch: 9. Train.      Loss: 3.410 , time : 38.82713055610657: 100%|██████████| 1898/1898 [00:38<00:00, 48.83it/s] \n",
      "Epoch: 9. Validation. Loss: 4.090 , time : 2.135387420654297: 100%|██████████| 475/475 [00:02<00:00, 218.05it/s] \n",
      "Epoch: 10. Train.      Loss: 3.280 , time : 38.87921071052551: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s] \n",
      "Epoch: 10. Validation. Loss: 3.979 , time : 2.2031593322753906: 100%|██████████| 475/475 [00:02<00:00, 211.30it/s]\n",
      "Epoch: 11. Train.      Loss: 3.154 , time : 38.98216509819031: 100%|██████████| 1898/1898 [00:39<00:00, 48.63it/s] \n",
      "Epoch: 11. Validation. Loss: 3.918 , time : 2.210489511489868: 100%|██████████| 475/475 [00:02<00:00, 210.71it/s] \n",
      "Epoch: 12. Train.      Loss: 3.044 , time : 38.97710609436035: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s] \n",
      "Epoch: 12. Validation. Loss: 3.867 , time : 2.153258800506592: 100%|██████████| 475/475 [00:02<00:00, 216.23it/s] \n",
      "Epoch: 13. Train.      Loss: 2.933 , time : 38.91221499443054: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s] \n",
      "Epoch: 13. Validation. Loss: 3.769 , time : 2.1680078506469727: 100%|██████████| 475/475 [00:02<00:00, 214.75it/s]\n",
      "Epoch: 14. Train.      Loss: 2.842 , time : 38.62705945968628: 100%|██████████| 1898/1898 [00:38<00:00, 49.08it/s] \n",
      "Epoch: 14. Validation. Loss: 3.749 , time : 2.187976121902466: 100%|██████████| 475/475 [00:02<00:00, 212.72it/s] \n",
      "Epoch: 15. Train.      Loss: 2.751 , time : 38.87058353424072: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 15. Validation. Loss: 3.708 , time : 2.1405322551727295: 100%|██████████| 475/475 [00:02<00:00, 216.97it/s]\n",
      "Epoch: 16. Train.      Loss: 2.658 , time : 38.959832191467285: 100%|██████████| 1898/1898 [00:39<00:00, 48.66it/s]\n",
      "Epoch: 16. Validation. Loss: 3.680 , time : 2.113128662109375: 100%|██████████| 475/475 [00:02<00:00, 220.28it/s] \n",
      "Epoch: 17. Train.      Loss: 2.583 , time : 39.18961715698242: 100%|██████████| 1898/1898 [00:39<00:00, 48.37it/s] \n",
      "Epoch: 17. Validation. Loss: 3.641 , time : 2.133448362350464: 100%|██████████| 475/475 [00:02<00:00, 218.06it/s] \n",
      "Epoch: 18. Train.      Loss: 2.508 , time : 39.32199811935425: 100%|██████████| 1898/1898 [00:39<00:00, 48.21it/s] \n",
      "Epoch: 18. Validation. Loss: 3.614 , time : 2.2189807891845703: 100%|██████████| 475/475 [00:02<00:00, 209.89it/s]\n",
      "Epoch: 19. Train.      Loss: 2.439 , time : 38.8638174533844: 100%|██████████| 1898/1898 [00:38<00:00, 48.78it/s]  \n",
      "Epoch: 19. Validation. Loss: 3.591 , time : 2.2369449138641357: 100%|██████████| 475/475 [00:02<00:00, 208.28it/s]\n",
      "Epoch: 20. Train.      Loss: 2.368 , time : 38.84676742553711: 100%|██████████| 1898/1898 [00:38<00:00, 48.80it/s] \n",
      "Epoch: 20. Validation. Loss: 3.536 , time : 2.1353466510772705: 100%|██████████| 475/475 [00:02<00:00, 218.00it/s]\n",
      "Epoch: 21. Train.      Loss: 2.302 , time : 39.12157654762268: 100%|██████████| 1898/1898 [00:39<00:00, 48.46it/s] \n",
      "Epoch: 21. Validation. Loss: 3.547 , time : 2.2172434329986572: 100%|██████████| 475/475 [00:02<00:00, 209.98it/s]\n",
      "Epoch: 22. Train.      Loss: 2.241 , time : 38.89926028251648: 100%|██████████| 1898/1898 [00:38<00:00, 48.74it/s] \n",
      "Epoch: 22. Validation. Loss: 3.511 , time : 2.2642569541931152: 100%|██████████| 475/475 [00:02<00:00, 205.59it/s]\n",
      "Epoch: 23. Train.      Loss: 2.184 , time : 39.56695199012756: 100%|██████████| 1898/1898 [00:39<00:00, 47.92it/s] \n",
      "Epoch: 23. Validation. Loss: 3.516 , time : 2.156226873397827: 100%|██████████| 475/475 [00:02<00:00, 215.91it/s] \n",
      "Epoch: 24. Train.      Loss: 2.131 , time : 38.81445384025574: 100%|██████████| 1898/1898 [00:38<00:00, 48.84it/s] \n",
      "Epoch: 24. Validation. Loss: 3.524 , time : 2.2390248775482178: 100%|██████████| 475/475 [00:02<00:00, 208.08it/s]\n",
      "Epoch: 25. Train.      Loss: 2.076 , time : 39.01691246032715: 100%|██████████| 1898/1898 [00:39<00:00, 48.59it/s] \n",
      "Epoch: 25. Validation. Loss: 3.463 , time : 2.144585609436035: 100%|██████████| 475/475 [00:02<00:00, 216.77it/s] \n",
      "Epoch: 26. Train.      Loss: 2.026 , time : 38.82909846305847: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 26. Validation. Loss: 3.540 , time : 2.1761674880981445: 100%|██████████| 475/475 [00:02<00:00, 214.03it/s]\n",
      "Epoch: 27. Train.      Loss: 1.978 , time : 38.83513140678406: 100%|██████████| 1898/1898 [00:38<00:00, 48.82it/s] \n",
      "Epoch: 27. Validation. Loss: 3.523 , time : 2.132672071456909: 100%|██████████| 475/475 [00:02<00:00, 218.26it/s] \n",
      "Epoch: 28. Train.      Loss: 1.923 , time : 39.119340896606445: 100%|██████████| 1898/1898 [00:39<00:00, 48.46it/s]\n",
      "Epoch: 28. Validation. Loss: 3.528 , time : 2.15854811668396: 100%|██████████| 475/475 [00:02<00:00, 215.59it/s]  \n",
      "Epoch: 29. Train.      Loss: 1.882 , time : 38.90347743034363: 100%|██████████| 1898/1898 [00:38<00:00, 48.73it/s] \n",
      "Epoch: 29. Validation. Loss: 3.487 , time : 2.1546056270599365: 100%|██████████| 475/475 [00:02<00:00, 216.08it/s]\n",
      "Epoch: 30. Train.      Loss: 1.834 , time : 39.24264073371887: 100%|██████████| 1898/1898 [00:39<00:00, 48.31it/s] \n",
      "Epoch: 30. Validation. Loss: 3.475 , time : 2.2822909355163574: 100%|██████████| 475/475 [00:02<00:00, 204.14it/s]\n",
      "Epoch: 31. Train.      Loss: 1.795 , time : 39.02873921394348: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s] \n",
      "Epoch: 31. Validation. Loss: 3.532 , time : 2.1509668827056885: 100%|██████████| 475/475 [00:02<00:00, 216.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20869... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>█▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>█▇▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.83367</td></tr><tr><td>Min_Val_Loss</td><td>3.46279</td></tr><tr><td>Val_Loss</td><td>3.4753</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vibrant-sweep-129</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f4nob7oq\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/f4nob7oq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_125555-f4nob7oq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g2e9d5ju with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/g2e9d5ju\" target=\"_blank\">bright-sweep-130</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.808 , time : 38.5283203125: 100%|██████████| 1898/1898 [00:38<00:00, 49.21it/s]     \n",
      "Epoch: 0. Validation. Loss: 3.542 , time : 2.2589282989501953: 100%|██████████| 475/475 [00:02<00:00, 206.32it/s]\n",
      "Epoch: 1. Train.      Loss: 1.716 , time : 38.76890707015991: 100%|██████████| 1898/1898 [00:38<00:00, 48.90it/s] \n",
      "Epoch: 1. Validation. Loss: 3.558 , time : 2.161714553833008: 100%|██████████| 475/475 [00:02<00:00, 214.72it/s] \n",
      "Epoch: 2. Train.      Loss: 1.676 , time : 38.911795139312744: 100%|██████████| 1898/1898 [00:38<00:00, 48.72it/s]\n",
      "Epoch: 2. Validation. Loss: 3.588 , time : 2.215540885925293: 100%|██████████| 475/475 [00:02<00:00, 210.28it/s] \n",
      "Epoch: 3. Train.      Loss: 1.637 , time : 38.8815495967865: 100%|██████████| 1898/1898 [00:38<00:00, 48.76it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.567 , time : 2.209758758544922: 100%|██████████| 475/475 [00:02<00:00, 210.75it/s] \n",
      "Epoch: 4. Train.      Loss: 1.598 , time : 38.76250171661377: 100%|██████████| 1898/1898 [00:38<00:00, 48.91it/s] \n",
      "Epoch: 4. Validation. Loss: 3.542 , time : 2.214168071746826: 100%|██████████| 475/475 [00:02<00:00, 210.40it/s] \n",
      "Epoch: 5. Train.      Loss: 1.569 , time : 38.87107872962952: 100%|██████████| 1898/1898 [00:38<00:00, 48.77it/s] \n",
      "Epoch: 5. Validation. Loss: 3.642 , time : 2.2329108715057373: 100%|██████████| 475/475 [00:02<00:00, 208.70it/s]\n",
      "Epoch: 6. Train.      Loss: 1.529 , time : 39.20497536659241: 100%|██████████| 1898/1898 [00:39<00:00, 48.36it/s] \n",
      "Epoch: 6. Validation. Loss: 3.618 , time : 2.1868607997894287: 100%|██████████| 475/475 [00:02<00:00, 212.96it/s]\n",
      "Epoch: 7. Train.      Loss: 1.497 , time : 38.93537163734436: 100%|██████████| 1898/1898 [00:38<00:00, 48.69it/s] \n",
      "Epoch: 7. Validation. Loss: 3.585 , time : 2.1698076725006104: 100%|██████████| 475/475 [00:02<00:00, 211.80it/s]\n",
      "Epoch: 8. Train.      Loss: 1.465 , time : 39.80587840080261: 100%|██████████| 1898/1898 [00:39<00:00, 47.61it/s] \n",
      "Epoch: 8. Validation. Loss: 3.655 , time : 2.2343952655792236: 100%|██████████| 475/475 [00:02<00:00, 208.56it/s]\n",
      "Epoch: 9. Train.      Loss: 1.433 , time : 39.239428758621216: 100%|██████████| 1898/1898 [00:39<00:00, 48.32it/s]\n",
      "Epoch: 9. Validation. Loss: 3.700 , time : 2.135897159576416: 100%|██████████| 475/475 [00:02<00:00, 217.97it/s] \n",
      "Epoch: 10. Train.      Loss: 1.404 , time : 39.15352702140808: 100%|██████████| 1898/1898 [00:39<00:00, 48.42it/s] \n",
      "Epoch: 10. Validation. Loss: 3.630 , time : 2.2110259532928467: 100%|██████████| 475/475 [00:02<00:00, 210.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29449... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▆▅▄▄▃▂▂▁</td></tr><tr><td>Min_Val_Loss</td><td>████▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▂▃▂▁▅▄▃▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.43301</td></tr><tr><td>Min_Val_Loss</td><td>3.542</td></tr><tr><td>Val_Loss</td><td>3.6996</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">bright-sweep-130</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/g2e9d5ju\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/g2e9d5ju</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_131813-g2e9d5ju/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z1swoj2f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/z1swoj2f\" target=\"_blank\">olive-sweep-131</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.417 , time : 38.94647455215454: 100%|██████████| 1898/1898 [00:38<00:00, 48.68it/s] \n",
      "Epoch: 0. Validation. Loss: 3.725 , time : 2.182996988296509: 100%|██████████| 475/475 [00:02<00:00, 213.34it/s] \n",
      "Epoch: 1. Train.      Loss: 1.355 , time : 38.79887509346008: 100%|██████████| 1898/1898 [00:38<00:00, 48.86it/s] \n",
      "Epoch: 1. Validation. Loss: 3.678 , time : 2.1222779750823975: 100%|██████████| 475/475 [00:02<00:00, 219.21it/s]\n",
      "Epoch: 2. Train.      Loss: 1.325 , time : 38.711217164993286: 100%|██████████| 1898/1898 [00:38<00:00, 48.97it/s]\n",
      "Epoch: 2. Validation. Loss: 3.751 , time : 2.123053550720215: 100%|██████████| 475/475 [00:02<00:00, 219.15it/s] \n",
      "Epoch: 3. Train.      Loss: 1.298 , time : 39.0587203502655: 100%|██████████| 1898/1898 [00:39<00:00, 48.54it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.745 , time : 2.282975912094116: 100%|██████████| 475/475 [00:02<00:00, 204.12it/s] \n",
      "Epoch: 4. Train.      Loss: 1.271 , time : 38.973727226257324: 100%|██████████| 1898/1898 [00:39<00:00, 48.64it/s]\n",
      "Epoch: 4. Validation. Loss: 3.767 , time : 2.2358930110931396: 100%|██████████| 475/475 [00:02<00:00, 208.41it/s]\n",
      "Epoch: 5. Train.      Loss: 1.248 , time : 39.023462772369385: 100%|██████████| 1898/1898 [00:39<00:00, 48.58it/s]\n",
      "Epoch: 5. Validation. Loss: 3.833 , time : 2.1760330200195312: 100%|██████████| 475/475 [00:02<00:00, 212.37it/s]\n",
      "Epoch: 6. Train.      Loss: 1.219 , time : 38.69256901741028: 100%|██████████| 1898/1898 [00:38<00:00, 49.00it/s] \n",
      "Epoch: 6. Validation. Loss: 3.825 , time : 2.1499102115631104: 100%|██████████| 475/475 [00:02<00:00, 216.55it/s]\n",
      "Epoch: 7. Train.      Loss: 1.196 , time : 38.969992876052856: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s]\n",
      "Epoch: 7. Validation. Loss: 3.909 , time : 2.2093842029571533: 100%|██████████| 475/475 [00:02<00:00, 209.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1126... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>█▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▁▄▄▅██</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.21949</td></tr><tr><td>Min_Val_Loss</td><td>3.67814</td></tr><tr><td>Val_Loss</td><td>3.82485</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-131</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/z1swoj2f\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/z1swoj2f</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_132558-z1swoj2f/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3r6vy4wr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/3r6vy4wr\" target=\"_blank\">earthy-sweep-132</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 1.219 , time : 38.21663951873779: 100%|██████████| 1898/1898 [00:38<00:00, 49.60it/s] \n",
      "Epoch: 0. Validation. Loss: 3.860 , time : 2.235133171081543: 100%|██████████| 475/475 [00:02<00:00, 208.48it/s] \n",
      "Epoch: 1. Train.      Loss: 1.162 , time : 39.10557770729065: 100%|██████████| 1898/1898 [00:39<00:00, 48.48it/s] \n",
      "Epoch: 1. Validation. Loss: 3.897 , time : 2.175377368927002: 100%|██████████| 475/475 [00:02<00:00, 211.79it/s] \n",
      "Epoch: 2. Train.      Loss: 1.143 , time : 38.96415400505066: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s] \n",
      "Epoch: 2. Validation. Loss: 3.927 , time : 2.1788530349731445: 100%|██████████| 475/475 [00:02<00:00, 213.65it/s]\n",
      "Epoch: 3. Train.      Loss: 1.123 , time : 38.7569797039032: 100%|██████████| 1898/1898 [00:38<00:00, 48.92it/s]  \n",
      "Epoch: 3. Validation. Loss: 3.899 , time : 2.1848981380462646: 100%|██████████| 475/475 [00:02<00:00, 213.20it/s]\n",
      "Epoch: 4. Train.      Loss: 1.100 , time : 38.9675018787384: 100%|██████████| 1898/1898 [00:39<00:00, 48.65it/s]  \n",
      "Epoch: 4. Validation. Loss: 3.975 , time : 2.1331379413604736: 100%|██████████| 475/475 [00:02<00:00, 218.21it/s]\n",
      "Epoch: 5. Train.      Loss: 1.079 , time : 38.665425062179565: 100%|██████████| 1898/1898 [00:38<00:00, 49.03it/s]\n",
      "Epoch: 5. Validation. Loss: 4.017 , time : 2.1486189365386963: 100%|██████████| 475/475 [00:02<00:00, 216.53it/s]\n",
      "Epoch: 6. Train.      Loss: 1.065 , time : 38.81348705291748: 100%|██████████| 1898/1898 [00:38<00:00, 48.85it/s] \n",
      "Epoch: 6. Validation. Loss: 3.973 , time : 2.2077550888061523: 100%|██████████| 475/475 [00:02<00:00, 210.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4241... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▅▄▃▂▁</td></tr><tr><td>Min_Val_Loss</td><td>▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▁▃▄▃▆█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.07904</td></tr><tr><td>Min_Val_Loss</td><td>3.85995</td></tr><tr><td>Val_Loss</td><td>4.01676</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">earthy-sweep-132</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/3r6vy4wr\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/3r6vy4wr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_133138-3r6vy4wr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s1qx9o4v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s1qx9o4v\" target=\"_blank\">distinctive-sweep-133</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 0.969 , time : 23.822208642959595: 100%|██████████| 1898/1898 [00:23<00:00, 79.53it/s]\n",
      "Epoch: 0. Validation. Loss: 3.975 , time : 2.2368693351745605: 100%|██████████| 475/475 [00:02<00:00, 208.16it/s]\n",
      "Epoch: 1. Train.      Loss: 0.949 , time : 24.065962314605713: 100%|██████████| 1898/1898 [00:24<00:00, 78.72it/s]\n",
      "Epoch: 1. Validation. Loss: 3.976 , time : 2.1809475421905518: 100%|██████████| 475/475 [00:02<00:00, 213.50it/s]\n",
      "Epoch: 2. Train.      Loss: 0.938 , time : 23.751142501831055: 100%|██████████| 1898/1898 [00:23<00:00, 79.69it/s]\n",
      "Epoch: 2. Validation. Loss: 3.957 , time : 2.204352855682373: 100%|██████████| 475/475 [00:02<00:00, 211.30it/s] \n",
      "Epoch: 3. Train.      Loss: 0.932 , time : 23.979156017303467: 100%|██████████| 1898/1898 [00:24<00:00, 79.01it/s]\n",
      "Epoch: 3. Validation. Loss: 3.959 , time : 2.1478099822998047: 100%|██████████| 475/475 [00:02<00:00, 216.68it/s]\n",
      "Epoch: 4. Train.      Loss: 0.925 , time : 24.076295614242554: 100%|██████████| 1898/1898 [00:24<00:00, 78.61it/s]\n",
      "Epoch: 4. Validation. Loss: 3.961 , time : 2.155557632446289: 100%|██████████| 475/475 [00:02<00:00, 215.96it/s] \n",
      "Epoch: 5. Train.      Loss: 0.921 , time : 24.379393100738525: 100%|██████████| 1898/1898 [00:24<00:00, 77.71it/s]\n",
      "Epoch: 5. Validation. Loss: 3.961 , time : 2.2567691802978516: 100%|██████████| 475/475 [00:02<00:00, 205.70it/s]\n",
      "Epoch: 6. Train.      Loss: 0.918 , time : 23.97766876220703: 100%|██████████| 1898/1898 [00:24<00:00, 79.01it/s] \n",
      "Epoch: 6. Validation. Loss: 3.975 , time : 2.1314237117767334: 100%|██████████| 475/475 [00:02<00:00, 218.36it/s]\n",
      "Epoch: 7. Train.      Loss: 0.915 , time : 23.889466047286987: 100%|██████████| 1898/1898 [00:23<00:00, 79.30it/s]\n",
      "Epoch: 7. Validation. Loss: 3.965 , time : 2.1961443424224854: 100%|██████████| 475/475 [00:02<00:00, 212.00it/s]\n",
      "Epoch: 8. Train.      Loss: 0.912 , time : 23.68282198905945: 100%|██████████| 1898/1898 [00:23<00:00, 80.00it/s] \n",
      "Epoch: 8. Validation. Loss: 3.956 , time : 2.2061634063720703: 100%|██████████| 475/475 [00:02<00:00, 211.14it/s]\n",
      "Epoch: 9. Train.      Loss: 0.909 , time : 23.858206510543823: 100%|██████████| 1898/1898 [00:23<00:00, 79.40it/s]\n",
      "Epoch: 9. Validation. Loss: 3.959 , time : 2.2582693099975586: 100%|██████████| 475/475 [00:02<00:00, 206.37it/s]\n",
      "Epoch: 10. Train.      Loss: 0.907 , time : 23.991462230682373: 100%|██████████| 1898/1898 [00:24<00:00, 78.91it/s]\n",
      "Epoch: 10. Validation. Loss: 3.971 , time : 2.165611743927002: 100%|██████████| 475/475 [00:02<00:00, 214.98it/s] \n",
      "Epoch: 11. Train.      Loss: 0.905 , time : 23.950833797454834: 100%|██████████| 1898/1898 [00:23<00:00, 79.09it/s]\n",
      "Epoch: 11. Validation. Loss: 3.965 , time : 2.2207822799682617: 100%|██████████| 475/475 [00:02<00:00, 209.76it/s]\n",
      "Epoch: 12. Train.      Loss: 0.904 , time : 23.80336356163025: 100%|██████████| 1898/1898 [00:23<00:00, 79.53it/s] \n",
      "Epoch: 12. Validation. Loss: 3.984 , time : 2.20283579826355: 100%|██████████| 475/475 [00:02<00:00, 211.45it/s]  \n",
      "Epoch: 13. Train.      Loss: 0.902 , time : 23.873740911483765: 100%|██████████| 1898/1898 [00:23<00:00, 79.35it/s]\n",
      "Epoch: 13. Validation. Loss: 3.979 , time : 2.1647417545318604: 100%|██████████| 475/475 [00:02<00:00, 214.98it/s]\n",
      "Epoch: 14. Train.      Loss: 0.903 , time : 23.826133489608765: 100%|██████████| 1898/1898 [00:23<00:00, 79.51it/s]\n",
      "Epoch: 14. Validation. Loss: 3.983 , time : 2.184976816177368: 100%|██████████| 475/475 [00:02<00:00, 213.16it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6939... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Min_Val_Loss</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▆▆▁▂▂▂▆▃▁▂▅▃█▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.90222</td></tr><tr><td>Min_Val_Loss</td><td>3.95593</td></tr><tr><td>Val_Loss</td><td>3.9789</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">distinctive-sweep-133</strong>: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s1qx9o4v\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/s1qx9o4v</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_133638-s1qx9o4v/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hwevqa9m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/runs/hwevqa9m\" target=\"_blank\">cool-sweep-134</a></strong> to <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn\" target=\"_blank\">https://wandb.ai/ahagyue/KNOW_dacon_contest/sweeps/n3h4t7kn</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train.      Loss: 0.902 , time : 24.397681713104248: 100%|██████████| 1898/1898 [00:24<00:00, 77.65it/s]\n",
      "Epoch: 0. Validation. Loss: 3.980 , time : 2.1508724689483643: 100%|██████████| 475/475 [00:02<00:00, 216.43it/s]\n",
      "Epoch: 1. Train.      Loss: 0.899 , time : 24.257630109786987: 100%|██████████| 1898/1898 [00:24<00:00, 78.10it/s]\n",
      "Epoch: 1. Validation. Loss: 3.983 , time : 2.2045772075653076: 100%|██████████| 475/475 [00:02<00:00, 211.32it/s]\n",
      "Epoch: 2. Train.      Loss: 0.905 , time : 21.31918215751648:  88%|████████▊ | 1673/1898 [00:21<00:02, 80.49it/s] "
     ]
    }
   ],
   "source": [
    "train_loader = lambda batch_size: create_exp_loaders(2017, args, 1, True, batch_size)\n",
    "val_loader = lambda batch_size: create_exp_loaders(2017, args, 1, False, batch_size)\n",
    "\n",
    "tune_hyperparameter(\n",
    "    train_dataset=train_loader, val_dataset=val_loader,  # data loader\n",
    "    hyper_params_setting=hyper_params_setting, default_setting=default_setting,  # hyperparameters for tuning\n",
    "    project='KNOW_dacon_contest', entity='ahagyue',  # names\n",
    "    arguments=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'grid',\n",
       " 'metric': {'name': 'Test_Loss', 'goal': 'minimize'},\n",
       " 'parameters': {'batch_size': {'values': [4, 8, 16]},\n",
       "  'learning_rate': {'values': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03]},\n",
       "  'weight_decay': {'values': [5e-06, 1e-05, 5e-05, 0.0001]},\n",
       "  'criterion': {'values': [CrossEntropyLoss()]},\n",
       "  'optimizer': {'values': [<function setting.exp_config.ExpConfig.__init__.<locals>.<lambda>(p, lr, wd)>,\n",
       "    <function setting.exp_config.ExpConfig.__init__.<locals>.<lambda>(p, lr, wd)>]},\n",
       "  'model': {'values': [KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=150, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=150, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=250, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=250, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=300, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=300, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=350, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=350, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=400, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=450, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=450, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=500, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=500, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=550, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=550, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=600, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=600, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=650, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=650, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=700, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=700, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=750, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=750, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=800, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=800, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=850, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=850, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=900, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=900, out_features=538, bias=True)\n",
       "      )\n",
       "    ),\n",
       "    KnowNet(\n",
       "      (small_net_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (10): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (11): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (12): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (13): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (14): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (15): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (16): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (17): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (18): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (19): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (20): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (21): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (22): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (23): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (24): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (25): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (26): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (27): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (28): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (29): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (30): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (31): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (32): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (33): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (34): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (35): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (36): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (37): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (38): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (39): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (40): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (41): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (42): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (43): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (44): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (45): Sequential(\n",
       "          (0): Linear(in_features=7, out_features=14, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=14, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (46): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (47): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (48): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Sequential(\n",
       "        (0): Linear(in_features=77, out_features=950, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=950, out_features=538, bias=True)\n",
       "      )\n",
       "    )]}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
